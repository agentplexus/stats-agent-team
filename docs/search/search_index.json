{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Statistics Agent Team","text":"<p>A multi-agent system for finding and verifying statistics from reputable web sources using Go, built with Google ADK (Agent Development Kit) and Eino.</p>"},{"location":"#overview","title":"Overview","text":"<p>This project implements a sophisticated multi-agent architecture that leverages LLMs and web search to find verifiable statistics, prioritizing well-known and respected publishers. The system ensures accuracy through automated verification of sources.</p>"},{"location":"#features","title":"Features","text":""},{"location":"#core-capabilities","title":"Core Capabilities","text":"<ul> <li>Multi-agent pipeline - Full verification workflow (Research \u2192 Synthesis \u2192 Verification)</li> <li>Real web search - Google search via Serper/SerpAPI (30 URLs searched by default)</li> <li>Comprehensive extraction - Processes 15+ pages, reads 30K chars per page for thorough coverage</li> <li>Source verification - Validates excerpts and values match actual web pages</li> <li>Human-in-the-loop retry - Prompts user when partial results found</li> <li>Reputable source prioritization - Government, academic, research organizations</li> </ul>"},{"location":"#alternative-modes","title":"Alternative Modes","text":"<ul> <li>Direct LLM mode - Fast but uses LLM memory (not recommended for statistics)</li> <li>Hybrid mode - LLM discovery + web verification</li> <li>OpenAPI documentation - Interactive Swagger UI for Direct agent (port 8005)</li> </ul>"},{"location":"#technical-stack","title":"Technical Stack","text":"<ul> <li>Multi-LLM providers - Gemini, Claude, OpenAI, Ollama, xAI Grok via unified interface</li> <li>Google ADK integration - For LLM-based agents</li> <li>Eino framework - Deterministic graph orchestration (Recommended)</li> <li>A2A Protocol - Agent-to-Agent interoperability (Google standard)</li> <li>LLM Observability - OmniObserve integration (Opik, Langfuse, Phoenix)</li> <li>Huma v2 - OpenAPI 3.1 docs for Direct agent</li> <li>MCP Server - Integration with Claude Code and other MCP clients</li> <li>Docker deployment - Easy containerized setup</li> </ul>"},{"location":"#output-format","title":"Output Format","text":"<p>The system returns verified statistics in JSON format:</p> <pre><code>[\n  {\n    \"name\": \"Global temperature increase since pre-industrial times\",\n    \"value\": 1.1,\n    \"unit\": \"\u00b0C\",\n    \"source\": \"IPCC Sixth Assessment Report\",\n    \"source_url\": \"https://www.ipcc.ch/...\",\n    \"excerpt\": \"Global surface temperature has increased by approximately 1.1\u00b0C since pre-industrial times...\",\n    \"verified\": true,\n    \"date_found\": \"2025-12-13T10:30:00Z\"\n  }\n]\n</code></pre>"},{"location":"#field-descriptions","title":"Field Descriptions","text":"Field Description <code>name</code> Description of the statistic <code>value</code> Numerical value (float32) <code>unit</code> Unit of measurement (e.g., \"\u00b0C\", \"%\", \"million\", \"billion\") <code>source</code> Name of source organization/publication <code>source_url</code> URL to the original source <code>excerpt</code> Verbatim quote containing the statistic <code>verified</code> Whether the verification agent confirmed it <code>date_found</code> Timestamp when statistic was found"},{"location":"#technology-stack","title":"Technology Stack","text":"<ul> <li>Language: Go 1.21+</li> <li>Agent Frameworks:<ul> <li>Google ADK (Agent Development Kit) - LLM-based agents + A2A protocol</li> <li>Eino - Deterministic graph orchestration</li> </ul> </li> <li>LLM Integration:<ul> <li>OmniLLM - Multi-provider LLM abstraction</li> <li>Supports: Gemini, Claude, OpenAI, xAI Grok, Ollama</li> </ul> </li> <li>Observability:<ul> <li>OmniObserve - Unified LLM observability</li> <li>Supports: Comet Opik, Langfuse, Arize Phoenix</li> </ul> </li> <li>Protocols:<ul> <li>HTTP - Custom security, flexibility (ports 800x)</li> <li>A2A - Agent-to-Agent interoperability (ports 900x)</li> </ul> </li> <li>Search:<ul> <li>OmniSerp - Unified serp API abstraction</li> <li>Supports: Serper.dev, SerpAPI</li> </ul> </li> </ul>"},{"location":"#how-it-works","title":"How It Works","text":"<ol> <li>User Request: User provides a topic via CLI or API</li> <li>Orchestration: Orchestrator receives request and initiates workflow</li> <li>Research Phase: Research agent searches web for candidate statistics</li> <li>Verification Phase: Verification agent validates each candidate</li> <li>Quality Control: Orchestrator checks if minimum verified stats met</li> <li>Retry Logic: If needed, request more candidates and verify</li> <li>Response: Return verified statistics in structured JSON format</li> </ol>"},{"location":"#contributing","title":"Contributing","text":"<p>Contributions welcome! Please:</p> <ol> <li>Fork the repository</li> <li>Create a feature branch</li> <li>Make your changes</li> <li>Add tests</li> <li>Submit a pull request</li> </ol>"},{"location":"#acknowledgments","title":"Acknowledgments","text":"<ul> <li>Built with Google ADK (Agent Development Kit)</li> <li>Uses Eino for deterministic orchestration</li> <li>Multi-LLM support via OmniLLM</li> <li>LLM observability via OmniObserve</li> <li>A2A protocol for agent interoperability</li> <li>Inspired by multi-agent collaboration frameworks</li> </ul>"},{"location":"architecture/4-agent-architecture/","title":"4-Agent Architecture Implementation","text":""},{"location":"architecture/4-agent-architecture/#overview","title":"Overview","text":"<p>The Statistics Agent Team now uses a 4-agent architecture with clear separation of concerns:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502         Orchestration Agent (Eino/ADK)              \u2502\n\u2502              Port 8003 / 8000                       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502              \u2502              \u2502\n         \u25bc              \u25bc              \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   Research     \u2502 \u2502  Synthesis   \u2502 \u2502 Verification   \u2502\n\u2502    Agent       \u2502 \u2502    Agent     \u2502 \u2502    Agent       \u2502\n\u2502   Port 8001    \u2502 \u2502  Port 8004   \u2502 \u2502   Port 8002    \u2502\n\u2502                \u2502 \u2502              \u2502 \u2502                \u2502\n\u2502 - Web Search   \u2502 \u2502 - Fetch URLs \u2502 \u2502 - Verify URLs  \u2502\n\u2502 - Find Sources \u2502 \u2502 - LLM Extract\u2502 \u2502 - Check Facts  \u2502\n\u2502 - Filter       \u2502 \u2502 - Parse Stats\u2502 \u2502 - Validate     \u2502\n\u2502   Reputable    \u2502 \u2502              \u2502 \u2502   Excerpts     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n        \u2502                  \u2502                  \u2502\n        \u25bc                  \u25bc                  \u25bc\n   Serper/SerpAPI    Webpage Content    Source Validation\n</code></pre>"},{"location":"architecture/4-agent-architecture/#agent-responsibilities","title":"Agent Responsibilities","text":""},{"location":"architecture/4-agent-architecture/#1-research-agent-port-8001","title":"1. Research Agent (Port 8001)","text":"<p>Role: Source Discovery Technology: Web Search (Serper/SerpAPI) No LLM Required</p> <p>Tasks: - Perform web searches via <code>pkg/search</code> service - Return URLs with metadata (title, snippet, domain) - Filter for reputable sources (.gov, .edu, research orgs) - Output: List of SearchResult objects</p> <p>Files: - <code>agents/research/main.go</code> - Simplified to focus on search only - <code>pkg/search/service.go</code> - MetaSerp integration</p> <p>API: <pre><code>POST /research\n{\n  \"topic\": \"climate change\",\n  \"max_statistics\": 20,\n  \"reputable_only\": true\n}\n\nResponse:\n{\n  \"topic\": \"climate change\",\n  \"candidates\": [/* URLs as placeholder candidates */],\n  \"timestamp\": \"2025-12-13T10:30:00Z\"\n}\n</code></pre></p>"},{"location":"architecture/4-agent-architecture/#2-synthesis-agent-port-8004-new","title":"2. Synthesis Agent (Port 8004) \u2b50 NEW","text":"<p>Role: Statistics Extraction Technology: ADK + LLM (Gemini/Claude/OpenAI/Ollama) LLM-Heavy</p> <p>Tasks: - Fetch webpage content from URLs - Use LLM to intelligently analyze text and extract statistics - Extract numerical values, units, and context using structured prompts - Find verbatim excerpts containing statistics - Create candidate statistics with proper metadata - Output: List of CandidateStatistic objects</p> <p>Files: - <code>agents/synthesis/main.go</code> - LLM-based extraction agent \u2705 - Uses <code>pkg/agent/base.go</code> for shared LLM initialization - Full LLM integration with JSON output parsing - Supports all LLM providers via ADK</p> <p>API: <pre><code>POST /synthesize\n{\n  \"topic\": \"climate change\",\n  \"search_results\": [\n    {\n      \"url\": \"https://www.iea.org/...\",\n      \"title\": \"Renewable Energy Report\",\n      \"snippet\": \"...\",\n      \"domain\": \"iea.org\"\n    }\n  ],\n  \"min_statistics\": 5,\n  \"max_statistics\": 20\n}\n\nResponse:\n{\n  \"topic\": \"climate change\",\n  \"candidates\": [\n    {\n      \"name\": \"Renewable energy growth\",\n      \"value\": 83,\n      \"unit\": \"%\",\n      \"source\": \"iea.org\",\n      \"source_url\": \"https://www.iea.org/...\",\n      \"excerpt\": \"Renewable capacity grew by 83% in 2023...\"\n    }\n  ],\n  \"sources_analyzed\": 5,\n  \"timestamp\": \"2025-12-13T10:30:15Z\"\n}\n</code></pre></p>"},{"location":"architecture/4-agent-architecture/#3-verification-agent-port-8002","title":"3. Verification Agent (Port 8002)","text":"<p>Role: Fact Checking Technology: ADK + LLM (light usage) LLM-Light</p> <p>Tasks: - Re-fetch source URLs - Verify excerpts exist verbatim in source - Check numerical values match - Flag hallucinations or mismatches - Output: VerificationResult objects with pass/fail</p> <p>Files: - <code>agents/verification/main.go</code> - Unchanged</p> <p>API: (Unchanged)</p>"},{"location":"architecture/4-agent-architecture/#4-orchestration-agent-ports-80038000","title":"4. Orchestration Agent (Ports 8003/8000)","text":"<p>Role: Workflow Coordination Technology: Eino (recommended) or ADK No LLM (Eino) or LLM-driven (ADK)</p> <p>Workflow: 1. Call Research Agent \u2192 get URLs 2. Call Synthesis Agent \u2192 extract statistics from URLs 3. Call Verification Agent \u2192 validate statistics 4. Retry logic if needed 5. Return verified statistics</p> <p>Files: - <code>agents/orchestration-eino/main.go</code> - Eino version (deterministic) - <code>agents/orchestration/main.go</code> - ADK version (LLM-driven) - <code>pkg/orchestration/eino.go</code> - Shared Eino logic</p>"},{"location":"architecture/4-agent-architecture/#data-flow","title":"Data Flow","text":"<pre><code>User Request\n     \u2502\n     \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Orchestration   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u2502 1. Search for sources\n         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Research Agent  \u2502 \u2500\u2500\u25ba Returns: [{url, title, snippet, domain}, ...]\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u2502 2. Extract statistics from URLs\n         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Synthesis Agent \u2502 \u2500\u2500\u25ba Returns: [{name, value, unit, source_url, excerpt}, ...]\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u2502 3. Verify statistics\n         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Verification    \u2502 \u2500\u2500\u25ba Returns: [{statistic, verified: true/false, reason}, ...]\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u25bc\n    Verified Statistics\n</code></pre>"},{"location":"architecture/4-agent-architecture/#models-pkgmodelsstatisticgo","title":"Models (pkg/models/statistic.go)","text":""},{"location":"architecture/4-agent-architecture/#new-models-added","title":"New Models Added:","text":"<pre><code>// SearchResult - Output from Research Agent\ntype SearchResult struct {\n    URL      string\n    Title    string\n    Snippet  string\n    Domain   string\n    Position int\n}\n\n// SynthesisRequest - Input to Synthesis Agent\ntype SynthesisRequest struct {\n    Topic         string\n    SearchResults []SearchResult\n    MinStatistics int\n    MaxStatistics int\n}\n\n// SynthesisResponse - Output from Synthesis Agent\ntype SynthesisResponse struct {\n    Topic           string\n    Candidates      []CandidateStatistic\n    SourcesAnalyzed int\n    Timestamp       time.Time\n}\n</code></pre>"},{"location":"architecture/4-agent-architecture/#implementation-status","title":"Implementation Status","text":""},{"location":"architecture/4-agent-architecture/#completed","title":"\u2705 Completed","text":"<ol> <li>Synthesis Agent Created (<code>agents/synthesis/main.go</code>)</li> <li>ADK integration</li> <li>Webpage fetching</li> <li>Basic regex extraction (placeholder)</li> <li> <p>HTTP API on port 8004</p> </li> <li> <p>Research Agent Refactored (<code>agents/research/main.go</code>)</p> </li> <li>Removed LLM/ADK dependencies</li> <li>Focus on search only</li> <li>Returns SearchResult objects</li> <li> <p>Reputable source filtering</p> </li> <li> <p>Models Updated (<code>pkg/models/statistic.go</code>)</p> </li> <li>SearchResult model</li> <li> <p>SynthesisRequest/Response models</p> </li> <li> <p>Configuration Updated (<code>pkg/config/config.go</code>)</p> </li> <li>Added SynthesisAgentURL (port 8004)</li> </ol>"},{"location":"architecture/4-agent-architecture/#completed-updated","title":"\u2705 Completed (Updated)","text":"<ol> <li>Orchestration Update - Both Eino and ADK orchestration updated for 4-agent workflow</li> <li> <p>Eino Orchestration (<code>pkg/orchestration/eino.go</code>) \u2705</p> <ul> <li>Added synthesis agent call between research and verification</li> <li>Updated workflow graph with nodeSynthesis</li> <li>Added SynthesisState type</li> <li>Added callSynthesisAgent() helper method</li> </ul> </li> <li> <p>ADK Orchestration (<code>agents/orchestration/main.go</code>) \u2705</p> <ul> <li>Added HTTP client for synthesis agent</li> <li>Updated orchestrate() method to call all 4 agents in sequence</li> <li>Added callSynthesisAgent() helper method</li> </ul> </li> <li> <p>Docker Configuration \u2705</p> </li> <li>Added synthesis agent to Dockerfile (build and copy binary)</li> <li>Updated docker-compose.yml with port 8004</li> <li>Added synthesis agent to docker-entrypoint.sh (startup and shutdown)</li> <li> <p>Exposed all 4 ports: 8001, 8002, 8003, 8004</p> </li> <li> <p>Makefile Updates \u2705</p> </li> <li>Added <code>run-synthesis</code> target</li> <li>Updated <code>run-all</code> to include synthesis agent</li> <li>Updated <code>run-all-eino</code> to include synthesis agent</li> <li>Updated <code>build</code> target to build synthesis binary</li> </ol>"},{"location":"architecture/4-agent-architecture/#recently-completed","title":"\u2705 Recently Completed","text":"<ol> <li>LLM Integration &amp; Code Refactoring \u2705</li> <li>Created <code>pkg/agent/base.go</code> - Shared agent base with common LLM initialization</li> <li>Refactored Synthesis Agent to use proper LLM-based extraction (not regex)</li> <li>Refactored Verification Agent to use shared base agent</li> <li>Eliminated code duplication across agents</li> <li>Full multi-LLM support (Gemini/Claude/OpenAI/Ollama) via unified interface</li> </ol>"},{"location":"architecture/4-agent-architecture/#todo","title":"\u23f3 TODO","text":"<ol> <li>Documentation Updates</li> <li>Update API examples to show 4-agent workflow with LLM extraction</li> </ol>"},{"location":"architecture/4-agent-architecture/#benefits-of-4-agent-architecture","title":"Benefits of 4-Agent Architecture","text":"<p>\u2705 Separation of Concerns - Each agent has one job \u2705 Better Caching - Research results can be reused \u2705 Parallel Processing - Synthesize multiple URLs concurrently \u2705 Cost Optimization - Only use LLM where needed (synthesis) \u2705 Easier Testing - Mock each agent independently \u2705 Scalability - Scale synthesis agents based on load \u2705 Flexibility - Can run all in-process or as microservices</p>"},{"location":"architecture/4-agent-architecture/#next-steps","title":"Next Steps","text":"<p>To complete the 4-agent architecture:</p> <ol> <li>Update orchestration agents to call synthesis</li> <li>Update Docker/Makefile for deployment</li> <li>Enhance synthesis agent with full LLM integration</li> <li>Update all documentation</li> <li>Test end-to-end workflow</li> </ol>"},{"location":"architecture/4-agent-architecture/#port-mapping","title":"Port Mapping","text":"Agent Port Role Orchestration (ADK) 8000 Workflow (LLM-driven) Research 8001 Search (no LLM) Verification 8002 Validation (LLM-light) Orchestration (Eino) 8003 Workflow (deterministic) Synthesis 8004 Extraction (LLM-heavy) \u2b50"},{"location":"architecture/eino-orchestration/","title":"Eino Orchestration Agent","text":"<p>A deterministic orchestration agent built with Eino framework that provides more predictable and reliable workflow execution for finding verified statistics.</p>"},{"location":"architecture/eino-orchestration/#overview","title":"Overview","text":"<p>This project now includes two orchestration agents with different characteristics:</p>"},{"location":"architecture/eino-orchestration/#1-adk-orchestration-port-8000","title":"1. ADK Orchestration (Port 8000)","text":"<ul> <li>Framework: Google ADK (Agent Development Kit)</li> <li>Approach: LLM-based decision making (Gemini 2.0 Flash)</li> <li>Characteristics:</li> <li>Flexible, adaptive behavior</li> <li>Uses LLM for orchestration decisions</li> <li>More dynamic but less predictable</li> <li>Ideal for complex decision-making workflows</li> </ul>"},{"location":"architecture/eino-orchestration/#2-eino-orchestration-port-8003-recommended","title":"2. Eino Orchestration (Port 8003) \u2b50 RECOMMENDED","text":"<ul> <li>Framework: Eino</li> <li>Approach: Deterministic graph-based workflow</li> <li>Characteristics:</li> <li>Deterministic, predictable behavior</li> <li>Type-safe graph orchestration</li> <li>Compile-time validation</li> <li>More reliable and faster</li> <li>Recommended for production use</li> </ul>"},{"location":"architecture/eino-orchestration/#why-eino-for-orchestration","title":"Why Eino for Orchestration?","text":""},{"location":"architecture/eino-orchestration/#deterministic-workflow","title":"Deterministic Workflow","text":"<p>The Eino orchestrator uses a directed graph with explicit nodes and edges, ensuring: - Same input \u2192 Same workflow execution path - No LLM decision-making for orchestration logic - Predictable resource usage and timing</p>"},{"location":"architecture/eino-orchestration/#type-safety","title":"Type Safety","text":"<p>Eino provides compile-time type checking: <pre><code>Graph[*models.OrchestrationRequest, *models.OrchestrationResponse]\n</code></pre> This ensures all nodes have compatible input/output types.</p>"},{"location":"architecture/eino-orchestration/#performance","title":"Performance","text":"<ul> <li>Faster: No LLM calls for orchestration decisions</li> <li>Lower cost: Only uses LLMs in research/verification agents</li> <li>More reliable: Graph compilation validates workflow before execution</li> </ul>"},{"location":"architecture/eino-orchestration/#eino-workflow-graph","title":"Eino Workflow Graph","text":"<p>The Eino orchestrator implements this deterministic workflow:</p> <pre><code>START\n  \u2193\n[1. Validate Input]\n  \u2193\n[2. Research] \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2192 Call Research Agent\n  \u2193\n[3. Verification] \u2500\u2500\u2500\u2500\u2500\u2500\u2192 Call Verification Agent\n  \u2193\n[4. Quality Check] \u2500\u2500\u2500\u2500\u2192 Deterministic decision (verified &gt;= target?)\n  \u2193\n[5. Retry Research?] \u2500\u2500\u2192 If needed, request more candidates\n  \u2193\n[6. Format Response]\n  \u2193\nEND\n</code></pre>"},{"location":"architecture/eino-orchestration/#node-descriptions","title":"Node Descriptions","text":"<ol> <li>Validate Input: Set defaults, validate parameters</li> <li>Research: HTTP call to research agent for candidates</li> <li>Verification: HTTP call to verification agent</li> <li>Quality Check: Deterministic comparison (verified count vs target)</li> <li>Retry Research: Conditional retry based on quality check</li> <li>Format Response: Build final JSON output</li> </ol>"},{"location":"architecture/eino-orchestration/#usage","title":"Usage","text":""},{"location":"architecture/eino-orchestration/#running-the-eino-orchestrator","title":"Running the Eino Orchestrator","text":""},{"location":"architecture/eino-orchestration/#option-1-run-with-eino-orchestrator","title":"Option 1: Run with Eino orchestrator","text":"<pre><code>make run-all-eino\n</code></pre> <p>This starts: - Research Agent (8001/9001) - Verification Agent (8002/9002) - Eino Orchestration Agent (8003/9003) \u2b50</p>"},{"location":"architecture/eino-orchestration/#option-2-run-eino-orchestrator-separately","title":"Option 2: Run Eino orchestrator separately","text":"<pre><code># Terminal 1: Research Agent\nmake run-research\n\n# Terminal 2: Verification Agent\nmake run-verification\n\n# Terminal 3: Eino Orchestrator\nmake run-orchestration-eino\n</code></pre>"},{"location":"architecture/eino-orchestration/#api-calls","title":"API Calls","text":""},{"location":"architecture/eino-orchestration/#http-api","title":"HTTP API","text":"<pre><code>curl -X POST http://localhost:8003/orchestrate \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"topic\": \"climate change\",\n    \"min_verified_stats\": 10,\n    \"max_candidates\": 30,\n    \"reputable_only\": true\n  }'\n</code></pre>"},{"location":"architecture/eino-orchestration/#a2a-protocol-port-9003","title":"A2A Protocol (Port 9003)","text":"<p>The Eino orchestrator also supports A2A protocol for agent-to-agent communication.</p>"},{"location":"architecture/eino-orchestration/#comparison-trpc-agent-vs-eino","title":"Comparison: trpc-agent vs Eino","text":"Feature trpc-agent Orchestrator Eino Orchestrator Port 8000 (HTTP), 9000 (A2A) 8003 (HTTP), 9003 (A2A) Decision Making LLM-based Deterministic Predictability Variable Consistent Performance Slower (LLM calls) Faster (no LLM) Cost Higher (LLM tokens) Lower (no LLM) Flexibility High Moderate Type Safety Runtime Compile-time Workflow Dynamic Static graph Best For Complex adaptive tasks Predictable workflows"},{"location":"architecture/eino-orchestration/#when-to-use-which","title":"When to Use Which?","text":""},{"location":"architecture/eino-orchestration/#use-eino-orchestrator-when","title":"Use Eino Orchestrator When:","text":"<ul> <li>\u2705 You need deterministic, reproducible results</li> <li>\u2705 You want faster response times</li> <li>\u2705 You need lower costs (no LLM for orchestration)</li> <li>\u2705 Your workflow is well-defined and stable</li> <li>\u2705 You want compile-time type safety</li> </ul>"},{"location":"architecture/eino-orchestration/#use-adk-orchestrator-when","title":"Use ADK Orchestrator When:","text":"<ul> <li>\u2705 You need adaptive decision making</li> <li>\u2705 Workflow logic changes based on content</li> <li>\u2705 You want LLM reasoning for orchestration (Gemini 2.0 Flash)</li> <li>\u2705 Requirements are less well-defined</li> <li>\u2705 You need complex decision trees in orchestration</li> </ul>"},{"location":"architecture/eino-orchestration/#eino-graph-implementation","title":"Eino Graph Implementation","text":""},{"location":"architecture/eino-orchestration/#key-components","title":"Key Components","text":""},{"location":"architecture/eino-orchestration/#1-lambda-nodes","title":"1. Lambda Nodes","text":"<p>Each step is implemented as an <code>InvokableLambda</code>: <pre><code>validateInputLambda := compose.InvokableLambda(\n    func(ctx context.Context, req *models.OrchestrationRequest) (*models.OrchestrationRequest, error) {\n        // Validation logic\n        return req, nil\n    }\n)\ng.AddLambdaNode(\"validate_input\", validateInputLambda)\n</code></pre></p>"},{"location":"architecture/eino-orchestration/#2-type-safe-state","title":"2. Type-Safe State","text":"<p>State is passed through typed structs: - <code>OrchestrationRequest</code> \u2192 Input - <code>ResearchState</code> \u2192 After research - <code>VerificationState</code> \u2192 After verification - <code>QualityDecision</code> \u2192 After quality check - <code>OrchestrationResponse</code> \u2192 Output</p>"},{"location":"architecture/eino-orchestration/#3-graph-edges","title":"3. Graph Edges","text":"<p>Edges define workflow sequence: <pre><code>g.AddEdge(compose.START, \"validate_input\")\ng.AddEdge(\"validate_input\", \"research\")\ng.AddEdge(\"research\", \"verification\")\n// ... etc\n</code></pre></p>"},{"location":"architecture/eino-orchestration/#4-graph-compilation","title":"4. Graph Compilation","text":"<p>Graph is compiled before execution: <pre><code>compiledGraph, err := oa.graph.Compile(ctx)\nresult, err := compiledGraph.Invoke(ctx, req)\n</code></pre></p>"},{"location":"architecture/eino-orchestration/#configuration","title":"Configuration","text":""},{"location":"architecture/eino-orchestration/#environment-variables","title":"Environment Variables","text":"<pre><code>ORCHESTRATOR_EINO_URL=http://localhost:8003\n</code></pre> <p>Add to your <code>.env</code> file to configure the Eino orchestrator URL.</p>"},{"location":"architecture/eino-orchestration/#architecture-diagram","title":"Architecture Diagram","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    USER REQUEST                          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                   \u2502\n                   \u2502 Choose orchestrator:\n                   \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                   \u2502                 \u2502                     \u2502\n                   \u25bc                 \u25bc                     \u25bc\n         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n         \u2502   ORCHESTRATOR  \u2502  \u2502  ORCHESTRATOR    \u2502  \u2502   Direct   \u2502\n         \u2502   (trpc-agent)  \u2502  \u2502    (Eino)        \u2502  \u2502   Call     \u2502\n         \u2502   Port 8000     \u2502  \u2502   Port 8003      \u2502  \u2502            \u2502\n         \u2502                 \u2502  \u2502                  \u2502  \u2502            \u2502\n         \u2502  LLM-based      \u2502  \u2502  Deterministic   \u2502  \u2502            \u2502\n         \u2502  decisions      \u2502  \u2502  graph workflow  \u2502  \u2502            \u2502\n         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518\n                  \u2502                    \u2502                   \u2502\n                  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                               \u2502\n                \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                \u2502                             \u2502\n                \u25bc                             \u25bc\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502  RESEARCH AGENT      \u2502     \u2502 VERIFICATION AGENT   \u2502\n    \u2502  Port 8001           \u2502     \u2502 Port 8002            \u2502\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"architecture/eino-orchestration/#benefits-of-dual-orchestrators","title":"Benefits of Dual Orchestrators","text":"<ol> <li>Flexibility: Choose the right tool for your use case</li> <li>Comparison: A/B test different orchestration approaches</li> <li>Migration: Gradually move from LLM to deterministic workflows</li> <li>Learning: Compare results between approaches</li> </ol>"},{"location":"architecture/eino-orchestration/#technology-stack","title":"Technology Stack","text":"<ul> <li>Eino: CloudWeGo's LLM application framework</li> <li>Graph Orchestration: Directed graph with typed nodes</li> <li>A2A Protocol: trpc-a2a-go for agent communication</li> <li>Type Safety: Compile-time validation</li> </ul>"},{"location":"architecture/eino-orchestration/#logging","title":"Logging","text":"<p>The Eino orchestrator provides detailed logging with <code>[Eino]</code> prefix: <pre><code>[Eino] Validating input for topic: climate change\n[Eino] Executing research for topic: climate change\n[Eino] Verifying 15 candidates\n[Eino] Quality check: 12 verified (target: 10)\n[Eino] Quality target met\n[Eino] Formatting response with 12 verified statistics\n</code></pre></p>"},{"location":"architecture/eino-orchestration/#next-steps","title":"Next Steps","text":"<ol> <li> <p>Install Eino:    <pre><code>go get github.com/cloudwego/eino\n</code></pre></p> </li> <li> <p>Build:    <pre><code>make build\n</code></pre></p> </li> <li> <p>Run with Eino:    <pre><code>make run-all-eino\n</code></pre></p> </li> <li> <p>Test:    <pre><code>curl -X POST http://localhost:8003/orchestrate -H \"Content-Type: application/json\" -d '{\"topic\": \"AI statistics\", \"min_verified_stats\": 5}'\n</code></pre></p> </li> </ol>"},{"location":"architecture/eino-orchestration/#contributing","title":"Contributing","text":"<p>Contributions to improve the Eino orchestration workflow are welcome!</p>"},{"location":"architecture/overview/","title":"Architecture Overview","text":"<p>The system implements a 4-agent architecture with clear separation of concerns.</p>"},{"location":"architecture/overview/#high-level-architecture","title":"High-Level Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                   User Request                          \u2502\n\u2502              \"Find climate change statistics\"           \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                    \u2502\n                    \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502            ORCHESTRATION AGENT                          \u2502\n\u2502              (Port 8000 - Both ADK/Eino)                \u2502\n\u2502  \u2022 Coordinates 4-agent workflow                         \u2502\n\u2502  \u2022 Manages retry logic                                  \u2502\n\u2502  \u2022 Ensures quality standards                            \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n      \u2502             \u2502                \u2502\n      \u25bc             \u25bc                \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  RESEARCH  \u2502 \u2502SYNTHESIS \u2502 \u2502  VERIFICATION   \u2502\n\u2502   AGENT    \u2502 \u2502  AGENT   \u2502 \u2502     AGENT       \u2502\n\u2502 Port 8001  \u2502 \u2502Port 8004 \u2502 \u2502   Port 8002     \u2502\n\u2502            \u2502 \u2502          \u2502 \u2502                 \u2502\n\u2502 \u2022 Search   \u2502\u2500\u2502\u2022 Fetch   \u2502\u2500\u2502\u2022 Re-fetch URLs  \u2502\n\u2502   Serper   \u2502 \u2502  URLs    \u2502 \u2502\u2022 Validate text  \u2502\n\u2502 \u2022 Filter   \u2502 \u2502\u2022 LLM     \u2502 \u2502\u2022 Check numbers  \u2502\n\u2502   Sources  \u2502 \u2502  Extract \u2502 \u2502\u2022 Flag errors    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n      \u2502             \u2502                \u2502\n      \u25bc             \u25bc                \u25bc\n  URLs only     Statistics     Verified Stats\n</code></pre>"},{"location":"architecture/overview/#agent-responsibilities","title":"Agent Responsibilities","text":""},{"location":"architecture/overview/#1-research-agent-agentsresearch-web-search-only","title":"1. Research Agent (<code>agents/research/</code>) - Web Search Only","text":"<ul> <li>No LLM required - Pure search functionality</li> <li>Web search via Serper/SerpAPI integration</li> <li>Returns URLs with metadata (title, snippet, domain)</li> <li>Prioritizes reputable sources (<code>.gov</code>, <code>.edu</code>, research orgs)</li> <li>Output: List of <code>SearchResult</code> objects</li> <li>Port: 8001</li> </ul>"},{"location":"architecture/overview/#2-synthesis-agent-agentssynthesis-google-adk","title":"2. Synthesis Agent (<code>agents/synthesis/</code>) - Google ADK","text":"<ul> <li>LLM-heavy extraction agent</li> <li>Built with Google ADK and LLM (Gemini/Claude/OpenAI/Ollama)</li> <li>Fetches webpage content from URLs</li> <li>Extracts numerical statistics using LLM analysis</li> <li>Finds verbatim excerpts containing statistics</li> <li>Creates <code>CandidateStatistic</code> objects with proper metadata</li> <li>Port: 8004</li> </ul>"},{"location":"architecture/overview/#3-verification-agent-agentsverification-google-adk","title":"3. Verification Agent (<code>agents/verification/</code>) - Google ADK","text":"<ul> <li>LLM-light validation agent</li> <li>Re-fetches source URLs to verify content</li> <li>Checks excerpts exist verbatim in source</li> <li>Validates numerical values match exactly</li> <li>Flags hallucinations and discrepancies</li> <li>Returns verification results with pass/fail reasons</li> <li>Port: 8002</li> </ul>"},{"location":"architecture/overview/#4a-orchestration-agent-google-adk-agentsorchestration","title":"4a. Orchestration Agent - Google ADK (<code>agents/orchestration/</code>)","text":"<ul> <li>Built with Google ADK for LLM-driven workflow decisions</li> <li>Coordinates: Research \u2192 Synthesis \u2192 Verification</li> <li>Implements adaptive retry logic</li> <li>Dynamic quality control</li> <li>Port: 8000</li> </ul>"},{"location":"architecture/overview/#4b-orchestration-agent-eino-agentsorchestration-eino-recommended","title":"4b. Orchestration Agent - Eino (<code>agents/orchestration-eino/</code>) - RECOMMENDED","text":"<ul> <li>Deterministic graph-based workflow (no LLM for orchestration)</li> <li>Type-safe orchestration with Eino framework</li> <li>Predictable, reproducible behavior</li> <li>Faster and lower cost</li> <li>Workflow: ValidateInput \u2192 Research \u2192 Synthesis \u2192 Verification \u2192 QualityCheck \u2192 Format</li> <li>Port: 8000 (same port as ADK, but they don't run simultaneously)</li> <li>Recommended for production use</li> </ul>"},{"location":"architecture/overview/#reputable-sources","title":"Reputable Sources","text":"<p>The research agent prioritizes these source types:</p> <ul> <li>Government Agencies: CDC, NIH, Census Bureau, EPA, etc.</li> <li>Academic Institutions: Universities, research journals</li> <li>Research Organizations: Pew Research, Gallup, McKinsey, etc.</li> <li>International Organizations: WHO, UN, World Bank, IMF, etc.</li> <li>Respected Media: With proper citations (NYT, WSJ, Economist, etc.)</li> </ul>"},{"location":"architecture/overview/#error-handling","title":"Error Handling","text":"<ul> <li>Source Unreachable: Marked as failed with reason</li> <li>Excerpt Not Found: Verification fails with explanation</li> <li>Value Mismatch: Flagged as discrepancy</li> <li>Insufficient Results: Automatic retry with more candidates</li> <li>Max Retries Exceeded: Returns partial results with warning</li> </ul>"},{"location":"architecture/overview/#learn-more","title":"Learn More","text":"<ul> <li>4-Agent Architecture - Detailed agent implementation</li> <li>Eino Orchestration - Deterministic graph-based orchestration</li> </ul>"},{"location":"development/lint-fixes/","title":"Lint Fixes Summary","text":"<p>This document summarizes the lint errors that were fixed in the codebase.</p>"},{"location":"development/lint-fixes/#issues-fixed","title":"Issues Fixed","text":""},{"location":"development/lint-fixes/#1-code-duplication-dupl-4-issues","title":"1. Code Duplication (dupl) - 4 issues","text":"<p>Problem: HTTP client code was duplicated across orchestration agents.</p> <p>Solution: Created a shared HTTP client utility: - File: <code>pkg/httpclient/client.go</code> - Function: <code>PostJSON()</code> - handles JSON POST requests with error handling - Benefits:   - Eliminates code duplication   - Centralizes HTTP error handling   - Easier to maintain and test</p> <p>Files Updated: - <code>pkg/orchestration/eino.go</code> - replaced duplicate <code>callResearchAgent()</code> and <code>callVerificationAgent()</code> - <code>agents/orchestration/main.go</code> - replaced duplicate HTTP client code</p>"},{"location":"development/lint-fixes/#2-unchecked-errors-errcheck-21-issues","title":"2. Unchecked Errors (errcheck) - 21 issues","text":"<p>Problem: Error return values were not being checked for: - <code>w.Write()</code> calls in health endpoints - <code>json.NewEncoder(w).Encode()</code> calls in HTTP handlers - <code>g.AddLambdaNode()</code> calls in Eino graph construction - <code>g.AddEdge()</code> calls in Eino graph construction</p> <p>Solution: Added proper error handling:</p> <p>Health Endpoints: <pre><code>// Before\nw.Write([]byte(\"OK\"))\n\n// After\nif _, err := w.Write([]byte(\"OK\")); err != nil {\n    log.Printf(\"Failed to write health response: %v\", err)\n}\n</code></pre></p> <p>JSON Encoding: <pre><code>// Before\njson.NewEncoder(w).Encode(resp)\n\n// After\nif err := json.NewEncoder(w).Encode(resp); err != nil {\n    log.Printf(\"Failed to encode response: %v\", err)\n}\n</code></pre></p> <p>Eino Graph Construction: <pre><code>// Before\ng.AddLambdaNode(nodeName, lambda)\n\n// After\nif err := g.AddLambdaNode(nodeName, lambda); err != nil {\n    log.Printf(\"[Eino] Warning: failed to add node: %v\", err)\n}\n\n// For edges (non-critical)\n_ = g.AddEdge(source, target)\n</code></pre></p> <p>Files Updated: - <code>pkg/orchestration/eino.go</code> - all graph construction and HTTP handlers - <code>agents/orchestration/main.go</code> - HTTP handlers - <code>agents/orchestration-eino/main.go</code> - health endpoint - <code>agents/research/main.go</code> - HTTP handlers - <code>agents/verification/main.go</code> - HTTP handlers</p>"},{"location":"development/lint-fixes/#3-security-issues-gosec-4-issues","title":"3. Security Issues (gosec) - 4 issues","text":"<p>Problem: HTTP servers using <code>http.ListenAndServe()</code> without timeouts (G114).</p> <p>Solution: Created <code>http.Server</code> instances with proper timeouts:</p> <pre><code>// Before\nif err := http.ListenAndServe(\":8000\", nil); err != nil {\n    log.Fatalf(\"HTTP server failed: %v\", err)\n}\n\n// After\nserver := &amp;http.Server{\n    Addr:         \":8000\",\n    ReadTimeout:  60 * time.Second,\n    WriteTimeout: 60 * time.Second,\n    IdleTimeout:  120 * time.Second,\n}\nif err := server.ListenAndServe(); err != nil {\n    log.Fatalf(\"HTTP server failed: %v\", err)\n}\n</code></pre> <p>Timeout Values by Agent: - Research Agent (<code>:8001</code>): 30s read/write, 60s idle - Verification Agent (<code>:8002</code>): 45s read/write, 90s idle - Orchestration Agent (<code>:8000</code>): 60s read/write, 120s idle - Eino Orchestration (<code>:8003</code>): 60s read/write, 120s idle</p> <p>Files Updated: - <code>agents/orchestration/main.go</code> - <code>agents/orchestration-eino/main.go</code> - <code>agents/research/main.go</code> - <code>agents/verification/main.go</code></p>"},{"location":"development/lint-fixes/#4-unused-parameters-unparam-4-issues","title":"4. Unused Parameters (unparam) - 4 issues","text":"<p>Problem: - <code>agents/research/main.go:131</code> - <code>ctx</code> parameter unused in <code>Research()</code> method - <code>agents/research/main.go:131</code> - <code>error</code> return value always nil in <code>Research()</code> method - <code>agents/verification/main.go:190</code> - <code>error</code> return value always nil in <code>Verify()</code> method</p> <p>Solution:</p> <p>Research Agent - Unused ctx parameter: <pre><code>// Before\nfunc (ra *ResearchAgent) Research(ctx context.Context, req *models.ResearchRequest) ...\n\n// After (ctx marked as unused with underscore)\nfunc (ra *ResearchAgent) Research(_ context.Context, req *models.ResearchRequest) ...\n</code></pre></p> <p>Research and Verification Agents - Error returns always nil: Added nolint directives to suppress warnings while keeping error returns for API consistency:</p> <pre><code>// Research performs research directly\n//\n//nolint:unparam // error return kept for API consistency, will be used when real implementation replaces mock\nfunc (ra *ResearchAgent) Research(_ context.Context, req *models.ResearchRequest) (*models.ResearchResponse, error) {\n</code></pre> <pre><code>// Verify processes a verification request\n//\n//nolint:unparam // error return kept for API consistency\nfunc (va *VerificationAgent) Verify(ctx context.Context, req *models.VerificationRequest) (*models.VerificationResponse, error) {\n</code></pre> <p>Rationale: Error returns are kept because: - Current implementations use mock data and don't encounter errors - Real implementations (when integrated with actual search APIs) will need error handling - Maintaining consistent API signatures across all agent methods - Methods are public interfaces that may be called by external code</p> <p>Files Updated: - <code>agents/research/main.go</code> - <code>agents/verification/main.go</code></p>"},{"location":"development/lint-fixes/#files-created","title":"Files Created","text":"<ol> <li>pkg/httpclient/client.go - Shared HTTP client utility</li> <li><code>PostJSON()</code> function for common HTTP POST with JSON</li> </ol>"},{"location":"development/lint-fixes/#testing","title":"Testing","text":"<p>All changes have been verified to compile successfully: <pre><code>go build ./...\n</code></pre></p>"},{"location":"development/lint-fixes/#impact","title":"Impact","text":"<ul> <li>Code Quality: Reduced duplication, improved error handling</li> <li>Security: Added timeouts to prevent resource exhaustion</li> <li>Maintainability: Centralized HTTP client logic</li> <li>Standards Compliance: Follows Go best practices</li> </ul>"},{"location":"development/lint-fixes/#linter-configuration","title":"Linter Configuration","text":"<p>The project uses <code>.golangci.yaml</code> with the following active linters: - dogsled - dupl - errcheck - gofmt - goimports - gosec - govet - ineffassign - misspell - nakedret - staticcheck - unconvert - unparam - unused - whitespace</p> <p>All 33 issues have been resolved (31 fixed + 2 suppressed with nolint).</p>"},{"location":"getting-started/configuration/","title":"Configuration","text":""},{"location":"getting-started/configuration/#environment-variables","title":"Environment Variables","text":""},{"location":"getting-started/configuration/#llm-configuration","title":"LLM Configuration","text":"Variable Description Default <code>LLM_PROVIDER</code> LLM provider: <code>gemini</code>, <code>claude</code>, <code>openai</code>, <code>xai</code>, <code>ollama</code> <code>gemini</code> <code>LLM_MODEL</code> Model name (provider-specific) See defaults below <code>LLM_API_KEY</code> Generic API key (overrides provider-specific) - <code>LLM_BASE_URL</code> Base URL for custom endpoints (Ollama, etc.) -"},{"location":"getting-started/configuration/#provider-specific-api-keys","title":"Provider-Specific API Keys","text":"Variable Description Default <code>GOOGLE_API_KEY</code> / <code>GEMINI_API_KEY</code> Google API key for Gemini Required for Gemini <code>ANTHROPIC_API_KEY</code> / <code>CLAUDE_API_KEY</code> Anthropic API key for Claude Required for Claude <code>OPENAI_API_KEY</code> OpenAI API key Required for OpenAI <code>XAI_API_KEY</code> xAI API key for Grok Required for xAI <code>OLLAMA_URL</code> Ollama server URL <code>http://localhost:11434</code>"},{"location":"getting-started/configuration/#default-models-by-provider","title":"Default Models by Provider","text":"Provider Default Model Alternative Gemini <code>gemini-2.5-flash</code> <code>gemini-2.5-pro</code> Claude <code>claude-sonnet-4-20250514</code> <code>claude-opus-4-1-20250805</code> OpenAI <code>gpt-4o</code> <code>gpt-5</code> xAI <code>grok-4-1-fast-reasoning</code> <code>grok-4-1-fast-non-reasoning</code> Ollama <code>llama3:8b</code> <code>mistral:7b</code> <p>See LLM Configuration for detailed LLM setup.</p>"},{"location":"getting-started/configuration/#search-configuration","title":"Search Configuration","text":"Variable Description Default <code>SEARCH_PROVIDER</code> Search provider: <code>serper</code>, <code>serpapi</code> <code>serper</code> <code>SERPER_API_KEY</code> Serper API key (get from serper.dev) Required for real search <code>SERPAPI_API_KEY</code> SerpAPI key (alternative provider) Required for SerpAPI <p>Note</p> <p>Without a search API key, the research agent will use mock data. See Search Integration for setup details.</p>"},{"location":"getting-started/configuration/#observability-configuration","title":"Observability Configuration","text":"Variable Description Default <code>OBSERVABILITY_ENABLED</code> Enable LLM observability <code>false</code> <code>OBSERVABILITY_PROVIDER</code> Provider: <code>opik</code>, <code>langfuse</code>, <code>phoenix</code> <code>opik</code> <code>OBSERVABILITY_API_KEY</code> API key for the provider - <code>OBSERVABILITY_ENDPOINT</code> Custom endpoint (optional) Provider default <code>OBSERVABILITY_PROJECT</code> Project name for grouping traces <code>stats-agent-team</code> <p>Supported Providers:</p> <ul> <li>Comet Opik - LLM tracing and evaluation</li> <li>Langfuse - Open-source LLM observability</li> <li>Arize Phoenix - ML observability platform</li> </ul>"},{"location":"getting-started/configuration/#agent-url-configuration","title":"Agent URL Configuration","text":"Variable Description Default <code>RESEARCH_AGENT_URL</code> Research agent URL <code>http://localhost:8001</code> <code>SYNTHESIS_AGENT_URL</code> Synthesis agent URL <code>http://localhost:8004</code> <code>VERIFICATION_AGENT_URL</code> Verification agent URL <code>http://localhost:8002</code> <code>ORCHESTRATOR_URL</code> Orchestrator URL (both ADK/Eino) <code>http://localhost:8000</code>"},{"location":"getting-started/configuration/#port-configuration","title":"Port Configuration","text":"<p>Each agent exposes both HTTP and A2A (Agent-to-Agent) protocol endpoints:</p> Agent HTTP Port A2A Port Description Orchestration (ADK/Eino) 8000 9000 Graph-based workflow coordination Research (ADK) 8001 9001 Web search via Serper/SerpAPI Verification (ADK) 8002 9002 LLM-based verification Synthesis (ADK) 8004 9004 LLM-based statistics extraction Direct (Huma) 8005 - Direct LLM search with OpenAPI docs"},{"location":"getting-started/configuration/#a2a-endpoints-per-agent","title":"A2A Endpoints per Agent","text":"<ul> <li><code>GET /.well-known/agent-card.json</code> - Agent discovery</li> <li><code>POST /invoke</code> - JSON-RPC execution</li> </ul> <p>Enable A2A with: <code>A2A_ENABLED=true</code></p>"},{"location":"getting-started/configuration/#project-structure","title":"Project Structure","text":"<pre><code>stats-agent-team/\n\u251c\u2500\u2500 agents/\n\u2502   \u251c\u2500\u2500 direct/             # Direct search agent (Huma + OpenAPI, port 8005)\n\u2502   \u2502   \u2514\u2500\u2500 main.go\n\u2502   \u251c\u2500\u2500 orchestration/      # Orchestration agent (Google ADK, port 8000)\n\u2502   \u2502   \u2514\u2500\u2500 main.go\n\u2502   \u251c\u2500\u2500 orchestration-eino/ # Orchestration agent (Eino, port 8000)\n\u2502   \u2502   \u2514\u2500\u2500 main.go\n\u2502   \u251c\u2500\u2500 research/           # Research agent (port 8001)\n\u2502   \u2502   \u2514\u2500\u2500 main.go\n\u2502   \u251c\u2500\u2500 synthesis/          # Synthesis agent (Google ADK, port 8004)\n\u2502   \u2502   \u2514\u2500\u2500 main.go\n\u2502   \u2514\u2500\u2500 verification/       # Verification agent (Google ADK, port 8002)\n\u2502       \u2514\u2500\u2500 main.go\n\u251c\u2500\u2500 pkg/\n\u2502   \u251c\u2500\u2500 config/            # Configuration management\n\u2502   \u251c\u2500\u2500 direct/            # Direct LLM search service\n\u2502   \u251c\u2500\u2500 llm/               # Multi-provider LLM factory (OmniLLM + OmniObserve)\n\u2502   \u2502   \u2514\u2500\u2500 adapters/      # OmniLLM adapter for ADK integration\n\u2502   \u251c\u2500\u2500 models/            # Shared data models\n\u2502   \u2514\u2500\u2500 orchestration/     # Orchestration logic\n\u251c\u2500\u2500 main.go                # CLI entry point\n\u251c\u2500\u2500 Makefile               # Build and run commands\n\u251c\u2500\u2500 go.mod                 # Go dependencies\n\u251c\u2500\u2500 .env.example           # Environment template\n\u2514\u2500\u2500 README.md              # This file\n</code></pre>"},{"location":"getting-started/configuration/#development-commands","title":"Development Commands","text":""},{"location":"getting-started/configuration/#building","title":"Building","text":"<pre><code>make build\n</code></pre>"},{"location":"getting-started/configuration/#running-tests","title":"Running Tests","text":"<pre><code>make test\n</code></pre>"},{"location":"getting-started/configuration/#cleaning-build-artifacts","title":"Cleaning Build Artifacts","text":"<pre><code>make clean\n</code></pre>"},{"location":"getting-started/installation/","title":"Installation","text":""},{"location":"getting-started/installation/#prerequisites","title":"Prerequisites","text":"<ul> <li>Go 1.21 or higher</li> <li>LLM API key for your chosen provider:<ul> <li>Gemini (default): Google API key (set as <code>GOOGLE_API_KEY</code> or <code>GEMINI_API_KEY</code>)</li> <li>Claude: Anthropic API key (set as <code>ANTHROPIC_API_KEY</code> or <code>CLAUDE_API_KEY</code>)</li> <li>OpenAI: OpenAI API key (set as <code>OPENAI_API_KEY</code>)</li> <li>xAI Grok: xAI API key (set as <code>XAI_API_KEY</code>)</li> <li>Ollama: Local Ollama installation (default: <code>http://localhost:11434</code>)</li> </ul> </li> <li>Optional: API keys for search provider (Serper, SerpAPI)</li> </ul>"},{"location":"getting-started/installation/#setup","title":"Setup","text":""},{"location":"getting-started/installation/#1-clone-the-repository","title":"1. Clone the repository","text":"<pre><code>git clone https://github.com/agentplexus/stats-agent-team.git\ncd stats-agent-team\n</code></pre>"},{"location":"getting-started/installation/#2-install-dependencies","title":"2. Install dependencies","text":"<pre><code>make install\n# or\ngo mod download\n</code></pre>"},{"location":"getting-started/installation/#3-configure-environment-variables","title":"3. Configure environment variables","text":"<pre><code># For Gemini (default)\nexport GOOGLE_API_KEY=\"your-google-api-key\"\n\n# For Claude\nexport LLM_PROVIDER=\"claude\"\nexport ANTHROPIC_API_KEY=\"your-anthropic-api-key\"\n\n# For OpenAI\nexport LLM_PROVIDER=\"openai\"\nexport OPENAI_API_KEY=\"your-openai-api-key\"\n\n# For xAI Grok\nexport LLM_PROVIDER=\"xai\"\nexport XAI_API_KEY=\"your-xai-api-key\"\n\n# For Ollama (local)\nexport LLM_PROVIDER=\"ollama\"\nexport OLLAMA_URL=\"http://localhost:11434\"\nexport LLM_MODEL=\"llama3:latest\"\n\n# Optional: Create .env file\ncp .env.example .env\n# Edit .env with your API keys\n</code></pre>"},{"location":"getting-started/installation/#4-build-the-agents","title":"4. Build the agents","text":"<pre><code>make build\n</code></pre>"},{"location":"getting-started/installation/#verification","title":"Verification","text":"<p>After installation, verify everything is working:</p> <pre><code># Check build artifacts\nls -la bin/\n\n# Run a quick test (requires API keys configured)\nmake run-all-eino &amp;\nsleep 5\ncurl http://localhost:8000/health\n</code></pre>"},{"location":"getting-started/installation/#next-steps","title":"Next Steps","text":"<ul> <li>Quick Start - Get started quickly with Docker or local development</li> <li>Configuration - Detailed configuration options</li> </ul>"},{"location":"getting-started/quickstart/","title":"Quick Start","text":"<p>You can run the system either with Docker (containerized) or locally. Choose the method that best fits your needs.</p> Method Best For Command Docker Production, quick start, isolated environment <code>docker-compose up -d</code> Local Development, debugging, customization <code>make run-all-eino</code>"},{"location":"getting-started/quickstart/#quick-start-with-docker","title":"Quick Start with Docker","text":"<p>The fastest way to get started:</p> <pre><code># Start all agents with Docker Compose\ndocker-compose up -d\n\n# Test the orchestration endpoint\ncurl -X POST http://localhost:8000/orchestrate \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"topic\": \"climate change\", \"min_verified_stats\": 5}'\n\n# View logs\ndocker-compose logs -f\n\n# Stop\ndocker-compose down\n</code></pre> <p>See Docker Deployment for complete Docker deployment guide.</p>"},{"location":"getting-started/quickstart/#local-development-setup","title":"Local Development Setup","text":""},{"location":"getting-started/quickstart/#running-the-agents-locally","title":"Running the Agents Locally","text":""},{"location":"getting-started/quickstart/#option-1-run-all-agents-with-eino-orchestrator-recommended","title":"Option 1: Run all agents with Eino orchestrator (Recommended)","text":"<pre><code>make run-all-eino\n</code></pre>"},{"location":"getting-started/quickstart/#option-2-run-all-agents-with-adk-orchestrator","title":"Option 2: Run all agents with ADK orchestrator","text":"<pre><code>make run-all\n</code></pre>"},{"location":"getting-started/quickstart/#option-3-run-each-agent-separately-in-different-terminals","title":"Option 3: Run each agent separately (in different terminals)","text":"<pre><code># Terminal 1: Research Agent (ADK)\nmake run-research\n\n# Terminal 2: Verification Agent (ADK)\nmake run-verification\n\n# Terminal 3: Orchestration Agent (choose one)\nmake run-orchestration       # ADK version (LLM-based)\nmake run-orchestration-eino  # Eino version (deterministic, recommended)\n</code></pre>"},{"location":"getting-started/quickstart/#using-the-cli","title":"Using the CLI","text":"<p>The CLI supports three modes: Direct LLM search (fast, like ChatGPT), Direct + Verification (hybrid), and Multi-agent verification pipeline (thorough, verified).</p>"},{"location":"getting-started/quickstart/#multi-agent-pipeline-mode-recommended","title":"Multi-Agent Pipeline Mode (Recommended)","text":"<p>For verified, web-scraped statistics (requires agents running):</p> <pre><code># Start agents first\nmake run-all-eino\n\n# Then in another terminal:\n# Basic search with verification pipeline\n./bin/stats-agent search \"climate change\"\n\n# Request specific number of verified statistics\n./bin/stats-agent search \"global warming\" --min-stats 15\n\n# Increase candidate search space\n./bin/stats-agent search \"AI trends\" --min-stats 10 --max-candidates 100\n\n# Only reputable sources\n./bin/stats-agent search \"COVID-19 statistics\" --reputable-only\n\n# JSON output only\n./bin/stats-agent search \"renewable energy\" --output json\n\n# Text output only\n./bin/stats-agent search \"climate data\" --output text\n</code></pre> <p>Advantages of Multi-Agent Mode:</p> <ul> <li>Verified sources - Actually fetches and checks web pages</li> <li>Web search - Finds current statistics from the web</li> <li>Accuracy - Validates excerpts and values match</li> <li>Human-in-the-loop - Prompts to continue if target not met</li> </ul>"},{"location":"getting-started/quickstart/#direct-mode-not-recommended-for-statistics","title":"Direct Mode (Not Recommended for Statistics)","text":"<p>Direct mode uses a single LLM call to find statistics from memory - similar to ChatGPT without web search:</p> <pre><code># Start direct agent first\nmake run-direct\n\n# Then query (fast but uses LLM memory)\n./bin/stats-agent search \"climate change\" --direct\n</code></pre> <p>Why Not Recommended for Statistics</p> <ul> <li>Uses LLM memory - Not real-time web search (training data up to Jan 2025)</li> <li>Outdated URLs - LLM guesses URLs where stats came from</li> <li>Low accuracy - Pages may have moved, changed, or be paywalled</li> <li>0% verification rate - When combined with <code>--direct-verify</code>, most claims fail</li> </ul> <p>When to Use:</p> <ul> <li>General knowledge questions</li> <li>Concept explanations</li> <li>Quick brainstorming (accept unverified data)</li> </ul>"},{"location":"getting-started/quickstart/#cli-options","title":"CLI Options","text":"<pre><code>stats-agent search &lt;topic&gt; [options]\n\nOptions:\n  -d, --direct              Use direct LLM search (fast, like ChatGPT)\n      --direct-verify       Verify LLM claims with verification agent (requires --direct)\n  -m, --min-stats &lt;n&gt;       Minimum statistics to find (default: 10)\n  -c, --max-candidates &lt;n&gt;  Max candidates for pipeline mode (default: 50)\n  -r, --reputable-only      Only use reputable sources\n  -o, --output &lt;format&gt;     Output format: json, text, both (default: both)\n      --orchestrator-url    Override orchestrator URL\n  -v, --verbose             Show verbose debug information\n      --version             Show version information\n</code></pre>"},{"location":"getting-started/quickstart/#mode-comparison","title":"Mode Comparison","text":"Mode Speed Accuracy Agents Needed Client Needs API Key? Best For <code>--direct</code> Fastest LLM-claimed Direct agent only No Quick research, brainstorming <code>--direct --direct-verify</code> Fast Web-verified Direct + Verification No Balanced speed + accuracy Pipeline (default) Slower Fully verified All 4 agents No Maximum reliability"},{"location":"getting-started/quickstart/#api-usage","title":"API Usage","text":"<p>You can also call the agents directly via HTTP (works with both Docker and local deployment):</p> <pre><code># Call orchestration agent (port 8000 - supports both ADK and Eino)\ncurl -X POST http://localhost:8000/orchestrate \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"topic\": \"climate change\",\n    \"min_verified_stats\": 10,\n    \"max_candidates\": 30,\n    \"reputable_only\": true\n  }'\n</code></pre>"},{"location":"getting-started/quickstart/#using-with-claude-code-mcp-server","title":"Using with Claude Code (MCP Server)","text":"<p>The system can be used as an MCP server with Claude Code and other MCP clients:</p> <pre><code># Build the MCP server\nmake build-mcp\n\n# Configure in Claude Code's MCP settings (see MCP Server guide)\n</code></pre> <p>See MCP Server Integration for detailed setup instructions.</p>"},{"location":"guides/docker/","title":"Docker Deployment Guide","text":"<p>This guide explains how to run the Statistics Agent Team using Docker.</p> <p>Note: For local development without Docker, see the main README.</p>"},{"location":"guides/docker/#overview","title":"Overview","text":"<p>The Docker setup runs all four agents in a single container: - Research Agent (port 8001): Web search for source URLs - Synthesis Agent (port 8004): Extract statistics from URLs using LLM \u2b50 NEW - Verification Agent (port 8002): Verifies statistics from sources - Eino Orchestration Agent (port 8003): Coordinates the 4-agent workflow</p>"},{"location":"guides/docker/#quick-start","title":"Quick Start","text":""},{"location":"guides/docker/#using-docker-compose-recommended","title":"Using Docker Compose (Recommended)","text":"<ol> <li>Set up environment variables</li> </ol> <p>Create a <code>.env</code> file in the project root:</p> <pre><code># LLM Provider (gemini, claude, openai, ollama)\nLLM_PROVIDER=gemini\n\n# LLM API Keys (provide at least one)\nGEMINI_API_KEY=your_gemini_api_key_here\nCLAUDE_API_KEY=your_claude_api_key_here\nOPENAI_API_KEY=your_openai_api_key_here\n\n# Search API Keys (required for real web search)\nSEARCH_PROVIDER=serper\nSERPER_API_KEY=your_serper_api_key_here\n# OR use SerpAPI\n# SEARCH_PROVIDER=serpapi\n# SERPAPI_API_KEY=your_serpapi_key_here\n\n# For Ollama (local models)\nOLLAMA_URL=http://host.docker.internal:11434\nOLLAMA_MODEL=llama2\n\n# Optional: Override default models\n# GEMINI_MODEL=gemini-2.0-flash-exp\n# CLAUDE_MODEL=claude-3-5-sonnet-20241022\n# OPENAI_MODEL=gpt-4\n</code></pre> <ol> <li>Start the agents</li> </ol> <pre><code>docker-compose up -d\n</code></pre> <ol> <li>Check status</li> </ol> <pre><code>docker-compose ps\ndocker-compose logs -f\n</code></pre> <ol> <li>Test the orchestration endpoint</li> </ol> <pre><code>curl -X POST http://localhost:8003/orchestrate \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"topic\": \"climate change\",\n    \"min_verified_stats\": 5,\n    \"max_candidates\": 20,\n    \"reputable_only\": true\n  }'\n</code></pre> <ol> <li>Stop the agents</li> </ol> <pre><code>docker-compose down\n</code></pre>"},{"location":"guides/docker/#using-docker-directly","title":"Using Docker Directly","text":"<ol> <li>Build the image</li> </ol> <pre><code>docker build -t stats-agent-team .\n</code></pre> <ol> <li>Run the container</li> </ol> <pre><code>docker run -d \\\n  --name stats-agent-eino \\\n  -p 8001:8001 \\\n  -p 8002:8002 \\\n  -p 8003:8003 \\\n  -p 8004:8004 \\\n  -e LLM_PROVIDER=gemini \\\n  -e GEMINI_API_KEY=your_api_key_here \\\n  -e SEARCH_PROVIDER=serper \\\n  -e SERPER_API_KEY=your_serper_key_here \\\n  stats-agent-team\n</code></pre> <ol> <li>View logs</li> </ol> <pre><code>docker logs -f stats-agent-eino\n</code></pre> <ol> <li>Stop the container</li> </ol> <pre><code>docker stop stats-agent-eino\ndocker rm stats-agent-eino\n</code></pre>"},{"location":"guides/docker/#service-endpoints","title":"Service Endpoints","text":"<p>Once running, the following endpoints are available:</p>"},{"location":"guides/docker/#research-agent-port-8001","title":"Research Agent (Port 8001)","text":"<ul> <li><code>POST http://localhost:8001/research</code> - Web search for source URLs</li> <li><code>GET http://localhost:8001/health</code> - Health check</li> </ul>"},{"location":"guides/docker/#synthesis-agent-port-8004-new","title":"Synthesis Agent (Port 8004) \u2b50 NEW","text":"<ul> <li><code>POST http://localhost:8004/synthesize</code> - Extract statistics from URLs</li> <li><code>GET http://localhost:8004/health</code> - Health check</li> </ul>"},{"location":"guides/docker/#verification-agent-port-8002","title":"Verification Agent (Port 8002)","text":"<ul> <li><code>POST http://localhost:8002/verify</code> - Verify statistics</li> <li><code>GET http://localhost:8002/health</code> - Health check</li> </ul>"},{"location":"guides/docker/#orchestration-agent-port-8003","title":"Orchestration Agent (Port 8003)","text":"<ul> <li><code>POST http://localhost:8003/orchestrate</code> - Full 4-agent workflow</li> <li><code>GET http://localhost:8003/health</code> - Health check</li> </ul> <p>Note: While all agents are exposed for testing and troubleshooting, typical usage only requires calling the orchestration endpoint.</p>"},{"location":"guides/docker/#configuration","title":"Configuration","text":""},{"location":"guides/docker/#environment-variables","title":"Environment Variables","text":"Variable Description Default Required <code>LLM_PROVIDER</code> LLM provider to use <code>gemini</code> Yes <code>GEMINI_API_KEY</code> Google Gemini API key - If using Gemini <code>CLAUDE_API_KEY</code> Anthropic Claude API key - If using Claude <code>OPENAI_API_KEY</code> OpenAI API key - If using OpenAI <code>OLLAMA_URL</code> Ollama server URL <code>http://host.docker.internal:11434</code> If using Ollama <code>GEMINI_MODEL</code> Gemini model name <code>gemini-2.0-flash-exp</code> No <code>CLAUDE_MODEL</code> Claude model name <code>claude-3-5-sonnet-20241022</code> No <code>OPENAI_MODEL</code> OpenAI model name <code>gpt-4</code> No <code>OLLAMA_MODEL</code> Ollama model name <code>llama2</code> No <code>SEARCH_PROVIDER</code> Search provider <code>serper</code> No <code>SERPER_API_KEY</code> Serper API key - For real search <code>SERPAPI_API_KEY</code> SerpAPI key - Alternative search"},{"location":"guides/docker/#llm-provider-options","title":"LLM Provider Options","text":"<p>Gemini (Default) <pre><code>LLM_PROVIDER=gemini\nGEMINI_API_KEY=your_key_here\n</code></pre></p> <p>Claude <pre><code>LLM_PROVIDER=claude\nCLAUDE_API_KEY=your_key_here\n</code></pre></p> <p>OpenAI <pre><code>LLM_PROVIDER=openai\nOPENAI_API_KEY=your_key_here\n</code></pre></p> <p>Ollama (Local) <pre><code>LLM_PROVIDER=ollama\nOLLAMA_URL=http://host.docker.internal:11434\nOLLAMA_MODEL=llama2\n</code></pre></p>"},{"location":"guides/docker/#api-examples","title":"API Examples","text":""},{"location":"guides/docker/#orchestrate-full-workflow","title":"Orchestrate Full Workflow","text":"<pre><code>curl -X POST http://localhost:8003/orchestrate \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"topic\": \"renewable energy adoption\",\n    \"min_verified_stats\": 10,\n    \"max_candidates\": 30,\n    \"reputable_only\": true\n  }'\n</code></pre> <p>Response: <pre><code>{\n  \"topic\": \"renewable energy adoption\",\n  \"statistics\": [\n    {\n      \"name\": \"Global renewable capacity growth\",\n      \"value\": 83,\n      \"unit\": \"%\",\n      \"source\": \"International Energy Agency\",\n      \"source_url\": \"https://www.iea.org/...\",\n      \"excerpt\": \"Renewable capacity grew by 83% in 2023...\",\n      \"verified\": true,\n      \"date_found\": \"2025-12-13T10:30:00Z\"\n    }\n  ],\n  \"total_candidates\": 25,\n  \"verified_count\": 12,\n  \"failed_count\": 13,\n  \"timestamp\": \"2025-12-13T10:30:15Z\"\n}\n</code></pre></p>"},{"location":"guides/docker/#research-only","title":"Research Only","text":"<pre><code>curl -X POST http://localhost:8001/research \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"topic\": \"electric vehicles\",\n    \"min_statistics\": 5,\n    \"max_statistics\": 10,\n    \"reputable_only\": true\n  }'\n</code></pre>"},{"location":"guides/docker/#verification-only","title":"Verification Only","text":"<pre><code>curl -X POST http://localhost:8002/verify \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"candidates\": [\n      {\n        \"name\": \"EV market share\",\n        \"value\": 18,\n        \"unit\": \"%\",\n        \"source\": \"Bloomberg NEF\",\n        \"source_url\": \"https://about.bnef.com/...\",\n        \"excerpt\": \"Electric vehicles reached 18% market share...\"\n      }\n    ]\n  }'\n</code></pre>"},{"location":"guides/docker/#troubleshooting","title":"Troubleshooting","text":""},{"location":"guides/docker/#container-wont-start","title":"Container won't start","text":"<p>Check logs: <pre><code>docker-compose logs -f stats-agent-eino\n</code></pre></p> <p>Common issues: - Missing API keys: Ensure you've set the appropriate <code>*_API_KEY</code> variable - Port conflicts: Another service using ports 8001-8003 - Invalid LLM provider: Use <code>gemini</code>, <code>claude</code>, <code>openai</code>, or <code>ollama</code></p>"},{"location":"guides/docker/#health-check-failing","title":"Health check failing","text":"<p>Test individual agents: <pre><code>curl http://localhost:8001/health  # Research\ncurl http://localhost:8002/health  # Verification\ncurl http://localhost:8003/health  # Orchestration\n</code></pre></p>"},{"location":"guides/docker/#ollama-connection-issues","title":"Ollama connection issues","text":"<p>If using Ollama on the host: - Use <code>http://host.docker.internal:11434</code> (Mac/Windows) - Use <code>http://172.17.0.1:11434</code> (Linux) - Ensure Ollama is running: <code>ollama serve</code></p>"},{"location":"guides/docker/#view-agent-communication","title":"View agent communication","text":"<p>Enable debug logging: <pre><code>docker-compose logs -f stats-agent-eino | grep \"Orchestration\\|Research\\|Verification\"\n</code></pre></p>"},{"location":"guides/docker/#building-for-production","title":"Building for Production","text":""},{"location":"guides/docker/#multi-platform-builds","title":"Multi-platform builds","text":"<pre><code>docker buildx build \\\n  --platform linux/amd64,linux/arm64 \\\n  -t stats-agent-team:latest \\\n  .\n</code></pre>"},{"location":"guides/docker/#optimize-image-size","title":"Optimize image size","text":"<p>The Dockerfile uses multi-stage builds and Alpine Linux for minimal size: - Builder stage: ~1.2GB (includes Go toolchain) - Runtime stage: ~50MB (only binaries + Alpine)</p>"},{"location":"guides/docker/#security-scanning","title":"Security scanning","text":"<pre><code>docker scan stats-agent-team:latest\n</code></pre>"},{"location":"guides/docker/#performance-tuning","title":"Performance Tuning","text":""},{"location":"guides/docker/#resource-limits-docker-composeyml","title":"Resource limits (docker-compose.yml)","text":"<pre><code>services:\n  stats-agent-eino:\n    deploy:\n      resources:\n        limits:\n          cpus: '2.0'\n          memory: 2G\n        reservations:\n          cpus: '1.0'\n          memory: 1G\n</code></pre>"},{"location":"guides/docker/#timeout-configuration","title":"Timeout configuration","text":"<p>Agents have built-in HTTP timeouts: - Research: 30s read/write, 60s idle - Verification: 45s read/write, 90s idle - Orchestration: 60s read/write, 120s idle</p>"},{"location":"guides/docker/#integration-with-other-services","title":"Integration with Other Services","text":""},{"location":"guides/docker/#behind-a-reverse-proxy-nginx","title":"Behind a reverse proxy (nginx)","text":"<pre><code>upstream stats_orchestration {\n    server localhost:8003;\n}\n\nserver {\n    listen 80;\n    server_name stats.example.com;\n\n    location / {\n        proxy_pass http://stats_orchestration;\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n    }\n}\n</code></pre>"},{"location":"guides/docker/#kubernetes-deployment","title":"Kubernetes deployment","text":"<p>See KUBERNETES.md for Kubernetes manifests (if available).</p>"},{"location":"guides/docker/#monitoring","title":"Monitoring","text":""},{"location":"guides/docker/#health-checks","title":"Health checks","text":"<p>Docker Compose includes automatic health checks every 30 seconds.</p>"},{"location":"guides/docker/#metrics","title":"Metrics","text":"<p>To add Prometheus metrics, mount a volume for logs: <pre><code>volumes:\n  - ./logs:/var/log/stats-agent\n</code></pre></p>"},{"location":"guides/docker/#references","title":"References","text":"<ul> <li>Search Integration Guide - Setup web search for real statistics</li> <li>LLM Configuration Guide - Configure LLM providers</li> <li>MCP Server Guide - Claude Code integration</li> <li>Main README - Project overview and local setup</li> </ul>"},{"location":"guides/kubernetes/","title":"Kubernetes Deployment Guide","text":"<p>This guide covers deploying the Stats Agent Team to Kubernetes using Helm, with support for local development (Minikube) and production (AWS EKS).</p>"},{"location":"guides/kubernetes/#architecture","title":"Architecture","text":"<p>In Kubernetes, each agent runs as a separate deployment with its own pod(s):</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                        Kubernetes Cluster                      \u2502\n\u2502                                                                \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502   Research   \u2502  \u2502  Synthesis   \u2502  \u2502    Verification      \u2502  \u2502\n\u2502  \u2502    Agent     \u2502  \u2502    Agent     \u2502  \u2502       Agent          \u2502  \u2502\n\u2502  \u2502   :8001      \u2502  \u2502    :8004     \u2502  \u2502       :8002          \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502          \u2502                \u2502                     \u2502              \u2502\n\u2502          \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518              \u2502\n\u2502                           \u2502                                    \u2502\n\u2502                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2510                             \u2502\n\u2502                    \u2502 Orchestrator\u2502                             \u2502\n\u2502                    \u2502   (Eino)    \u2502                             \u2502\n\u2502                    \u2502    :8000    \u2502                             \u2502\n\u2502                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                             \u2502\n\u2502                           \u2502                                    \u2502\n\u2502                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2510                             \u2502\n\u2502                    \u2502   Ingress   \u2502                             \u2502\n\u2502                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"guides/kubernetes/#prerequisites","title":"Prerequisites","text":"<ul> <li>Docker</li> <li>kubectl</li> <li>Helm 3.x</li> <li>For Minikube: minikube</li> <li>For EKS: AWS CLI, eksctl (optional)</li> </ul>"},{"location":"guides/kubernetes/#container-images","title":"Container Images","text":"<p>Pre-built container images are published to GitHub Container Registry (ghcr.io) on each release:</p> <pre><code># Available images\ndocker pull ghcr.io/agentplexus/stats-agent-research:latest\ndocker pull ghcr.io/agentplexus/stats-agent-synthesis:latest\ndocker pull ghcr.io/agentplexus/stats-agent-verification:latest\ndocker pull ghcr.io/agentplexus/stats-agent-orchestration-eino:latest\ndocker pull ghcr.io/agentplexus/stats-agent-direct:latest\n\n# Or use a specific version\ndocker pull ghcr.io/agentplexus/stats-agent-research:v1.0.0\n</code></pre>"},{"location":"guides/kubernetes/#quick-start","title":"Quick Start","text":""},{"location":"guides/kubernetes/#using-published-images-recommended","title":"Using Published Images (Recommended)","text":"<pre><code># Deploy directly using published images\nhelm upgrade --install stats-agent ./helm/stats-agent-team \\\n  --namespace stats-agent \\\n  --create-namespace \\\n  --set secrets.geminiApiKey=YOUR_GEMINI_KEY \\\n  --set secrets.serperApiKey=YOUR_SERPER_KEY\n\n# Access the orchestration agent\nkubectl port-forward -n stats-agent svc/stats-agent-stats-agent-team-orchestration 8000:8000\n\n# Test the deployment\ncurl http://localhost:8000/health\n</code></pre>"},{"location":"guides/kubernetes/#minikube-local-development-with-local-builds","title":"Minikube (Local Development with Local Builds)","text":"<pre><code># 1. Setup Minikube\nmake k8s-minikube-setup\n\n# 2. Build images in Minikube's Docker daemon\nmake k8s-minikube-build\n\n# 3. Deploy with Helm (uses local images)\nmake k8s-minikube-deploy \\\n  --set secrets.geminiApiKey=YOUR_GEMINI_KEY \\\n  --set secrets.serperApiKey=YOUR_SERPER_KEY\n\n# 4. Access the orchestration agent\nkubectl port-forward -n stats-agent svc/stats-agent-stats-agent-team-orchestration 8000:8000\n\n# 5. Test the deployment\ncurl http://localhost:8000/health\n</code></pre>"},{"location":"guides/kubernetes/#aws-eks-production","title":"AWS EKS (Production)","text":"<pre><code># Option 1: Use published images from ghcr.io (recommended)\nhelm upgrade --install stats-agent ./helm/stats-agent-team \\\n  -f ./helm/stats-agent-team/values-eks.yaml \\\n  --namespace stats-agent \\\n  --create-namespace \\\n  --set ingress.host=stats-agent.example.com\n\n# Option 2: Use your own ECR registry\n# 1. Build images locally\nmake k8s-build-images\n\n# 2. Push to ECR\nmake k8s-eks-push REGISTRY=123456789012.dkr.ecr.us-west-2.amazonaws.com\n\n# 3. Deploy to EKS\nmake k8s-eks-deploy REGISTRY=123456789012.dkr.ecr.us-west-2.amazonaws.com\n\n# 4. Get the ALB address\nkubectl get ingress -n stats-agent\n</code></pre>"},{"location":"guides/kubernetes/#detailed-setup","title":"Detailed Setup","text":""},{"location":"guides/kubernetes/#building-container-images","title":"Building Container Images","text":"<p>Each agent is built as a separate container using <code>Dockerfile.agent</code>:</p> <pre><code># Build all agents\nmake k8s-build-images\n\n# Or build individually\ndocker build --build-arg AGENT=research -t stats-agent-research:latest -f Dockerfile.agent .\ndocker build --build-arg AGENT=synthesis -t stats-agent-synthesis:latest -f Dockerfile.agent .\ndocker build --build-arg AGENT=verification -t stats-agent-verification:latest -f Dockerfile.agent .\ndocker build --build-arg AGENT=orchestration-eino -t stats-agent-orchestration-eino:latest -f Dockerfile.agent .\ndocker build --build-arg AGENT=direct -t stats-agent-direct:latest -f Dockerfile.agent .\n</code></pre>"},{"location":"guides/kubernetes/#helm-chart-structure","title":"Helm Chart Structure","text":"<pre><code>helm/stats-agent-team/\n\u251c\u2500\u2500 Chart.yaml              # Chart metadata\n\u251c\u2500\u2500 values.yaml             # Default values\n\u251c\u2500\u2500 values-minikube.yaml    # Minikube-specific values\n\u251c\u2500\u2500 values-eks.yaml         # EKS production values\n\u2514\u2500\u2500 templates/\n    \u251c\u2500\u2500 _helpers.tpl        # Template helpers\n    \u251c\u2500\u2500 namespace.yaml      # Namespace\n    \u251c\u2500\u2500 configmap.yaml      # Configuration\n    \u251c\u2500\u2500 secret.yaml         # API keys\n    \u251c\u2500\u2500 serviceaccount.yaml # Service account\n    \u251c\u2500\u2500 *-deployment.yaml   # Agent deployments\n    \u251c\u2500\u2500 *-service.yaml      # Agent services\n    \u2514\u2500\u2500 ingress.yaml        # Ingress (EKS)\n</code></pre>"},{"location":"guides/kubernetes/#configuration","title":"Configuration","text":""},{"location":"guides/kubernetes/#api-keys","title":"API Keys","text":"<p>Option 1: Helm values (development only) <pre><code>helm upgrade --install stats-agent ./helm/stats-agent-team \\\n  --set secrets.geminiApiKey=YOUR_KEY \\\n  --set secrets.serperApiKey=YOUR_KEY\n</code></pre></p> <p>Option 2: External secrets (recommended for production)</p> <p>Disable secret creation in values: <pre><code>secrets:\n  create: false\n</code></pre></p> <p>Then create secrets manually or use External Secrets Operator with AWS Secrets Manager.</p>"},{"location":"guides/kubernetes/#llm-provider","title":"LLM Provider","text":"<p>Configure in values.yaml or via <code>--set</code>:</p> <pre><code>llm:\n  provider: gemini  # gemini, claude, openai, ollama\n  geminiModel: \"gemini-2.0-flash-exp\"\n</code></pre>"},{"location":"guides/kubernetes/#resource-limits","title":"Resource Limits","text":"<p>Adjust per-agent resources in values:</p> <pre><code>synthesis:\n  resources:\n    requests:\n      cpu: 500m\n      memory: 512Mi\n    limits:\n      cpu: 2000m\n      memory: 1Gi\n</code></pre>"},{"location":"guides/kubernetes/#minikube-deployment","title":"Minikube Deployment","text":""},{"location":"guides/kubernetes/#setup","title":"Setup","text":"<pre><code># Start Minikube with adequate resources\nmake k8s-minikube-setup\n\n# This runs:\n# minikube start --cpus=4 --memory=8192\n# minikube addons enable ingress\n# minikube addons enable metrics-server\n</code></pre>"},{"location":"guides/kubernetes/#build-and-deploy","title":"Build and Deploy","text":"<pre><code># Build images in Minikube's Docker daemon\nmake k8s-minikube-build\n\n# Deploy\nmake k8s-minikube-deploy\n</code></pre>"},{"location":"guides/kubernetes/#accessing-services","title":"Accessing Services","text":"<pre><code># Port forward to orchestration agent\nkubectl port-forward -n stats-agent svc/stats-agent-stats-agent-team-orchestration 8000:8000\n\n# Or use minikube service\nminikube service stats-agent-stats-agent-team-orchestration -n stats-agent\n\n# View all pods\nkubectl get pods -n stats-agent\n\n# View logs\nkubectl logs -n stats-agent -l app.kubernetes.io/component=orchestration -f\n</code></pre>"},{"location":"guides/kubernetes/#cleanup","title":"Cleanup","text":"<pre><code>make k8s-minikube-delete\nminikube stop  # or minikube delete\n</code></pre>"},{"location":"guides/kubernetes/#aws-eks-deployment","title":"AWS EKS Deployment","text":""},{"location":"guides/kubernetes/#prerequisites_1","title":"Prerequisites","text":"<ol> <li>EKS cluster with AWS Load Balancer Controller installed</li> <li>ECR repositories for each agent image</li> <li>IAM role for IRSA (if using AWS Secrets Manager)</li> </ol>"},{"location":"guides/kubernetes/#create-ecr-repositories","title":"Create ECR Repositories","text":"<pre><code>REGION=us-west-2\nACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)\n\nfor agent in research synthesis verification orchestration-eino direct; do\n  aws ecr create-repository --repository-name stats-agent-$agent --region $REGION\ndone\n</code></pre>"},{"location":"guides/kubernetes/#build-and-push-images","title":"Build and Push Images","text":"<pre><code>REGISTRY=$ACCOUNT_ID.dkr.ecr.$REGION.amazonaws.com\n\n# Login to ECR\naws ecr get-login-password --region $REGION | docker login --username AWS --password-stdin $REGISTRY\n\n# Build and push\nmake k8s-build-images\nmake k8s-eks-push REGISTRY=$REGISTRY\n</code></pre>"},{"location":"guides/kubernetes/#deploy","title":"Deploy","text":"<pre><code># Basic deployment\nmake k8s-eks-deploy REGISTRY=$REGISTRY\n\n# With custom domain\nhelm upgrade --install stats-agent ./helm/stats-agent-team \\\n  -f ./helm/stats-agent-team/values-eks.yaml \\\n  --namespace stats-agent \\\n  --create-namespace \\\n  --set global.image.registry=$REGISTRY \\\n  --set ingress.host=stats-agent.example.com\n</code></pre>"},{"location":"guides/kubernetes/#secrets-management-aws-secrets-manager","title":"Secrets Management (AWS Secrets Manager)","text":"<ol> <li> <p>Install External Secrets Operator: <pre><code>helm repo add external-secrets https://charts.external-secrets.io\nhelm install external-secrets external-secrets/external-secrets -n external-secrets --create-namespace\n</code></pre></p> </li> <li> <p>Create a ClusterSecretStore: <pre><code>apiVersion: external-secrets.io/v1beta1\nkind: ClusterSecretStore\nmetadata:\n  name: aws-secrets-manager\nspec:\n  provider:\n    aws:\n      service: SecretsManager\n      region: us-west-2\n      auth:\n        jwt:\n          serviceAccountRef:\n            name: external-secrets\n            namespace: external-secrets\n</code></pre></p> </li> <li> <p>Create an ExternalSecret: <pre><code>apiVersion: external-secrets.io/v1beta1\nkind: ExternalSecret\nmetadata:\n  name: stats-agent-secrets\n  namespace: stats-agent\nspec:\n  refreshInterval: 1h\n  secretStoreRef:\n    kind: ClusterSecretStore\n    name: aws-secrets-manager\n  target:\n    name: stats-agent-stats-agent-team-secrets\n  data:\n    - secretKey: GEMINI_API_KEY\n      remoteRef:\n        key: stats-agent/api-keys\n        property: gemini\n</code></pre></p> </li> </ol>"},{"location":"guides/kubernetes/#https-with-acm","title":"HTTPS with ACM","text":"<pre><code>helm upgrade --install stats-agent ./helm/stats-agent-team \\\n  -f ./helm/stats-agent-team/values-eks.yaml \\\n  --set ingress.annotations.\"alb\\.ingress\\.kubernetes\\.io/certificate-arn\"=arn:aws:acm:REGION:ACCOUNT:certificate/CERT_ID \\\n  --set ingress.annotations.\"alb\\.ingress\\.kubernetes\\.io/listen-ports\"='[{\"HTTPS\":443}]'\n</code></pre>"},{"location":"guides/kubernetes/#cleanup_1","title":"Cleanup","text":"<pre><code>make k8s-eks-delete\n</code></pre>"},{"location":"guides/kubernetes/#monitoring-and-debugging","title":"Monitoring and Debugging","text":""},{"location":"guides/kubernetes/#view-logs","title":"View Logs","text":"<pre><code># All agents\nkubectl logs -n stats-agent -l app.kubernetes.io/instance=stats-agent -f\n\n# Specific agent\nkubectl logs -n stats-agent -l app.kubernetes.io/component=synthesis -f\n</code></pre>"},{"location":"guides/kubernetes/#check-health","title":"Check Health","text":"<pre><code># Get pod status\nkubectl get pods -n stats-agent\n\n# Describe a pod\nkubectl describe pod -n stats-agent -l app.kubernetes.io/component=orchestration\n\n# Check endpoints\nkubectl get endpoints -n stats-agent\n</code></pre>"},{"location":"guides/kubernetes/#scaling","title":"Scaling","text":"<pre><code># Scale an agent\nkubectl scale deployment -n stats-agent stats-agent-stats-agent-team-synthesis --replicas=3\n\n# Or via Helm\nhelm upgrade stats-agent ./helm/stats-agent-team --set synthesis.replicaCount=3\n</code></pre>"},{"location":"guides/kubernetes/#helm-commands-reference","title":"Helm Commands Reference","text":"<pre><code># Lint chart\nmake helm-lint\n\n# Render templates locally\nmake helm-template\n\n# View release status\nhelm status stats-agent -n stats-agent\n\n# View release history\nhelm history stats-agent -n stats-agent\n\n# Rollback\nhelm rollback stats-agent 1 -n stats-agent\n</code></pre>"},{"location":"guides/kubernetes/#troubleshooting","title":"Troubleshooting","text":""},{"location":"guides/kubernetes/#pods-not-starting","title":"Pods not starting","text":"<pre><code># Check events\nkubectl get events -n stats-agent --sort-by='.lastTimestamp'\n\n# Check pod logs\nkubectl logs -n stats-agent &lt;pod-name&gt; --previous\n</code></pre>"},{"location":"guides/kubernetes/#service-discovery-issues","title":"Service discovery issues","text":"<p>Agents communicate via Kubernetes DNS. Verify: <pre><code># From any pod\nkubectl exec -it -n stats-agent &lt;pod-name&gt; -- wget -qO- http://stats-agent-stats-agent-team-research:8001/health\n</code></pre></p>"},{"location":"guides/kubernetes/#image-pull-errors","title":"Image pull errors","text":"<p>For Minikube: <pre><code># Ensure images are built in Minikube's Docker\neval $(minikube docker-env)\ndocker images | grep stats-agent\n</code></pre></p> <p>For EKS: <pre><code># Verify ECR login\naws ecr get-login-password | docker login --username AWS --password-stdin $REGISTRY\n\n# Check image pull secrets\nkubectl get secret ecr-creds -n stats-agent -o yaml\n</code></pre></p>"},{"location":"guides/llm-configuration/","title":"LLM Provider Configuration","text":"<p>This document describes the LLM provider configuration system for the Statistics Agent Team.</p>"},{"location":"guides/llm-configuration/#overview","title":"Overview","text":"<p>The system now supports configurable LLM providers, allowing you to choose between: - Gemini (Google) - Default - Claude (Anthropic) - Planned - OpenAI - Planned - Ollama (Local) - Planned</p>"},{"location":"guides/llm-configuration/#current-status","title":"Current Status","text":"<p>\u2705 Gemini: Fully supported and tested \u23f3 Claude: Configuration ready, ADK integration pending \u23f3 OpenAI: Configuration ready, ADK integration pending \u23f3 Ollama: Configuration ready, ADK integration pending</p>"},{"location":"guides/llm-configuration/#configuration","title":"Configuration","text":""},{"location":"guides/llm-configuration/#environment-variables","title":"Environment Variables","text":""},{"location":"guides/llm-configuration/#llm-provider-selection","title":"LLM Provider Selection","text":"<pre><code># Choose your LLM provider\nexport LLM_PROVIDER=gemini  # Options: gemini, claude, openai, ollama\n</code></pre>"},{"location":"guides/llm-configuration/#provider-specific-api-keys","title":"Provider-Specific API Keys","text":"<pre><code># For Gemini (default)\nexport GOOGLE_API_KEY=your-google-api-key\n# or\nexport GEMINI_API_KEY=your-google-api-key\n\n# For Claude (when supported)\nexport ANTHROPIC_API_KEY=your-anthropic-api-key\n# or\nexport CLAUDE_API_KEY=your-anthropic-api-key\n\n# For OpenAI (when supported)\nexport OPENAI_API_KEY=your-openai-api-key\n\n# For Ollama (when supported)\nexport OLLAMA_URL=http://localhost:11434\n</code></pre>"},{"location":"guides/llm-configuration/#model-selection","title":"Model Selection","text":"<pre><code># Override the default model for your chosen provider\nexport LLM_MODEL=gemini-2.0-flash-exp  # For Gemini\n# export LLM_MODEL=claude-3-5-sonnet-20241022  # For Claude\n# export LLM_MODEL=gpt-4  # For OpenAI\n# export LLM_MODEL=llama3.2  # For Ollama\n</code></pre>"},{"location":"guides/llm-configuration/#generic-options","title":"Generic Options","text":"<pre><code># Use generic API key (overrides provider-specific keys)\nexport LLM_API_KEY=your-api-key\n\n# Custom base URL (for Ollama or custom endpoints)\nexport LLM_BASE_URL=http://localhost:11434\n</code></pre>"},{"location":"guides/llm-configuration/#default-models-by-provider","title":"Default Models by Provider","text":"Provider Default Model Gemini <code>gemini-2.0-flash-exp</code> Claude <code>claude-3-5-sonnet-20241022</code> OpenAI <code>gpt-4</code> Ollama <code>llama3.2</code>"},{"location":"guides/llm-configuration/#architecture","title":"Architecture","text":""},{"location":"guides/llm-configuration/#model-factory","title":"Model Factory","text":"<p>The <code>pkg/llm/factory.go</code> file provides a centralized <code>ModelFactory</code> that: 1. Reads configuration from environment variables 2. Creates the appropriate LLM model based on <code>LLM_PROVIDER</code> 3. Returns a <code>model.LLM</code> interface compatible with Google ADK</p>"},{"location":"guides/llm-configuration/#integration-points","title":"Integration Points","text":"<p>All agents use the model factory: - Research Agent (<code>agents/research/main.go</code>) - Verification Agent (<code>agents/verification/main.go</code>) - Orchestration Agent (<code>agents/orchestration/main.go</code>)</p> <p>Example usage: <pre><code>// Create model using factory\nmodelFactory := llm.NewModelFactory(cfg)\nmodel, err := modelFactory.CreateModel(ctx)\nif err != nil {\n    return nil, fmt.Errorf(\"failed to create model: %w\", err)\n}\n\nlog.Printf(\"Agent: Using %s\", modelFactory.GetProviderInfo())\n</code></pre></p>"},{"location":"guides/llm-configuration/#examples","title":"Examples","text":""},{"location":"guides/llm-configuration/#using-gemini-default","title":"Using Gemini (Default)","text":"<pre><code>export GOOGLE_API_KEY=your-google-api-key\nmake run-all-eino\n</code></pre>"},{"location":"guides/llm-configuration/#using-claude-when-supported","title":"Using Claude (When Supported)","text":"<pre><code>export LLM_PROVIDER=claude\nexport ANTHROPIC_API_KEY=your-anthropic-api-key\nexport LLM_MODEL=claude-3-5-sonnet-20241022\nmake run-all-eino\n</code></pre>"},{"location":"guides/llm-configuration/#using-openai-when-supported","title":"Using OpenAI (When Supported)","text":"<pre><code>export LLM_PROVIDER=openai\nexport OPENAI_API_KEY=your-openai-api-key\nexport LLM_MODEL=gpt-4-turbo\nmake run-all-eino\n</code></pre>"},{"location":"guides/llm-configuration/#using-ollama-when-supported","title":"Using Ollama (When Supported)","text":"<pre><code>export LLM_PROVIDER=ollama\nexport OLLAMA_URL=http://localhost:11434\nexport LLM_MODEL=llama3.2\nmake run-all-eino\n</code></pre>"},{"location":"guides/llm-configuration/#future-development","title":"Future Development","text":""},{"location":"guides/llm-configuration/#claude-support","title":"Claude Support","text":"<p>Claude support requires: 1. ADK integration or custom HTTP client for Anthropic API 2. Adapter to convert Claude responses to ADK's <code>model.LLM</code> interface 3. Testing with Claude-specific prompt engineering</p>"},{"location":"guides/llm-configuration/#openai-support","title":"OpenAI Support","text":"<p>OpenAI support requires: 1. ADK integration or custom HTTP client for OpenAI API 2. Adapter to convert OpenAI responses to ADK's <code>model.LLM</code> interface 3. Testing with OpenAI-specific parameters</p>"},{"location":"guides/llm-configuration/#ollama-support","title":"Ollama Support","text":"<p>Ollama support requires: 1. Custom HTTP client for Ollama API 2. Adapter to convert Ollama responses to ADK's <code>model.LLM</code> interface 3. Support for different local models (llama, mistral, etc.) 4. Streaming support for better performance</p>"},{"location":"guides/llm-configuration/#configuration-precedence","title":"Configuration Precedence","text":"<p>The system uses the following precedence for API keys:</p> <ol> <li><code>LLM_API_KEY</code> (if set, overrides all provider-specific keys)</li> <li>Provider-specific key (<code>GEMINI_API_KEY</code>, <code>CLAUDE_API_KEY</code>, etc.)</li> <li>Alternative provider key (<code>GOOGLE_API_KEY</code> for Gemini, <code>ANTHROPIC_API_KEY</code> for Claude)</li> </ol>"},{"location":"guides/llm-configuration/#error-handling","title":"Error Handling","text":"<p>If you select an unsupported provider, the system will return a clear error message:</p> <pre><code>Error: claude support via ADK is not yet implemented - use gemini for now\nError: openai support via ADK is not yet implemented - use gemini for now\nError: ollama support via ADK is not yet implemented - use gemini for now\n</code></pre>"},{"location":"guides/llm-configuration/#contributing","title":"Contributing","text":"<p>To add support for a new LLM provider:</p> <ol> <li>Update <code>pkg/llm/factory.go</code>:</li> <li>Add a new case in <code>CreateModel()</code></li> <li> <p>Implement <code>create&lt;Provider&gt;Model()</code> method</p> </li> <li> <p>Update <code>pkg/config/config.go</code>:</p> </li> <li>Add provider-specific configuration fields</li> <li>Update <code>LoadConfig()</code> to read new environment variables</li> <li> <p>Add default model in <code>getDefaultModel()</code></p> </li> <li> <p>Update documentation:</p> </li> <li>Add provider to README.md</li> <li>Update this LLM_CONFIGURATION.md</li> <li> <p>Update .env.example</p> </li> <li> <p>Test thoroughly with the new provider</p> </li> </ol>"},{"location":"guides/llm-configuration/#see-also","title":"See Also","text":"<ul> <li>README.md - Main project documentation</li> <li>.env.example - Example environment configuration</li> <li>pkg/config/config.go - Configuration implementation</li> <li>pkg/llm/factory.go - Model factory implementation</li> </ul>"},{"location":"guides/llm-integration/","title":"LLM Integration &amp; Multi-Provider Support","text":""},{"location":"guides/llm-integration/#overview","title":"Overview","text":"<p>The Statistics Agent Team now features full LLM-based extraction with support for multiple LLM providers through a unified interface. The refactored codebase eliminates duplication and provides a clean, maintainable architecture.</p>"},{"location":"guides/llm-integration/#supported-llm-providers","title":"Supported LLM Providers","text":"<p>All agents support the following LLM providers:</p> Provider Model Configuration Integration Gemini (Default) <code>gemini-2.0-flash-exp</code> <code>GEMINI_API_KEY</code> or <code>GOOGLE_API_KEY</code> Google ADK (native) \u2705 Claude <code>claude-3-5-sonnet-20241022</code> <code>CLAUDE_API_KEY</code> or <code>ANTHROPIC_API_KEY</code> MetaLLM adapter \u2705 OpenAI <code>gpt-4o-mini</code> <code>OPENAI_API_KEY</code> MetaLLM adapter \u2705 Ollama <code>llama3.2</code> <code>OLLAMA_URL</code> (local) MetaLLM adapter \u2705"},{"location":"guides/llm-integration/#architecture","title":"Architecture","text":""},{"location":"guides/llm-integration/#multi-provider-support-via-metallm","title":"Multi-Provider Support via MetaLLM","text":"<p>The system uses two integration paths:</p> <ol> <li>Gemini: Direct via Google ADK (native)</li> <li>Claude, OpenAI, Ollama: Via <code>metallm</code> adapter (<code>pkg/llm/adapters/metallm_adapter.go</code>)</li> </ol> <p>The <code>metallm</code> adapter implements the ADK <code>model.LLM</code> interface, allowing seamless multi-provider support.</p> <p>Design Note: The <code>pkg/llm/adapters/</code> directory is self-contained and can be moved to the <code>metallm</code> repository as <code>pkg/adk/</code> for broader reuse.</p>"},{"location":"guides/llm-integration/#shared-base-agent-pkgagentbasego","title":"Shared Base Agent (<code>pkg/agent/base.go</code>)","text":"<p>The new <code>BaseAgent</code> struct provides common functionality for all LLM-powered agents:</p> <pre><code>type BaseAgent struct {\n    Cfg          *config.Config\n    Client       *http.Client\n    Model        model.LLM\n    ModelFactory *llm.ModelFactory\n}\n</code></pre> <p>Features: - \u2705 Unified LLM initialization across all agents - \u2705 Shared HTTP client with configurable timeouts - \u2705 Common URL fetching with size limits - \u2705 Centralized logging helpers - \u2705 Zero code duplication</p>"},{"location":"guides/llm-integration/#synthesis-agent-llm-based-extraction","title":"Synthesis Agent - LLM-Based Extraction","text":"<p>The Synthesis Agent now uses intelligent LLM analysis instead of regex patterns:</p> <p>Before (Regex-based): <pre><code>// Simple pattern matching for statistics\npatterns := []string{\n    `(\\d+\\.?\\d*)\\s*%`,                    // Percentages\n    `(\\d+\\.?\\d*)\\s*(million|billion)`,    // Large numbers\n}\n</code></pre></p> <p>After (LLM-based): <pre><code>// Use LLM to extract statistics with structured prompt\nprompt := fmt.Sprintf(`Analyze the following webpage content and extract numerical statistics related to \"%s\".\n\nFor each statistic found, provide:\n1. name: A brief descriptive name\n2. value: The numerical value (as a number, not string)\n3. unit: The unit of measurement\n4. excerpt: The verbatim excerpt from the text\n\nReturn valid JSON array...`, topic)\n\nresponse := sa.Model.GenerateContent(ctx, llmReq, false)\n</code></pre></p> <p>Benefits: - \u2705 Understands context and semantics - \u2705 Extracts complex statistics, not just simple patterns - \u2705 Handles various formats and units intelligently - \u2705 Returns structured JSON output - \u2705 Includes verbatim excerpts for verification</p>"},{"location":"guides/llm-integration/#verification-agent-refactored","title":"Verification Agent - Refactored","text":"<p>The Verification Agent now uses the shared base:</p> <p>Before: <pre><code>type VerificationAgent struct {\n    cfg      *config.Config\n    client   *http.Client\n    adkAgent agent.Agent\n}\n\nfunc (va *VerificationAgent) fetchSourceContent(...) {\n    // Custom HTTP fetching code\n}\n</code></pre></p> <p>After: <pre><code>type VerificationAgent struct {\n    *agentbase.BaseAgent\n    adkAgent agent.Agent\n}\n\n// Use shared method\nsourceContent, err := va.FetchURL(ctx, candidate.SourceURL, 1)\n</code></pre></p>"},{"location":"guides/llm-integration/#configuration","title":"Configuration","text":""},{"location":"guides/llm-integration/#environment-variables","title":"Environment Variables","text":"<pre><code># LLM Provider Selection\nLLM_PROVIDER=gemini  # Options: gemini, claude, openai, ollama\n\n# API Keys (provide based on chosen provider)\nGEMINI_API_KEY=your_gemini_key_here\nCLAUDE_API_KEY=your_claude_key_here\nOPENAI_API_KEY=your_openai_key_here\n\n# For Ollama (local LLM)\nOLLAMA_URL=http://localhost:11434\nOLLAMA_MODEL=llama3.2\n\n# Optional: Override default models\nLLM_MODEL=gemini-2.0-flash-exp  # Or claude-3-5-sonnet-20241022, gpt-4, etc.\n</code></pre>"},{"location":"guides/llm-integration/#provider-specific-setup","title":"Provider-Specific Setup","text":""},{"location":"guides/llm-integration/#gemini-default-recommended","title":"Gemini (Default - Recommended)","text":"<p><pre><code>export LLM_PROVIDER=gemini\nexport GEMINI_API_KEY=your_api_key_here\n</code></pre> - \u2705 Fast and cost-effective - \u2705 <code>gemini-2.0-flash-exp</code> optimized for speed - \u2705 Good JSON output reliability</p>"},{"location":"guides/llm-integration/#claude","title":"Claude","text":"<p><pre><code>export LLM_PROVIDER=claude\nexport CLAUDE_API_KEY=your_api_key_here\n</code></pre> - \u2705 Excellent reasoning capabilities - \u2705 Good for complex extraction tasks</p>"},{"location":"guides/llm-integration/#openai","title":"OpenAI","text":"<p><pre><code>export LLM_PROVIDER=openai\nexport OPENAI_API_KEY=your_api_key_here\n</code></pre> - \u2705 GPT-4 for highest quality - \u26a0\ufe0f Higher cost</p>"},{"location":"guides/llm-integration/#ollama-local","title":"Ollama (Local)","text":"<p><pre><code>export LLM_PROVIDER=ollama\nexport OLLAMA_URL=http://localhost:11434\nexport OLLAMA_MODEL=llama3.2\n</code></pre> - \u2705 Free, runs locally - \u2705 No API key required - \u26a0\ufe0f Slower, requires GPU</p>"},{"location":"guides/llm-integration/#code-organization","title":"Code Organization","text":""},{"location":"guides/llm-integration/#before-refactor","title":"Before Refactor","text":"<pre><code>agents/synthesis/main.go    - 373 lines (duplicated LLM init, HTTP client, fetching)\nagents/verification/main.go - 220 lines (duplicated LLM init, HTTP client, fetching)\n</code></pre>"},{"location":"guides/llm-integration/#after-refactor","title":"After Refactor","text":"<pre><code>pkg/agent/base.go           - 95 lines (shared functionality)\nagents/synthesis/main.go    - 360 lines (focused on synthesis logic)\nagents/verification/main.go - 185 lines (focused on verification logic)\n</code></pre> <p>Improvements: - \ud83c\udfaf Single source of truth for LLM initialization - \ud83c\udfaf Consistent HTTP client configuration - \ud83c\udfaf Shared URL fetching with proper error handling - \ud83c\udfaf Easier to add new agents - \ud83c\udfaf Easier to maintain and update</p>"},{"location":"guides/llm-integration/#testing","title":"Testing","text":""},{"location":"guides/llm-integration/#build-all-agents","title":"Build All Agents","text":"<pre><code>make build\n</code></pre>"},{"location":"guides/llm-integration/#run-individual-agents","title":"Run Individual Agents","text":"<pre><code># Synthesis Agent (LLM-based extraction)\nmake run-synthesis\n\n# Verification Agent\nmake run-verification\n\n# Full workflow\nmake run-all-eino\n</code></pre>"},{"location":"guides/llm-integration/#test-llm-extraction","title":"Test LLM Extraction","text":"<pre><code># Start synthesis agent\nPORT=8004 make run-synthesis\n\n# Test extraction\ncurl -X POST http://localhost:8004/synthesize \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"topic\": \"renewable energy\",\n    \"search_results\": [\n      {\n        \"url\": \"https://www.iea.org/reports/renewables-2023\",\n        \"title\": \"Renewables 2023\",\n        \"snippet\": \"Renewable capacity additions reach record levels\",\n        \"domain\": \"iea.org\"\n      }\n    ],\n    \"min_statistics\": 3,\n    \"max_statistics\": 10\n  }'\n</code></pre>"},{"location":"guides/llm-integration/#performance-considerations","title":"Performance Considerations","text":""},{"location":"guides/llm-integration/#llm-provider-speed-comparison","title":"LLM Provider Speed Comparison","text":"Provider Avg Latency Cost (1M tokens) Quality Gemini 2.0 Flash ~500ms $0.075 \u2b50\u2b50\u2b50\u2b50 Claude 3.5 Sonnet ~1.5s $3.00 \u2b50\u2b50\u2b50\u2b50\u2b50 GPT-4 ~2.0s $10.00 \u2b50\u2b50\u2b50\u2b50\u2b50 Ollama (local) ~3-5s Free \u2b50\u2b50\u2b50 <p>Recommendation: Use Gemini 2.0 Flash for production (best speed/cost/quality balance)</p>"},{"location":"guides/llm-integration/#token-usage","title":"Token Usage","text":"<p>Synthesis Agent: - Input: ~2000 tokens per webpage (8000 char limit) - Output: ~200 tokens (JSON array of statistics) - Total per page: ~2200 tokens</p> <p>Cost Example (Gemini): - 10 pages analyzed = 22,000 tokens - Cost: ~$0.00165 per request</p>"},{"location":"guides/llm-integration/#migration-guide","title":"Migration Guide","text":""},{"location":"guides/llm-integration/#for-existing-agents","title":"For Existing Agents","text":"<p>To add LLM support to a new agent:</p> <pre><code>import agentbase \"github.com/agentplexus/stats-agent-team/pkg/agent\"\n\ntype MyAgent struct {\n    *agentbase.BaseAgent\n    // ... other fields\n}\n\nfunc NewMyAgent(cfg *config.Config) (*MyAgent, error) {\n    base, err := agentbase.NewBaseAgent(cfg, 30) // 30 second timeout\n    if err != nil {\n        return nil, err\n    }\n\n    return &amp;MyAgent{\n        BaseAgent: base,\n    }, nil\n}\n\n// Use base.Model for LLM calls\n// Use base.FetchURL() for HTTP requests\n// Use base.LogInfo() for logging\n</code></pre>"},{"location":"guides/llm-integration/#troubleshooting","title":"Troubleshooting","text":""},{"location":"guides/llm-integration/#llm-errors","title":"LLM Errors","text":"<p>\"failed to create model\" - Check API key is set: <code>echo $GEMINI_API_KEY</code> - Verify provider is correct: <code>echo $LLM_PROVIDER</code></p> <p>\"LLM generation failed\" - Check API key has sufficient quota - Verify network connectivity - Try a different provider</p>"},{"location":"guides/llm-integration/#json-parsing-errors","title":"JSON Parsing Errors","text":"<p>The synthesis agent handles malformed JSON by: 1. Attempting direct JSON parsing 2. Removing markdown code fences (```json) 3. Extracting JSON from LLM response</p> <p>If still failing, check LLM output format.</p>"},{"location":"guides/llm-integration/#future-enhancements","title":"Future Enhancements","text":"<ul> <li>[ ] Support for Anthropic native API (in addition to ADK)</li> <li>[ ] Streaming responses for faster synthesis</li> <li>[ ] Caching of LLM responses to reduce costs</li> <li>[ ] Fine-tuned models for statistics extraction</li> <li>[ ] Batch processing for multiple URLs</li> </ul>"},{"location":"guides/llm-integration/#references","title":"References","text":"<ul> <li>Google ADK Documentation</li> <li>Gemini API</li> <li>Claude API</li> <li>OpenAI API</li> <li>Ollama</li> </ul>"},{"location":"guides/mcp-server/","title":"MCP Server for Statistics Agent Team","text":"<p>This document explains how to use the Statistics Agent Team as an MCP (Model Context Protocol) server with MCP clients like Claude Code.</p>"},{"location":"guides/mcp-server/#overview","title":"Overview","text":"<p>The MCP server exposes the Statistics Agent Team's functionality through the Model Context Protocol, allowing AI assistants like Claude to search for and verify statistics on any topic using a multi-agent system.</p>"},{"location":"guides/mcp-server/#architecture","title":"Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                  MCP Client                              \u2502\n\u2502              (e.g., Claude Code)                         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                       \u2502 MCP Protocol (stdio)\n                       \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502              MCP Server                                  \u2502\n\u2502          (stats-agent-team)                             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                       \u2502\n           \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n           \u2502                        \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Research Agent     \u2502    \u2502 Verification Agent     \u2502\n\u2502 (Gemini + Web)     \u2502\u2500\u2500\u2500\u25b6\u2502 (Validates sources)    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"guides/mcp-server/#features","title":"Features","text":"<p>The MCP server provides one tool:</p>"},{"location":"guides/mcp-server/#search_statistics","title":"<code>search_statistics</code>","text":"<p>Search for verified statistics on a given topic using a multi-agent system.</p> <p>Parameters: - <code>topic</code> (string, required): The topic to search statistics for - <code>min_verified_stats</code> (number, optional): Minimum number of verified statistics to return (default: 10) - <code>max_candidates</code> (number, optional): Maximum number of candidate statistics to gather (default: 30) - <code>reputable_only</code> (boolean, optional): Only use reputable sources (default: true)</p> <p>Returns: - Markdown-formatted results with verified statistics - JSON output with all statistics - Human-readable format with sources and verification details</p>"},{"location":"guides/mcp-server/#prerequisites","title":"Prerequisites","text":"<ol> <li>Go 1.21+ installed</li> <li>API Keys configured:</li> <li><code>GOOGLE_API_KEY</code> for Gemini (default LLM)</li> <li>Or other LLM provider keys as configured</li> <li>Research and Verification agents running:    <pre><code># Terminal 1: Research Agent\n./bin/research\n\n# Terminal 2: Verification Agent\n./bin/verification\n</code></pre></li> </ol>"},{"location":"guides/mcp-server/#building","title":"Building","text":"<pre><code># Build the MCP server\ngo build -o bin/mcp-server ./mcp/server/main.go\n\n# Or use make\nmake build-mcp\n</code></pre>"},{"location":"guides/mcp-server/#configuration","title":"Configuration","text":""},{"location":"guides/mcp-server/#environment-variables","title":"Environment Variables","text":"<p>The MCP server uses the same configuration as other agents:</p> <pre><code># LLM Configuration\nexport LLM_PROVIDER=gemini  # or claude, openai, ollama\nexport GOOGLE_API_KEY=your-api-key\n\n# Agent URLs (defaults shown)\nexport RESEARCH_AGENT_URL=http://localhost:8001\nexport VERIFICATION_AGENT_URL=http://localhost:8002\n</code></pre> <p>See LLM_CONFIGURATION.md for full configuration options.</p>"},{"location":"guides/mcp-server/#using-with-claude-code","title":"Using with Claude Code","text":""},{"location":"guides/mcp-server/#1-add-to-claude-code-configuration","title":"1. Add to Claude Code Configuration","text":"<p>Add the MCP server to your Claude Code MCP settings file:</p> <p>Location: <code>~/.config/claude-code/mcp-settings.json</code> (or similar)</p> <pre><code>{\n  \"mcpServers\": {\n    \"stats-agent-team\": {\n      \"command\": \"/path/to/stats-agent-team/bin/mcp-server\",\n      \"env\": {\n        \"GOOGLE_API_KEY\": \"your-google-api-key\",\n        \"RESEARCH_AGENT_URL\": \"http://localhost:8001\",\n        \"VERIFICATION_AGENT_URL\": \"http://localhost:8002\"\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"guides/mcp-server/#2-start-required-agents","title":"2. Start Required Agents","text":"<p>Before using the MCP server, start the research and verification agents:</p> <pre><code># Terminal 1: Research Agent\ncd /path/to/stats-agent-team\nexport GOOGLE_API_KEY=your-key\n./bin/research\n\n# Terminal 2: Verification Agent\ncd /path/to/stats-agent-team\nexport GOOGLE_API_KEY=your-key\n./bin/verification\n</code></pre>"},{"location":"guides/mcp-server/#3-use-in-claude-code","title":"3. Use in Claude Code","text":"<p>The MCP server will automatically start when Claude Code launches. You can now use it by asking Claude to search for statistics:</p> <p>Example prompts: - \"Search for statistics about climate change\" - \"Find verified statistics on AI adoption rates\" - \"Get statistics about cybersecurity threats in 2024\"</p> <p>Claude will use the <code>search_statistics</code> tool to find and verify statistics from reputable sources.</p>"},{"location":"guides/mcp-server/#example-usage","title":"Example Usage","text":""},{"location":"guides/mcp-server/#request","title":"Request","text":"<pre><code>{\n  \"topic\": \"climate change\",\n  \"min_verified_stats\": 5,\n  \"max_candidates\": 20,\n  \"reputable_only\": true\n}\n</code></pre>"},{"location":"guides/mcp-server/#response","title":"Response","text":"<p>The tool returns formatted markdown output:</p> <pre><code># Statistics Search Results\n\n**Topic:** climate change\n**Verified:** 5 statistics\n**Failed:** 3 statistics\n**Total Candidates:** 20\n**Timestamp:** 2025-12-13 10:30:00\n\n## JSON Output\n\n```json\n[\n  {\n    \"name\": \"Global temperature increase since pre-industrial times\",\n    \"value\": 1.1,\n    \"unit\": \"\u00b0C\",\n    \"source\": \"IPCC Sixth Assessment Report\",\n    \"source_url\": \"https://www.ipcc.ch/...\",\n    \"excerpt\": \"Global surface temperature has increased by approximately 1.1\u00b0C...\",\n    \"verified\": true,\n    \"date_found\": \"2025-12-13T10:30:00Z\"\n  }\n]\n</code></pre>"},{"location":"guides/mcp-server/#verified-statistics","title":"Verified Statistics","text":""},{"location":"guides/mcp-server/#1-global-temperature-increase-since-pre-industrial-times","title":"1. Global temperature increase since pre-industrial times","text":"<ul> <li>Value: 1.1 \u00b0C</li> <li>Source: IPCC Sixth Assessment Report</li> <li>URL: https://www.ipcc.ch/...</li> <li>Excerpt: \"Global surface temperature has increased by approximately 1.1\u00b0C...\"</li> <li>Verified: \u2713</li> <li>Date Found: 2025-12-13 <pre><code>## Troubleshooting\n\n### MCP Server Not Starting\n\n1. **Check logs:** The MCP server logs to stderr, which Claude Code captures\n2. **Verify agents are running:** Research and verification agents must be running\n3. **Check API keys:** Ensure `GOOGLE_API_KEY` or other LLM provider keys are set\n\n### No Statistics Found\n\n1. **Check research agent:** Ensure it's running on port 8001\n2. **Check verification agent:** Ensure it's running on port 8002\n3. **Review topic:** Try a more specific or different topic\n\n### Connection Errors\n\n1. **Check agent URLs:** Verify `RESEARCH_AGENT_URL` and `VERIFICATION_AGENT_URL` are correct\n2. **Check network:** Ensure agents can communicate with each other\n3. **Check ports:** Ensure ports 8001 and 8002 are not blocked\n\n## Development\n\n### Testing the MCP Server\n\nYou can test the MCP server manually using the MCP Inspector or by writing a simple client:\n\n```bash\n# Run the server (stdio mode)\nexport GOOGLE_API_KEY=your-key\n./bin/mcp-server\n\n# The server expects JSON-RPC messages on stdin\n# See https://modelcontextprotocol.io for protocol details\n</code></pre></li> </ul>"},{"location":"guides/mcp-server/#logs","title":"Logs","text":"<p>The MCP server logs to stderr: - <code>[MCP] Server running on stdio transport</code> - <code>[MCP] Searching for statistics on topic: ...</code> - <code>[MCP] Found N verified statistics (from M candidates)</code></p>"},{"location":"guides/mcp-server/#architecture-details","title":"Architecture Details","text":""},{"location":"guides/mcp-server/#communication-flow","title":"Communication Flow","text":"<ol> <li>Claude Code \u2192 MCP Server: Claude sends <code>tools/call</code> request via stdio</li> <li>MCP Server \u2192 Eino Orchestrator: Orchestrator coordinates workflow</li> <li>Orchestrator \u2192 Research Agent: HTTP POST to /research endpoint</li> <li>Orchestrator \u2192 Verification Agent: HTTP POST to /verify endpoint</li> <li>MCP Server \u2192 Claude Code: Returns formatted results via stdio</li> </ol>"},{"location":"guides/mcp-server/#error-handling","title":"Error Handling","text":"<ul> <li>Tool errors: Returned with <code>isError: true</code> and error message in content</li> <li>Network errors: Logged and returned as tool errors</li> <li>Validation errors: Topic validation happens before orchestration</li> </ul>"},{"location":"guides/mcp-server/#see-also","title":"See Also","text":"<ul> <li>README.md - Main project documentation</li> <li>LLM_CONFIGURATION.md - LLM provider configuration</li> <li>MCP Protocol - Official MCP documentation</li> <li>Claude Code - Claude Code documentation</li> </ul>"},{"location":"guides/mcp-server/#license","title":"License","text":"<p>MIT - See LICENSE for details</p>"},{"location":"guides/multi-llm-support/","title":"Multi-LLM Provider Support Implementation","text":""},{"location":"guides/multi-llm-support/#summary","title":"Summary","text":"<p>The Statistics Agent Team now supports 4 LLM providers through a unified interface, allowing you to choose the best model for your use case.</p>"},{"location":"guides/multi-llm-support/#supported-providers","title":"Supported Providers \u2705","text":"Provider Status Default Model Integration Method Gemini \u2705 Working <code>gemini-2.0-flash-exp</code> Google ADK (native) Claude \u2705 Working <code>claude-3-5-sonnet-20241022</code> OmniLLM adapter OpenAI \u2705 Working <code>gpt-4o-mini</code> OmniLLM adapter Ollama \u2705 Working <code>llama3.2</code> OmniLLM adapter"},{"location":"guides/multi-llm-support/#quick-start","title":"Quick Start","text":""},{"location":"guides/multi-llm-support/#using-openai-your-current-setup","title":"Using OpenAI (Your Current Setup)","text":"<pre><code>export LLM_PROVIDER=openai\nexport OPENAI_API_KEY=your_key_here\nexport SEARCH_PROVIDER=serper\nexport SERPER_API_KEY=your_key_here\n\nmake run-all-eino\n</code></pre>"},{"location":"guides/multi-llm-support/#using-claude","title":"Using Claude","text":"<pre><code>export LLM_PROVIDER=claude\nexport CLAUDE_API_KEY=your_key_here\n# or\nexport ANTHROPIC_API_KEY=your_key_here\n\nmake run-all-eino\n</code></pre>"},{"location":"guides/multi-llm-support/#using-gemini-recommended-for-costspeed","title":"Using Gemini (Recommended for cost/speed)","text":"<pre><code>export LLM_PROVIDER=gemini\nexport GEMINI_API_KEY=your_key_here\n# or\nexport GOOGLE_API_KEY=your_key_here\n\nmake run-all-eino\n</code></pre>"},{"location":"guides/multi-llm-support/#using-ollama-free-local","title":"Using Ollama (Free, Local)","text":"<pre><code># Start Ollama first: ollama serve\nexport LLM_PROVIDER=ollama\nexport OLLAMA_URL=http://localhost:11434\nexport LLM_MODEL=llama3.2\n\nmake run-all-eino\n</code></pre>"},{"location":"guides/multi-llm-support/#implementation-details","title":"Implementation Details","text":""},{"location":"guides/multi-llm-support/#architecture","title":"Architecture","text":"<p>The system uses two integration paths:</p> <ol> <li>Gemini \u2192 Direct via Google ADK</li> <li>Uses <code>google.golang.org/adk/model/gemini</code></li> <li> <p>Native ADK support, most efficient</p> </li> <li> <p>Claude, OpenAI, Ollama \u2192 Via OmniLLM adapter</p> </li> <li>Uses <code>github.com/agentplexus/omnillm</code> v0.8.0</li> <li>Adapter: <code>pkg/llm/adapters/omnillm_adapter.go</code></li> <li>Implements ADK's <code>model.LLM</code> interface</li> </ol>"},{"location":"guides/multi-llm-support/#code-organization","title":"Code Organization","text":"<pre><code>pkg/llm/\n\u251c\u2500\u2500 factory.go              # LLM factory with multi-provider support\n\u2514\u2500\u2500 adapters/\n    \u2514\u2500\u2500 omnillm_adapter.go  # ADK interface adapter for OmniLLM\n                            # (Self-contained, can move to OmniLLM repo)\n</code></pre>"},{"location":"guides/multi-llm-support/#how-it-works","title":"How It Works","text":"<pre><code>// Factory creates appropriate LLM based on provider\nfunc (mf *ModelFactory) CreateModel(ctx context.Context) (model.LLM, error) {\n    switch mf.cfg.LLMProvider {\n    case \"gemini\":\n        return mf.createGeminiModel(ctx)  // Native ADK\n    case \"claude\":\n        return adapters.NewMetaLLMAdapter(\"anthropic\", apiKey, model)\n    case \"openai\":\n        return adapters.NewMetaLLMAdapter(\"openai\", apiKey, model)\n    case \"ollama\":\n        return adapters.NewMetaLLMAdapter(\"ollama\", \"\", model)\n    }\n}\n</code></pre>"},{"location":"guides/multi-llm-support/#metallm-adapter","title":"MetaLLM Adapter","text":"<p>The adapter (<code>pkg/llm/adapters/metallm_adapter.go</code>) is self-contained and portable:</p> <pre><code>type MetaLLMAdapter struct {\n    client *metallm.ChatClient\n    model  string\n}\n\n// Implements google.golang.org/adk/model.LLM interface\nfunc (m *MetaLLMAdapter) GenerateContent(ctx context.Context,\n    req *model.LLMRequest, stream bool) iter.Seq2[*model.LLMResponse, error]\n</code></pre> <p>Design Intent: This entire <code>adapters/</code> directory can be moved to <code>metallm</code> as <code>pkg/adk/</code> for broader ecosystem use.</p>"},{"location":"guides/multi-llm-support/#provider-comparison","title":"Provider Comparison","text":""},{"location":"guides/multi-llm-support/#performance","title":"Performance","text":"Provider Avg Latency Cost (1M input tokens) Best For Gemini 2.0 Flash ~500ms $0.075 Production (best balance) Claude 3.5 Sonnet ~1.5s $3.00 Complex reasoning GPT-4o-mini ~1.0s $0.15 Good balance Ollama (local) ~3-5s Free Privacy, no API costs"},{"location":"guides/multi-llm-support/#quality-for-statistics-extraction","title":"Quality for Statistics Extraction","text":"Provider JSON Output Context Understanding Accuracy Claude \u2b50\u2b50\u2b50\u2b50\u2b50 \u2b50\u2b50\u2b50\u2b50\u2b50 Excellent GPT-4o-mini \u2b50\u2b50\u2b50\u2b50 \u2b50\u2b50\u2b50\u2b50 Very Good Gemini Flash \u2b50\u2b50\u2b50\u2b50 \u2b50\u2b50\u2b50\u2b50 Very Good Ollama (llama3.2) \u2b50\u2b50\u2b50 \u2b50\u2b50\u2b50 Good"},{"location":"guides/multi-llm-support/#configuration-options","title":"Configuration Options","text":""},{"location":"guides/multi-llm-support/#environment-variables","title":"Environment Variables","text":"<pre><code># Provider selection (required)\nLLM_PROVIDER=openai  # Options: gemini, claude, openai, ollama\n\n# API Keys (provider-specific)\nGEMINI_API_KEY=sk-...       # For Gemini\nCLAUDE_API_KEY=sk-ant-...   # For Claude\nOPENAI_API_KEY=sk-...       # For OpenAI\n\n# Optional: Override default models\nLLM_MODEL=gpt-4o            # Use GPT-4o instead of mini\nLLM_MODEL=claude-3-opus-20240229  # Use Opus instead of Sonnet\n\n# Ollama specific\nOLLAMA_URL=http://localhost:11434\nLLM_MODEL=llama3.2\n</code></pre>"},{"location":"guides/multi-llm-support/#model-recommendations","title":"Model Recommendations","text":"<p>For Production (Speed + Cost): <pre><code>LLM_PROVIDER=gemini\nLLM_MODEL=gemini-2.0-flash-exp\n</code></pre></p> <p>For Best Quality: <pre><code>LLM_PROVIDER=claude\nLLM_MODEL=claude-3-5-sonnet-20241022\n</code></pre></p> <p>For Good Balance: <pre><code>LLM_PROVIDER=openai\nLLM_MODEL=gpt-4o-mini\n</code></pre></p> <p>For Privacy/Free: <pre><code>LLM_PROVIDER=ollama\nLLM_MODEL=llama3.2\n</code></pre></p>"},{"location":"guides/multi-llm-support/#testing-different-providers","title":"Testing Different Providers","text":"<p>Test each provider with a simple request:</p> <pre><code># Test OpenAI\nexport LLM_PROVIDER=openai\nexport OPENAI_API_KEY=your_key\nmake run-synthesis\n\n# In another terminal\ncurl -X POST http://localhost:8004/synthesize \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"topic\": \"renewable energy\",\n    \"search_results\": [\n      {\"url\": \"https://www.iea.org/reports/renewables-2023\",\n       \"title\": \"Renewables 2023\",\n       \"domain\": \"iea.org\"}\n    ],\n    \"min_statistics\": 3\n  }'\n</code></pre>"},{"location":"guides/multi-llm-support/#migration-from-openai-to-gemini","title":"Migration from OpenAI to Gemini","text":"<p>If you want to switch from OpenAI to Gemini (for cost savings):</p> <pre><code># 1. Get Gemini API key from https://aistudio.google.com/apikey\n\n# 2. Update environment\nexport LLM_PROVIDER=gemini\nexport GEMINI_API_KEY=your_gemini_key\n# Remove or unset OPENAI_API_KEY\n\n# 3. Restart agents\nmake run-all-eino\n</code></pre> <p>Cost Savings: - OpenAI GPT-4o-mini: $0.15/1M input tokens - Gemini 2.0 Flash: $0.075/1M input tokens - 50% cost reduction</p>"},{"location":"guides/multi-llm-support/#troubleshooting","title":"Troubleshooting","text":""},{"location":"guides/multi-llm-support/#openai-support-via-adk-is-not-yet-implemented","title":"\"openai support via ADK is not yet implemented\"","text":"<p>Issue: You have <code>LLM_PROVIDER=openai</code> but the old code is running.</p> <p>Fix: Rebuild the agents: <pre><code>make build\nmake run-all-eino\n</code></pre></p>"},{"location":"guides/multi-llm-support/#api-key-not-set","title":"\"API key not set\"","text":"<p>Issue: Missing API key for selected provider.</p> <p>Fix: Check your environment: <pre><code># For OpenAI\necho $OPENAI_API_KEY\n\n# For Claude\necho $CLAUDE_API_KEY\n\n# For Gemini\necho $GEMINI_API_KEY\n</code></pre></p> <p>Set the appropriate key for your provider.</p>"},{"location":"guides/multi-llm-support/#ollama-connection-error","title":"Ollama Connection Error","text":"<p>Issue: Can't connect to Ollama.</p> <p>Fix: <pre><code># Start Ollama\nollama serve\n\n# Pull the model\nollama pull llama3.2\n\n# Set environment\nexport OLLAMA_URL=http://localhost:11434\nexport LLM_MODEL=llama3.2\n</code></pre></p>"},{"location":"guides/multi-llm-support/#future-enhancements","title":"Future Enhancements","text":""},{"location":"guides/multi-llm-support/#planned","title":"Planned","text":"<ul> <li>[ ] Move <code>pkg/llm/adapters/</code> to <code>metallm</code> as <code>pkg/adk/</code></li> <li>[ ] Add streaming support for faster responses</li> <li>[ ] Add response caching to reduce API costs</li> <li>[ ] Support for additional metallm providers (AWS Bedrock, Azure, etc.)</li> </ul>"},{"location":"guides/multi-llm-support/#possible","title":"Possible","text":"<ul> <li>[ ] Automatic failover between providers</li> <li>[ ] Cost tracking and budgets</li> <li>[ ] A/B testing between providers</li> <li>[ ] Provider-specific optimizations</li> </ul>"},{"location":"guides/multi-llm-support/#related-documentation","title":"Related Documentation","text":"<ul> <li>LLM_INTEGRATION.md - Complete LLM integration guide</li> <li>4_AGENT_ARCHITECTURE.md - 4-agent architecture details</li> <li>OmniLLM repository - Multi-provider LLM library</li> </ul>"},{"location":"guides/multi-llm-support/#credits","title":"Credits","text":"<ul> <li>Google ADK: Native Gemini support</li> <li>OmniLLM: Multi-provider abstraction layer</li> <li>Integration design: Unified adapter pattern for portability</li> </ul>"},{"location":"guides/search-integration/","title":"Search Integration Guide","text":"<p>This document explains how the Statistics Agent Team integrates with web search APIs to find real statistics.</p>"},{"location":"guides/search-integration/#overview","title":"Overview","text":"<p>The research agent uses the agentplexus/omniserp library (aka OmniSerp) to perform web searches across multiple search engine providers. This enables the system to find real, verifiable statistics from reputable sources on the web.</p>"},{"location":"guides/search-integration/#supported-search-providers","title":"Supported Search Providers","text":"Provider Website Features Cost Serper serper.dev Fast, affordable, all search types $50/month for 5,000 searches SerpAPI serpapi.com Comprehensive, reliable $50/month for 5,000 searches <p>Both providers offer: - Real-time Google search results - Structured JSON responses - High reliability and speed - Free trial credits for testing</p>"},{"location":"guides/search-integration/#configuration","title":"Configuration","text":""},{"location":"guides/search-integration/#1-get-an-api-key","title":"1. Get an API Key","text":"<p>For Serper (Recommended): 1. Visit https://serper.dev 2. Sign up for an account 3. Get your API key from https://serper.dev/api-key 4. Free trial: 2,500 searches</p> <p>For SerpAPI: 1. Visit https://serpapi.com 2. Sign up for an account 3. Get your API key from dashboard 4. Free trial: 100 searches/month</p>"},{"location":"guides/search-integration/#2-set-environment-variables","title":"2. Set Environment Variables","text":"<pre><code># Option 1: Serper (recommended)\nexport SEARCH_PROVIDER=serper\nexport SERPER_API_KEY=your-serper-api-key-here\n\n# Option 2: SerpAPI\nexport SEARCH_PROVIDER=serpapi\nexport SERPAPI_API_KEY=your-serpapi-key-here\n</code></pre> <p>Or add to your <code>.env</code> file:</p> <pre><code># Copy from example\ncp .env.example .env\n\n# Edit .env with your API key\nSEARCH_PROVIDER=serper\nSERPER_API_KEY=your-serper-api-key-here\n</code></pre>"},{"location":"guides/search-integration/#3-verify-configuration","title":"3. Verify Configuration","text":"<p>The research agent will log which search provider it's using:</p> <pre><code>Research Agent: Using serper search provider\n</code></pre> <p>If no search API is configured, you'll see:</p> <pre><code>Warning: Search service not available: SERPER_API_KEY is required when using serper provider\nResearch agent will use mock data. Set SERPER_API_KEY or SERPAPI_API_KEY to enable real search.\n</code></pre>"},{"location":"guides/search-integration/#how-it-works","title":"How It Works","text":""},{"location":"guides/search-integration/#architecture","title":"Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502          Research Agent (ADK)               \u2502\n\u2502                                             \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u2502\n\u2502  \u2502   Search Service                   \u2502    \u2502\n\u2502  \u2502   (pkg/search/service.go)          \u2502    \u2502\n\u2502  \u2502                                    \u2502    \u2502\n\u2502  \u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u2502    \u2502\n\u2502  \u2502   \u2502  MetaSerp Library        \u2502    \u2502    \u2502\n\u2502  \u2502   \u2502  - Serper Client         \u2502    \u2502    \u2502\n\u2502  \u2502   \u2502  - SerpAPI Client        \u2502    \u2502    \u2502\n\u2502  \u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502    \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502\n\u2502                                             \u2502\n\u2502  LLM analyzes search results to extract    \u2502\n\u2502  statistics, sources, and excerpts         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                    \u2502\n                    \u25bc\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2502  Search API          \u2502\n        \u2502  (Serper/SerpAPI)    \u2502\n        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                    \u2502\n                    \u25bc\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2502  Google Search       \u2502\n        \u2502  Results             \u2502\n        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"guides/search-integration/#search-flow","title":"Search Flow","text":"<ol> <li>User requests statistics on a topic (e.g., \"climate change\")</li> <li>Research agent calls search service</li> <li>Search service uses MetaSerp to query Serper/SerpAPI</li> <li>Search API returns Google search results</li> <li>Research agent analyzes results (currently extracts metadata, will use LLM in future)</li> <li>Candidate statistics are created with:</li> <li>Source URLs for verification</li> <li>Snippets containing potential statistics</li> <li>Source attribution</li> <li>Verification agent fetches actual URLs to verify excerpts</li> </ol>"},{"location":"guides/search-integration/#current-implementation","title":"Current Implementation","text":"<p>The current implementation: - \u2705 Performs real web searches via Serper/SerpAPI - \u2705 Returns actual URLs and snippets from search results - \u2705 Gracefully falls back to mock data if search unavailable - \u26a0\ufe0f TODO: Use LLM to analyze search result content and extract actual statistics</p>"},{"location":"guides/search-integration/#future-enhancement","title":"Future Enhancement","text":"<p>The next step is to use the LLM to: 1. Fetch full page content from search result URLs 2. Analyze content to find numerical statistics 3. Extract exact values, units, and context 4. Identify reputable sources (academic, government, research) 5. Create high-quality candidate statistics</p>"},{"location":"guides/search-integration/#usage-examples","title":"Usage Examples","text":""},{"location":"guides/search-integration/#basic-search","title":"Basic Search","text":"<pre><code># Start research agent with search configured\nexport SERPER_API_KEY=your-key-here\nmake run-research\n</code></pre>"},{"location":"guides/search-integration/#via-http-api","title":"Via HTTP API","text":"<pre><code>curl -X POST http://localhost:8001/research \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"topic\": \"renewable energy adoption\",\n    \"min_statistics\": 5,\n    \"max_statistics\": 10,\n    \"reputable_only\": true\n  }'\n</code></pre> <p>Response will include real search results:</p> <pre><code>{\n  \"topic\": \"renewable energy adoption\",\n  \"candidates\": [\n    {\n      \"name\": \"Statistic about renewable energy adoption from iea.org\",\n      \"value\": 10,\n      \"unit\": \"%\",\n      \"source\": \"Iea.org\",\n      \"source_url\": \"https://www.iea.org/reports/renewables-2023\",\n      \"excerpt\": \"Renewable energy capacity is set to expand by 50% between 2023 and 2028...\"\n    }\n  ],\n  \"timestamp\": \"2025-12-13T10:30:00Z\"\n}\n</code></pre>"},{"location":"guides/search-integration/#via-docker","title":"Via Docker","text":"<pre><code># Add to .env file\nSEARCH_PROVIDER=serper\nSERPER_API_KEY=your-key-here\n\n# Start with Docker\ndocker-compose up -d\n\n# Check logs to verify search is working\ndocker-compose logs -f | grep \"search provider\"\n</code></pre>"},{"location":"guides/search-integration/#monitoring-and-debugging","title":"Monitoring and Debugging","text":""},{"location":"guides/search-integration/#check-search-service-status","title":"Check Search Service Status","text":"<p>Look for these log messages:</p> <p>Success: <pre><code>Research Agent: Using serper search provider\nResearch Agent: Found 10 search results\n</code></pre></p> <p>Fallback to Mock Data: <pre><code>Warning: Search service not available: SERPER_API_KEY is required\nResearch agent will use mock data\nUsing mock data (search service not configured)\n</code></pre></p> <p>Search Error: <pre><code>Search failed, falling back to mock data: search failed: API error\n</code></pre></p>"},{"location":"guides/search-integration/#common-issues","title":"Common Issues","text":"<p>Issue: \"SERPER_API_KEY is required\" - Solution: Set the appropriate API key environment variable - Verify: <code>echo $SERPER_API_KEY</code></p> <p>Issue: Search returns no results - Check API key is valid - Verify API quota hasn't been exceeded - Check serper.dev or serpapi.com dashboard for usage</p> <p>Issue: \"unsupported search provider\" - Solution: Use <code>SEARCH_PROVIDER=serper</code> or <code>SEARCH_PROVIDER=serpapi</code> - Default is <code>serper</code> if not specified</p>"},{"location":"guides/search-integration/#api-costs","title":"API Costs","text":""},{"location":"guides/search-integration/#serper-pricing","title":"Serper Pricing","text":"<ul> <li>Free Plan: 2,500 searches (trial)</li> <li>Hobby: $50/month for 5,000 searches ($0.01 per search)</li> <li>Startup: $200/month for 25,000 searches ($0.008 per search)</li> </ul>"},{"location":"guides/search-integration/#serpapi-pricing","title":"SerpAPI Pricing","text":"<ul> <li>Free: 100 searches/month</li> <li>Developer: $50/month for 5,000 searches</li> <li>Production: $250/month for 30,000 searches</li> </ul>"},{"location":"guides/search-integration/#cost-optimization","title":"Cost Optimization","text":"<p>The research agent is designed to be cost-effective: - Configurable number of search results per query - Graceful fallback to mock data on errors - Single search per research request - Results cached within the session</p> <p>Estimated costs for typical usage: - 100 statistics queries/day = 100 searches = ~$1/month (Serper) - 1,000 statistics queries/day = 1,000 searches = ~$10/month (Serper)</p>"},{"location":"guides/search-integration/#implementation-details","title":"Implementation Details","text":""},{"location":"guides/search-integration/#code-structure","title":"Code Structure","text":"<pre><code>pkg/search/\n  \u2514\u2500\u2500 service.go          # Search service wrapper\n\nagents/research/\n  \u2514\u2500\u2500 main.go            # Research agent with search integration\n      \u251c\u2500\u2500 searchForStatistics()    # Uses search service\n      \u251c\u2500\u2500 extractSource()          # Helper to parse URLs\n      \u2514\u2500\u2500 generateMockCandidates() # Fallback data\n</code></pre>"},{"location":"guides/search-integration/#key-functions","title":"Key Functions","text":"<p>pkg/search/service.go: - <code>NewService(cfg)</code> - Creates search service with provider - <code>Search(ctx, query, num)</code> - Basic web search - <code>SearchForStatistics(ctx, topic, num)</code> - Optimized for statistics</p> <p>agents/research/main.go: - <code>searchForStatistics()</code> - Performs search and creates candidates - Graceful fallback on errors - LLM will be integrated for content analysis</p>"},{"location":"guides/search-integration/#switching-providers","title":"Switching Providers","text":"<p>To switch from Serper to SerpAPI (or vice versa):</p> <pre><code># Stop current service\nmake stop # or docker-compose down\n\n# Update environment\nexport SEARCH_PROVIDER=serpapi\nexport SERPAPI_API_KEY=your-serpapi-key\n\n# Restart\nmake run-research # or docker-compose up -d\n</code></pre> <p>The change takes effect immediately on restart.</p>"},{"location":"guides/search-integration/#next-steps","title":"Next Steps","text":"<p>Future enhancements planned:</p> <ol> <li>LLM Content Analysis - Use ADK agent to analyze search result pages</li> <li>Source Ranking - Prioritize reputable sources (academic, government)</li> <li>Statistics Extraction - Parse numerical values and context from text</li> <li>Caching - Cache search results to reduce API calls</li> <li>Rate Limiting - Intelligent request throttling</li> <li>Multiple Search Types - News, scholar, images for different use cases</li> </ol>"},{"location":"guides/search-integration/#references","title":"References","text":"<ul> <li>OmniSerp Library</li> <li>Serper API Docs</li> <li>SerpAPI Docs</li> <li>Google ADK Docs</li> </ul>"},{"location":"guides/search-integration/#support","title":"Support","text":"<p>If you encounter issues with search integration:</p> <ol> <li>Check the Troubleshooting section</li> <li>Review search provider dashboard for errors</li> <li>Enable debug logging: <code>export LOG_LEVEL=debug</code></li> <li>Open an issue with logs and error messages</li> </ol>"},{"location":"operations/chart-testing/","title":"Helm Chart Testing Guide","text":"<p>This guide covers testing the Stats Agent Team Helm chart for correctness, security, and Kubernetes compatibility.</p>"},{"location":"operations/chart-testing/#testing-layers","title":"Testing Layers","text":"<p>The chart testing strategy follows industry best practices with multiple validation layers:</p> Layer Tool Purpose CI Stage Secrets <code>gitleaks</code> Hardcoded secret detection Always Secrets <code>trivy</code> (secret scan) Secret pattern detection Always Config <code>trivy</code> (config scan) IaC misconfiguration Always Vulnerabilities <code>trivy</code> (image scan) Container CVE detection Always Syntax <code>helm lint</code> YAML/template validation Always Unit Tests <code>helm-unittest</code> Template logic verification Always Schema <code>kubeconform</code> K8s API compatibility Always Best Practices <code>Polaris</code> K8s security compliance Always Go Validation <code>go test</code> Values struct validation Always Integration <code>Kind</code> + <code>helm install</code> Real cluster deployment On merge"},{"location":"operations/chart-testing/#quick-start","title":"Quick Start","text":"<pre><code># Run all chart tests locally\nmake helm-test-all\n\n# Quick test (lint + unittest only)\nmake helm-test\n\n# Individual tests\nmake helm-lint\nmake helm-unittest\nmake helm-kubeconform\nmake helm-polaris\n\n# Security scanning (requires gitleaks and trivy installed)\ngitleaks detect --config .gitleaks.toml --source . -v\ntrivy config ./helm/stats-agent-team\ntrivy fs --scanners secret .\n</code></pre>"},{"location":"operations/chart-testing/#tool-installation","title":"Tool Installation","text":""},{"location":"operations/chart-testing/#required","title":"Required","text":"<pre><code># Helm (required)\nbrew install helm\n\n# helm-unittest plugin (auto-installed by Makefile)\nhelm plugin install https://github.com/helm-unittest/helm-unittest.git\n</code></pre>"},{"location":"operations/chart-testing/#optional-for-full-test-suite","title":"Optional (for full test suite)","text":"<pre><code># kubeconform - K8s schema validation\nbrew install kubeconform\n\n# Polaris - security best practices\nbrew install FairwindsOps/tap/polaris\n\n# chart-testing - official Helm testing tool\nbrew install chart-testing\n</code></pre>"},{"location":"operations/chart-testing/#test-types","title":"Test Types","text":""},{"location":"operations/chart-testing/#1-security-scanning","title":"1. Security Scanning","text":""},{"location":"operations/chart-testing/#gitleaks-secret-detection","title":"Gitleaks (Secret Detection)","text":"<p>Scans git history and current files for hardcoded secrets:</p> <pre><code># Install gitleaks\nbrew install gitleaks\n\n# Run locally\ngitleaks detect --config .gitleaks.toml --source . -v\n\n# Scan git history\ngitleaks detect --config .gitleaks.toml --source . --log-opts=\"--all\"\n</code></pre> <p>Configuration: <code>.gitleaks.toml</code></p>"},{"location":"operations/chart-testing/#trivy-multi-scanner","title":"Trivy (Multi-Scanner)","text":"<p>Comprehensive security scanner for configs, secrets, and container vulnerabilities:</p> <pre><code># Install trivy\nbrew install trivy\n\n# Scan Helm chart for misconfigurations\ntrivy config ./helm/stats-agent-team\n\n# Scan for secrets in filesystem\ntrivy fs --scanners secret .\n\n# Scan container image for vulnerabilities\ndocker build --build-arg AGENT=research -t stats-agent-research:scan -f Dockerfile.agent .\ntrivy image stats-agent-research:scan\n\n# Generate SBOM (Software Bill of Materials)\ntrivy image --format cyclonedx -o sbom.json stats-agent-research:scan\n</code></pre> <p>Configuration: <code>.trivyignore</code> (for ignoring specific CVEs or rules)</p>"},{"location":"operations/chart-testing/#3-helm-lint","title":"3. Helm Lint","text":"<p>Basic syntax and structure validation:</p> <pre><code>make helm-lint\n\n# Or directly:\nhelm lint ./helm/stats-agent-team\nhelm lint ./helm/stats-agent-team -f ./helm/stats-agent-team/values-minikube.yaml\nhelm lint ./helm/stats-agent-team -f ./helm/stats-agent-team/values-eks.yaml\n</code></pre>"},{"location":"operations/chart-testing/#4-unit-tests-helm-unittest","title":"4. Unit Tests (helm-unittest)","text":"<p>Unit tests verify template rendering logic. Tests are located in <code>helm/stats-agent-team/tests/</code>.</p> <pre><code>make helm-unittest\n\n# Or directly:\nhelm unittest ./helm/stats-agent-team\n</code></pre>"},{"location":"operations/chart-testing/#writing-unit-tests","title":"Writing Unit Tests","text":"<p>Test files use YAML format with BDD-style assertions:</p> <pre><code># tests/deployment_test.yaml\nsuite: deployment tests\ntemplates:\n  - research-deployment.yaml\n\ntests:\n  - it: should create deployment when enabled\n    set:\n      research.enabled: true\n    asserts:\n      - isKind:\n          of: Deployment\n      - equal:\n          path: spec.replicas\n          value: 1\n\n  - it: should not create deployment when disabled\n    set:\n      research.enabled: false\n    asserts:\n      - hasDocuments:\n          count: 0\n</code></pre>"},{"location":"operations/chart-testing/#available-assertions","title":"Available Assertions","text":"Assertion Description <code>equal</code> Exact value match <code>notEqual</code> Value does not match <code>matchRegex</code> Regex pattern match <code>contains</code> Array contains value <code>isKind</code> Resource kind check <code>isAPIVersion</code> API version check <code>hasDocuments</code> Document count <code>exists</code> Path exists <code>notExists</code> Path does not exist <code>isNull</code> Value is null <code>isNotNull</code> Value is not null <code>isEmpty</code> Value is empty <code>isNotEmpty</code> Value is not empty <code>lengthEqual</code> Array/string length"},{"location":"operations/chart-testing/#5-schema-validation-kubeconform","title":"5. Schema Validation (kubeconform)","text":"<p>Validates rendered templates against Kubernetes API schemas:</p> <pre><code>make helm-kubeconform\n\n# Or directly:\nhelm template stats-agent ./helm/stats-agent-team | \\\n  kubeconform -strict -summary -kubernetes-version 1.29.0\n\n# With specific values:\nhelm template stats-agent ./helm/stats-agent-team \\\n  --set research.autoscaling.enabled=true \\\n  --set research.pdb.enabled=true | \\\n  kubeconform -strict -summary -kubernetes-version 1.29.0\n</code></pre>"},{"location":"operations/chart-testing/#testing-multiple-k8s-versions","title":"Testing Multiple K8s Versions","text":"<pre><code>for version in 1.27.0 1.28.0 1.29.0; do\n  echo \"Testing Kubernetes $version\"\n  helm template stats-agent ./helm/stats-agent-team | \\\n    kubeconform -strict -kubernetes-version $version\ndone\n</code></pre>"},{"location":"operations/chart-testing/#6-security-best-practices-polaris","title":"6. Security Best Practices (Polaris)","text":"<p>Checks for security issues and Kubernetes best practices:</p> <pre><code>make helm-polaris\n\n# Or directly:\nhelm template stats-agent ./helm/stats-agent-team | \\\n  polaris audit --audit-path - --format pretty\n\n# With score threshold (fails if below 70):\nhelm template stats-agent ./helm/stats-agent-team | \\\n  polaris audit --audit-path - --set-exit-code-below-score 70\n</code></pre>"},{"location":"operations/chart-testing/#common-polaris-checks","title":"Common Polaris Checks","text":"<ul> <li>Resource requests/limits configured</li> <li>Security context set (non-root, read-only filesystem)</li> <li>Liveness/readiness probes defined</li> <li>No privileged containers</li> <li>No host network/PID access</li> </ul>"},{"location":"operations/chart-testing/#7-go-struct-validation","title":"7. Go Struct Validation","text":"<p>Validates values.yaml against Go struct definitions:</p> <pre><code>go test -v ./pkg/helm/...\n</code></pre> <p>This catches: - Invalid LLM/search provider values - Port conflicts between agents - Missing required fields - Invalid resource quantity formats</p>"},{"location":"operations/chart-testing/#8-integration-tests","title":"8. Integration Tests","text":"<p>Deploy to a real cluster (Kind) and verify functionality:</p> <pre><code># Create Kind cluster\nkind create cluster --name chart-testing\n\n# Build and load images\nmake k8s-build-images\nkind load docker-image stats-agent-research:latest --name chart-testing\nkind load docker-image stats-agent-synthesis:latest --name chart-testing\nkind load docker-image stats-agent-verification:latest --name chart-testing\nkind load docker-image stats-agent-orchestration-eino:latest --name chart-testing\n\n# Install chart\nhelm install stats-agent ./helm/stats-agent-team \\\n  --namespace stats-agent \\\n  --create-namespace \\\n  --set global.image.pullPolicy=Never \\\n  --wait --timeout 5m\n\n# Verify pods are running\nkubectl get pods -n stats-agent\n\n# Cleanup\nkind delete cluster --name chart-testing\n</code></pre>"},{"location":"operations/chart-testing/#cicd-integration","title":"CI/CD Integration","text":""},{"location":"operations/chart-testing/#github-actions-workflow","title":"GitHub Actions Workflow","text":"<p>The <code>.github/workflows/helm.yaml</code> workflow runs automatically on: - Push to <code>main</code> affecting <code>helm/**</code> - Pull requests affecting <code>helm/**</code></p>"},{"location":"operations/chart-testing/#workflow-jobs","title":"Workflow Jobs","text":"<p>Security Scanning: 1. gitleaks - Hardcoded secret detection in code and git history 2. trivy-config - Helm chart misconfiguration and secret pattern detection 3. trivy-image - Container vulnerability scanning with SBOM generation</p> <p>Chart Validation: 4. lint - <code>helm lint</code> with all values files 5. unittest - <code>helm-unittest</code> plugin tests 6. kubeconform - Schema validation against K8s 1.29 7. polaris - Security best practices audit 8. go-validation - Go struct validation tests 9. integration - Kind cluster deployment test (requires security scans to pass) 10. chart-testing - Official <code>ct lint</code> tool</p>"},{"location":"operations/chart-testing/#local-pre-commit-testing","title":"Local Pre-commit Testing","text":"<p>Before pushing changes, run:</p> <pre><code># Quick validation\nmake helm-test\n\n# Full test suite\nmake helm-test-all\n\n# Go validation\ngo test ./pkg/helm/...\n</code></pre>"},{"location":"operations/chart-testing/#test-directory-structure","title":"Test Directory Structure","text":"<pre><code>helm/stats-agent-team/\n\u251c\u2500\u2500 tests/\n\u2502   \u251c\u2500\u2500 deployment_test.yaml    # Deployment template tests\n\u2502   \u251c\u2500\u2500 service_test.yaml       # Service template tests\n\u2502   \u251c\u2500\u2500 hpa_test.yaml           # HPA template tests\n\u2502   \u251c\u2500\u2500 pdb_test.yaml           # PDB template tests\n\u2502   \u2514\u2500\u2500 ingress_test.yaml       # Ingress template tests\n\u251c\u2500\u2500 templates/\n\u2502   \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 values.yaml\n\u251c\u2500\u2500 values-minikube.yaml\n\u2514\u2500\u2500 values-eks.yaml\n</code></pre>"},{"location":"operations/chart-testing/#debugging-test-failures","title":"Debugging Test Failures","text":""},{"location":"operations/chart-testing/#view-rendered-templates","title":"View Rendered Templates","text":"<pre><code># Render with specific values\nhelm template stats-agent ./helm/stats-agent-team \\\n  --set research.enabled=true \\\n  --set research.autoscaling.enabled=true \\\n  --debug\n\n# Render specific template\nhelm template stats-agent ./helm/stats-agent-team \\\n  --show-only templates/hpa.yaml\n</code></pre>"},{"location":"operations/chart-testing/#verbose-unit-test-output","title":"Verbose Unit Test Output","text":"<pre><code>helm unittest ./helm/stats-agent-team --color --output-type detailed\n</code></pre>"},{"location":"operations/chart-testing/#check-template-syntax","title":"Check Template Syntax","text":"<pre><code># Validate YAML syntax\nhelm template stats-agent ./helm/stats-agent-team | yq '.'\n\n# Check specific path\nhelm template stats-agent ./helm/stats-agent-team | \\\n  yq '.spec.template.spec.containers[0].resources'\n</code></pre>"},{"location":"operations/chart-testing/#adding-new-tests","title":"Adding New Tests","text":"<p>When adding new templates:</p> <ol> <li>Create test file in <code>tests/&lt;template&gt;_test.yaml</code></li> <li>Add tests for:</li> <li>Enabled/disabled states</li> <li>Default values</li> <li>Custom values</li> <li>Edge cases</li> <li>Run tests locally: <code>make helm-unittest</code></li> <li>Update this documentation if needed</li> </ol>"},{"location":"operations/chart-testing/#test-template","title":"Test Template","text":"<pre><code>suite: &lt;component&gt; tests\ntemplates:\n  - &lt;template-file&gt;.yaml\n\ntests:\n  - it: should create &lt;resource&gt; when enabled\n    set:\n      &lt;component&gt;.enabled: true\n    asserts:\n      - isKind:\n          of: &lt;ResourceKind&gt;\n      - equal:\n          path: metadata.name\n          value: RELEASE-NAME-stats-agent-team-&lt;component&gt;\n\n  - it: should not create &lt;resource&gt; when disabled\n    set:\n      &lt;component&gt;.enabled: false\n    asserts:\n      - hasDocuments:\n          count: 0\n\n  - it: should set custom values correctly\n    set:\n      &lt;component&gt;.enabled: true\n      &lt;component&gt;.&lt;field&gt;: &lt;value&gt;\n    asserts:\n      - equal:\n          path: &lt;yaml.path&gt;\n          value: &lt;expected&gt;\n</code></pre>"},{"location":"operations/chart-testing/#references","title":"References","text":"<ul> <li>helm-unittest Documentation</li> <li>kubeconform Documentation</li> <li>Polaris Documentation</li> <li>chart-testing Documentation</li> <li>Helm Testing Best Practices</li> </ul>"},{"location":"operations/scaling/","title":"Scaling Guide","text":"<p>This guide covers horizontal and vertical scaling for the Stats Agent Team, following patterns established by Apache Superset and ArgoCD.</p>"},{"location":"operations/scaling/#overview","title":"Overview","text":"<p>Each agent in the Stats Agent Team supports:</p> <ul> <li>Horizontal Pod Autoscaling (HPA) - Automatically scale replicas based on CPU/memory utilization</li> <li>Pod Disruption Budgets (PDB) - Ensure availability during voluntary disruptions</li> <li>Resource Limits - Control CPU and memory allocation per pod</li> </ul> <p>All scaling features are disabled by default and can be enabled per-agent via Helm values.</p>"},{"location":"operations/scaling/#quick-start","title":"Quick Start","text":""},{"location":"operations/scaling/#enable-autoscaling-for-production","title":"Enable Autoscaling for Production","text":"<pre><code># values-production.yaml\norchestration:\n  autoscaling:\n    enabled: true\n    minReplicas: 2\n    maxReplicas: 10\n    targetCPUUtilizationPercentage: 70\n  pdb:\n    enabled: true\n    minAvailable: 1\n\nsynthesis:\n  autoscaling:\n    enabled: true\n    minReplicas: 2\n    maxReplicas: 20\n    targetCPUUtilizationPercentage: 80\n  pdb:\n    enabled: true\n    minAvailable: 1\n</code></pre> <p>Deploy with: <pre><code>helm upgrade --install stats-agent ./helm/stats-agent-team \\\n  -f values-production.yaml \\\n  --namespace stats-agent\n</code></pre></p>"},{"location":"operations/scaling/#horizontal-pod-autoscaler-hpa","title":"Horizontal Pod Autoscaler (HPA)","text":""},{"location":"operations/scaling/#configuration-options","title":"Configuration Options","text":"<p>Each agent supports these autoscaling settings:</p> <pre><code>&lt;agent&gt;:\n  autoscaling:\n    # Enable HPA for this agent\n    enabled: false\n\n    # Minimum number of replicas\n    minReplicas: 1\n\n    # Maximum number of replicas\n    maxReplicas: 10\n\n    # Scale up when average CPU exceeds this percentage\n    targetCPUUtilizationPercentage: 80\n\n    # Scale up when average memory exceeds this percentage (optional)\n    # targetMemoryUtilizationPercentage: 80\n\n    # Advanced scaling behavior (optional)\n    # behavior:\n    #   scaleDown:\n    #     stabilizationWindowSeconds: 300\n    #     policies:\n    #       - type: Percent\n    #         value: 10\n    #         periodSeconds: 60\n    #   scaleUp:\n    #     stabilizationWindowSeconds: 0\n    #     policies:\n    #       - type: Percent\n    #         value: 100\n    #         periodSeconds: 15\n</code></pre>"},{"location":"operations/scaling/#scaling-recommendations-by-agent","title":"Scaling Recommendations by Agent","text":"Agent Scaling Behavior Recommended Settings Research I/O bound (web requests) CPU-based, moderate scaling Synthesis CPU intensive (LLM calls) CPU-based, aggressive scaling Verification Mixed (fetch + LLM) CPU-based, moderate scaling Orchestration Stateless coordinator Conservative scaling, ensure HA Direct CPU intensive (LLM) CPU-based, aggressive scaling"},{"location":"operations/scaling/#example-high-traffic-configuration","title":"Example: High-Traffic Configuration","text":"<pre><code># For high-traffic production deployments\nresearch:\n  autoscaling:\n    enabled: true\n    minReplicas: 3\n    maxReplicas: 15\n    targetCPUUtilizationPercentage: 70\n\nsynthesis:\n  autoscaling:\n    enabled: true\n    minReplicas: 5\n    maxReplicas: 50\n    targetCPUUtilizationPercentage: 60\n    targetMemoryUtilizationPercentage: 70\n\nverification:\n  autoscaling:\n    enabled: true\n    minReplicas: 3\n    maxReplicas: 20\n    targetCPUUtilizationPercentage: 70\n\norchestration:\n  autoscaling:\n    enabled: true\n    minReplicas: 2\n    maxReplicas: 5\n    targetCPUUtilizationPercentage: 80\n</code></pre>"},{"location":"operations/scaling/#scaling-behavior-tuning","title":"Scaling Behavior Tuning","text":"<p>For gradual scale-down to avoid flapping:</p> <pre><code>synthesis:\n  autoscaling:\n    enabled: true\n    minReplicas: 2\n    maxReplicas: 20\n    targetCPUUtilizationPercentage: 70\n    behavior:\n      scaleDown:\n        stabilizationWindowSeconds: 300  # Wait 5 min before scaling down\n        policies:\n          - type: Percent\n            value: 10                     # Scale down max 10% at a time\n            periodSeconds: 60\n      scaleUp:\n        stabilizationWindowSeconds: 0    # Scale up immediately\n        policies:\n          - type: Percent\n            value: 100                    # Double capacity if needed\n            periodSeconds: 15\n          - type: Pods\n            value: 4                      # Or add 4 pods\n            periodSeconds: 15\n        selectPolicy: Max                 # Use whichever adds more pods\n</code></pre>"},{"location":"operations/scaling/#pod-disruption-budgets-pdb","title":"Pod Disruption Budgets (PDB)","text":"<p>PDBs ensure a minimum number of pods remain available during voluntary disruptions like: - Node drains - Cluster upgrades - Deployment rollouts</p>"},{"location":"operations/scaling/#configuration-options_1","title":"Configuration Options","text":"<pre><code>&lt;agent&gt;:\n  pdb:\n    # Enable PDB for this agent\n    enabled: false\n\n    # Minimum pods that must remain available (use one or the other)\n    minAvailable: 1          # Can be integer or percentage: \"50%\"\n\n    # Maximum pods that can be unavailable\n    # maxUnavailable: 1      # Can be integer or percentage: \"25%\"\n</code></pre> <p>Note: <code>minAvailable</code> and <code>maxUnavailable</code> are mutually exclusive. If neither is specified when PDB is enabled, <code>maxUnavailable: 1</code> is used as the default.</p>"},{"location":"operations/scaling/#example-high-availability-configuration","title":"Example: High Availability Configuration","text":"<pre><code># Ensure at least 2 pods of each critical agent remain available\nresearch:\n  replicaCount: 3\n  pdb:\n    enabled: true\n    minAvailable: 2\n\nsynthesis:\n  replicaCount: 4\n  pdb:\n    enabled: true\n    minAvailable: 2\n\nverification:\n  replicaCount: 3\n  pdb:\n    enabled: true\n    minAvailable: 2\n\norchestration:\n  replicaCount: 3\n  pdb:\n    enabled: true\n    minAvailable: 2\n</code></pre>"},{"location":"operations/scaling/#example-percentage-based-pdb","title":"Example: Percentage-Based PDB","text":"<pre><code># Allow up to 25% of pods to be unavailable during disruptions\nsynthesis:\n  replicaCount: 8\n  pdb:\n    enabled: true\n    maxUnavailable: \"25%\"\n</code></pre>"},{"location":"operations/scaling/#vertical-scaling-resources","title":"Vertical Scaling (Resources)","text":"<p>Each agent's resource requests and limits can be configured:</p> <pre><code>&lt;agent&gt;:\n  resources:\n    requests:\n      cpu: 200m\n      memory: 256Mi\n    limits:\n      cpu: 1000m\n      memory: 512Mi\n</code></pre>"},{"location":"operations/scaling/#recommended-resource-profiles","title":"Recommended Resource Profiles","text":""},{"location":"operations/scaling/#development-minikube","title":"Development / Minikube","text":"<pre><code>research:\n  resources:\n    requests:\n      cpu: 50m\n      memory: 64Mi\n    limits:\n      cpu: 200m\n      memory: 128Mi\n\nsynthesis:\n  resources:\n    requests:\n      cpu: 100m\n      memory: 128Mi\n    limits:\n      cpu: 500m\n      memory: 256Mi\n</code></pre>"},{"location":"operations/scaling/#production","title":"Production","text":"<pre><code>research:\n  resources:\n    requests:\n      cpu: 200m\n      memory: 256Mi\n    limits:\n      cpu: 1000m\n      memory: 512Mi\n\nsynthesis:\n  resources:\n    requests:\n      cpu: 500m\n      memory: 512Mi\n    limits:\n      cpu: 2000m\n      memory: 1Gi\n\nverification:\n  resources:\n    requests:\n      cpu: 500m\n      memory: 512Mi\n    limits:\n      cpu: 2000m\n      memory: 1Gi\n\norchestration:\n  resources:\n    requests:\n      cpu: 200m\n      memory: 256Mi\n    limits:\n      cpu: 1000m\n      memory: 512Mi\n</code></pre>"},{"location":"operations/scaling/#monitoring-scaling","title":"Monitoring Scaling","text":""},{"location":"operations/scaling/#view-hpa-status","title":"View HPA Status","text":"<pre><code># List all HPAs\nkubectl get hpa -n stats-agent\n\n# Watch HPA in real-time\nkubectl get hpa -n stats-agent -w\n\n# Describe specific HPA\nkubectl describe hpa stats-agent-stats-agent-team-synthesis -n stats-agent\n</code></pre>"},{"location":"operations/scaling/#view-pdb-status","title":"View PDB Status","text":"<pre><code># List all PDBs\nkubectl get pdb -n stats-agent\n\n# Check disruption status\nkubectl describe pdb stats-agent-stats-agent-team-orchestration -n stats-agent\n</code></pre>"},{"location":"operations/scaling/#view-pod-resource-usage","title":"View Pod Resource Usage","text":"<pre><code># Current resource usage (requires metrics-server)\nkubectl top pods -n stats-agent\n\n# Resource requests/limits\nkubectl describe pods -n stats-agent | grep -A 5 \"Requests\\|Limits\"\n</code></pre>"},{"location":"operations/scaling/#scaling-patterns","title":"Scaling Patterns","text":""},{"location":"operations/scaling/#pattern-1-start-small-scale-up","title":"Pattern 1: Start Small, Scale Up","text":"<p>Begin with conservative settings and increase based on observed load:</p> <pre><code># Initial deployment\nsynthesis:\n  replicaCount: 2\n  autoscaling:\n    enabled: true\n    minReplicas: 2\n    maxReplicas: 5\n    targetCPUUtilizationPercentage: 80\n</code></pre> <p>Monitor and adjust: <pre><code># Watch scaling behavior\nkubectl get hpa -n stats-agent -w\n\n# If constantly at max, increase maxReplicas\nhelm upgrade stats-agent ./helm/stats-agent-team \\\n  --set synthesis.autoscaling.maxReplicas=10\n</code></pre></p>"},{"location":"operations/scaling/#pattern-2-predictable-load-scaling","title":"Pattern 2: Predictable Load Scaling","text":"<p>For predictable traffic patterns, use scheduled scaling with KEDA or CronJobs:</p> <pre><code># Scale up during business hours (example with KEDA)\napiVersion: keda.sh/v1alpha1\nkind: ScaledObject\nmetadata:\n  name: synthesis-scaler\nspec:\n  scaleTargetRef:\n    name: stats-agent-stats-agent-team-synthesis\n  minReplicaCount: 2\n  maxReplicaCount: 20\n  triggers:\n    - type: cron\n      metadata:\n        timezone: America/Los_Angeles\n        start: 0 8 * * 1-5    # 8 AM weekdays\n        end: 0 18 * * 1-5     # 6 PM weekdays\n        desiredReplicas: \"10\"\n</code></pre>"},{"location":"operations/scaling/#pattern-3-queue-based-scaling","title":"Pattern 3: Queue-Based Scaling","text":"<p>For batch processing workloads, scale based on queue depth (requires KEDA):</p> <pre><code># Scale based on pending work\napiVersion: keda.sh/v1alpha1\nkind: ScaledObject\nmetadata:\n  name: synthesis-queue-scaler\nspec:\n  scaleTargetRef:\n    name: stats-agent-stats-agent-team-synthesis\n  minReplicaCount: 1\n  maxReplicaCount: 50\n  triggers:\n    - type: redis\n      metadata:\n        address: redis:6379\n        listName: synthesis-queue\n        listLength: \"10\"  # 1 pod per 10 queue items\n</code></pre>"},{"location":"operations/scaling/#troubleshooting","title":"Troubleshooting","text":""},{"location":"operations/scaling/#hpa-not-scaling","title":"HPA Not Scaling","text":"<ol> <li> <p>Check metrics-server is running: <pre><code>kubectl get pods -n kube-system | grep metrics-server\n</code></pre></p> </li> <li> <p>Verify HPA can read metrics: <pre><code>kubectl describe hpa &lt;hpa-name&gt; -n stats-agent\n</code></pre></p> </li> <li> <p>Check resource requests are set:    HPA requires resource requests to calculate utilization percentages.</p> </li> </ol>"},{"location":"operations/scaling/#pods-evicted-during-upgrade","title":"Pods Evicted During Upgrade","text":"<ol> <li> <p>Enable PDB: <pre><code>orchestration:\n  pdb:\n    enabled: true\n    minAvailable: 1\n</code></pre></p> </li> <li> <p>Check PDB is working: <pre><code>kubectl get pdb -n stats-agent\n</code></pre></p> </li> </ol>"},{"location":"operations/scaling/#scaling-too-aggressively","title":"Scaling Too Aggressively","text":"<p>Add stabilization windows: <pre><code>autoscaling:\n  behavior:\n    scaleDown:\n      stabilizationWindowSeconds: 300\n</code></pre></p>"},{"location":"operations/scaling/#references","title":"References","text":"<ul> <li>Kubernetes HPA Documentation</li> <li>Kubernetes PDB Documentation</li> <li>Apache Superset Helm Chart</li> <li>ArgoCD Helm Chart</li> <li>KEDA - Kubernetes Event-driven Autoscaling</li> </ul>"},{"location":"operations/security/","title":"Security Guide for Statistics Agent Team","text":"<p>This document provides comprehensive security recommendations for deploying the Statistics Agent Team system, covering credential management, cloud deployment (AWS/Azure), and local development scenarios.</p>"},{"location":"operations/security/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Overview</li> <li>Threat Model</li> <li>Credential Management</li> <li>Current State: Environment Variables</li> <li>Cloud Secrets Managers</li> <li>Workload Identity with SPIFFE/SPIRE</li> <li>Enterprise Identity: Okta Integration</li> <li>Cloud Deployment Security</li> <li>AWS Security Configuration</li> <li>Azure Security Configuration</li> <li>Local Development Security</li> <li>Network Security</li> <li>API Security</li> <li>Container Security</li> <li>Monitoring and Auditing</li> <li>Incident Response</li> <li>Compliance Considerations</li> </ul>"},{"location":"operations/security/#overview","title":"Overview","text":"<p>The Statistics Agent Team is a multi-agent system that requires several types of credentials:</p> Credential Type Purpose Sensitivity LLM API Keys Gemini, Claude, OpenAI, xAI High - billing, rate limits Search API Keys Serper, SerpAPI Medium - billing Inter-Agent Auth A2A protocol tokens Medium - internal access Database Credentials Future: result caching High - data access <p>Key Principle: Never store secrets in code, configuration files committed to version control, or container images.</p>"},{"location":"operations/security/#threat-model","title":"Threat Model","text":""},{"location":"operations/security/#attack-vectors","title":"Attack Vectors","text":"<ol> <li>Credential Exposure</li> <li>Secrets in source code or logs</li> <li>Environment variable leakage</li> <li> <p>Container image inspection</p> </li> <li> <p>Network Attacks</p> </li> <li>Man-in-the-middle on inter-agent communication</li> <li>Unauthorized API access</li> <li> <p>DNS spoofing</p> </li> <li> <p>Application Vulnerabilities</p> </li> <li>Injection attacks via user topics</li> <li>Server-Side Request Forgery (SSRF) via URL fetching</li> <li> <p>Denial of Service through resource exhaustion</p> </li> <li> <p>Supply Chain</p> </li> <li>Compromised dependencies</li> <li>Malicious container base images</li> </ol>"},{"location":"operations/security/#security-objectives","title":"Security Objectives","text":"<ul> <li>Confidentiality: Protect API keys and user queries</li> <li>Integrity: Ensure verified statistics are not tampered with</li> <li>Availability: Maintain service uptime and rate limit management</li> </ul>"},{"location":"operations/security/#credential-management","title":"Credential Management","text":""},{"location":"operations/security/#current-state-environment-variables","title":"Current State: Environment Variables","text":"<p>The current implementation uses environment variables for credential storage:</p> <pre><code># Current approach (basic security)\nexport GOOGLE_API_KEY=\"your-key\"\nexport SERPER_API_KEY=\"your-key\"\n</code></pre> <p>Limitations: - Credentials visible in process listings (<code>ps aux</code>) - Persisted in shell history - Visible in Docker inspect - No rotation mechanism - No audit trail</p>"},{"location":"operations/security/#cloud-secrets-managers","title":"Cloud Secrets Managers","text":""},{"location":"operations/security/#aws-secrets-manager","title":"AWS Secrets Manager","text":"<p>Recommended for AWS deployments. Provides automatic rotation, fine-grained IAM policies, and audit logging.</p> <p>Setup:</p> <ol> <li> <p>Create secrets: <pre><code>aws secretsmanager create-secret \\\n    --name \"stats-agent/llm-keys\" \\\n    --description \"LLM API keys for Statistics Agent\" \\\n    --secret-string '{\n        \"GEMINI_API_KEY\": \"your-gemini-key\",\n        \"ANTHROPIC_API_KEY\": \"your-anthropic-key\",\n        \"OPENAI_API_KEY\": \"your-openai-key\"\n    }'\n\naws secretsmanager create-secret \\\n    --name \"stats-agent/search-keys\" \\\n    --description \"Search API keys\" \\\n    --secret-string '{\n        \"SERPER_API_KEY\": \"your-serper-key\"\n    }'\n</code></pre></p> </li> <li> <p>IAM Policy for ECS/EKS: <pre><code>{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"secretsmanager:GetSecretValue\"\n            ],\n            \"Resource\": [\n                \"arn:aws:secretsmanager:*:*:secret:stats-agent/*\"\n            ]\n        }\n    ]\n}\n</code></pre></p> </li> <li> <p>Integration in Go: <pre><code>import (\n    \"github.com/aws/aws-sdk-go-v2/service/secretsmanager\"\n)\n\nfunc LoadSecretsFromAWS(ctx context.Context) (map[string]string, error) {\n    cfg, err := config.LoadDefaultConfig(ctx)\n    if err != nil {\n        return nil, err\n    }\n\n    client := secretsmanager.NewFromConfig(cfg)\n    result, err := client.GetSecretValue(ctx, &amp;secretsmanager.GetSecretValueInput{\n        SecretId: aws.String(\"stats-agent/llm-keys\"),\n    })\n    if err != nil {\n        return nil, err\n    }\n\n    var secrets map[string]string\n    json.Unmarshal([]byte(*result.SecretString), &amp;secrets)\n    return secrets, nil\n}\n</code></pre></p> </li> <li> <p>ECS Task Definition with Secrets: <pre><code>{\n    \"containerDefinitions\": [{\n        \"name\": \"stats-agent-eino\",\n        \"secrets\": [\n            {\n                \"name\": \"GEMINI_API_KEY\",\n                \"valueFrom\": \"arn:aws:secretsmanager:us-east-1:123456789:secret:stats-agent/llm-keys:GEMINI_API_KEY::\"\n            },\n            {\n                \"name\": \"SERPER_API_KEY\",\n                \"valueFrom\": \"arn:aws:secretsmanager:us-east-1:123456789:secret:stats-agent/search-keys:SERPER_API_KEY::\"\n            }\n        ]\n    }]\n}\n</code></pre></p> </li> </ol>"},{"location":"operations/security/#aws-systems-manager-parameter-store","title":"AWS Systems Manager Parameter Store","text":"<p>Lower cost alternative for simpler use cases without automatic rotation needs.</p> <pre><code># Create parameters (use SecureString for secrets)\naws ssm put-parameter \\\n    --name \"/stats-agent/gemini-api-key\" \\\n    --type \"SecureString\" \\\n    --value \"your-gemini-key\"\n</code></pre>"},{"location":"operations/security/#azure-key-vault","title":"Azure Key Vault","text":"<p>Recommended for Azure deployments.</p> <ol> <li> <p>Create Key Vault: <pre><code>az keyvault create \\\n    --name stats-agent-vault \\\n    --resource-group stats-agent-rg \\\n    --location eastus\n\naz keyvault secret set \\\n    --vault-name stats-agent-vault \\\n    --name \"gemini-api-key\" \\\n    --value \"your-gemini-key\"\n</code></pre></p> </li> <li> <p>Managed Identity for AKS/Container Apps: <pre><code># Enable managed identity\naz aks update \\\n    --resource-group stats-agent-rg \\\n    --name stats-agent-aks \\\n    --enable-managed-identity\n\n# Grant access to Key Vault\naz keyvault set-policy \\\n    --name stats-agent-vault \\\n    --object-id &lt;managed-identity-object-id&gt; \\\n    --secret-permissions get list\n</code></pre></p> </li> <li> <p>Integration in Go: <pre><code>import (\n    \"github.com/Azure/azure-sdk-for-go/sdk/keyvault/azsecrets\"\n    \"github.com/Azure/azure-sdk-for-go/sdk/azidentity\"\n)\n\nfunc LoadSecretsFromAzure(ctx context.Context) (map[string]string, error) {\n    cred, err := azidentity.NewDefaultAzureCredential(nil)\n    if err != nil {\n        return nil, err\n    }\n\n    client, err := azsecrets.NewClient(\n        \"https://stats-agent-vault.vault.azure.net/\",\n        cred,\n        nil,\n    )\n    if err != nil {\n        return nil, err\n    }\n\n    resp, err := client.GetSecret(ctx, \"gemini-api-key\", \"\", nil)\n    if err != nil {\n        return nil, err\n    }\n\n    return map[string]string{\n        \"GEMINI_API_KEY\": *resp.Value,\n    }, nil\n}\n</code></pre></p> </li> </ol>"},{"location":"operations/security/#workload-identity-with-spiffespire","title":"Workload Identity with SPIFFE/SPIRE","text":"<p>SPIFFE (Secure Production Identity Framework for Everyone) provides cryptographic identities to workloads, eliminating static credentials for service-to-service authentication.</p>"},{"location":"operations/security/#use-cases-for-stats-agent","title":"Use Cases for Stats Agent","text":"<ol> <li>Inter-agent authentication (Research \u2194 Synthesis \u2194 Verification)</li> <li>Zero-trust network communication</li> <li>Short-lived, automatically rotated credentials</li> </ol>"},{"location":"operations/security/#spire-deployment","title":"SPIRE Deployment","text":"<ol> <li> <p>Install SPIRE Server: <pre><code># spire-server.yaml for Kubernetes\napiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: spire-server\n  namespace: spire\nspec:\n  selector:\n    matchLabels:\n      app: spire-server\n  template:\n    spec:\n      containers:\n      - name: spire-server\n        image: ghcr.io/spiffe/spire-server:1.9.0\n        args:\n          - -config\n          - /run/spire/config/server.conf\n        volumeMounts:\n        - name: spire-config\n          mountPath: /run/spire/config\n</code></pre></p> </li> <li> <p>Configure SPIRE Agent: <pre><code># agent.conf\nagent {\n    data_dir = \"/opt/spire/data\"\n    log_level = \"INFO\"\n    server_address = \"spire-server\"\n    server_port = \"8081\"\n    socket_path = \"/run/spire/sockets/agent.sock\"\n    trust_bundle_path = \"/opt/spire/conf/bootstrap.crt\"\n    trust_domain = \"stats-agent.example.com\"\n}\n\nplugins {\n    NodeAttestor \"k8s_psat\" {\n        plugin_data {\n            cluster = \"stats-agent-cluster\"\n        }\n    }\n\n    WorkloadAttestor \"k8s\" {\n        plugin_data {\n            skip_kubelet_verification = true\n        }\n    }\n}\n</code></pre></p> </li> <li> <p>Register Workloads (assign SPIFFE IDs): <pre><code># Register Research Agent\nspire-server entry create \\\n    -spiffeID spiffe://stats-agent.example.com/research-agent \\\n    -parentID spiffe://stats-agent.example.com/k8s-node \\\n    -selector k8s:ns:stats-agent \\\n    -selector k8s:sa:research-agent\n\n# Register Synthesis Agent\nspire-server entry create \\\n    -spiffeID spiffe://stats-agent.example.com/synthesis-agent \\\n    -parentID spiffe://stats-agent.example.com/k8s-node \\\n    -selector k8s:ns:stats-agent \\\n    -selector k8s:sa:synthesis-agent\n</code></pre></p> </li> <li> <p>Go Integration with go-spiffe: <pre><code>import (\n    \"github.com/spiffe/go-spiffe/v2/spiffeid\"\n    \"github.com/spiffe/go-spiffe/v2/spiffetls/tlsconfig\"\n    \"github.com/spiffe/go-spiffe/v2/workloadapi\"\n)\n\nfunc NewSecureHTTPClient(ctx context.Context) (*http.Client, error) {\n    // Create X509Source from Workload API\n    source, err := workloadapi.NewX509Source(ctx)\n    if err != nil {\n        return nil, fmt.Errorf(\"unable to create X509Source: %w\", err)\n    }\n\n    // Authorize connections to specific SPIFFE IDs\n    authorizedIDs := []spiffeid.ID{\n        spiffeid.RequireFromString(\"spiffe://stats-agent.example.com/synthesis-agent\"),\n        spiffeid.RequireFromString(\"spiffe://stats-agent.example.com/verification-agent\"),\n    }\n\n    tlsConfig := tlsconfig.MTLSClientConfig(source, source, tlsconfig.AuthorizeOneOf(authorizedIDs...))\n\n    return &amp;http.Client{\n        Transport: &amp;http.Transport{\n            TLSClientConfig: tlsConfig,\n        },\n    }, nil\n}\n</code></pre></p> </li> </ol>"},{"location":"operations/security/#enterprise-identity-okta-integration","title":"Enterprise Identity: Okta Integration","text":"<p>For enterprise deployments requiring centralized identity management, integrate with Okta for: - User authentication for API access - Service account management - Fine-grained authorization policies</p>"},{"location":"operations/security/#okta-api-access-management-xaa","title":"Okta API Access Management (XAA)","text":"<ol> <li> <p>Create API Authorization Server: <pre><code># Via Okta Admin Console or API\ncurl -X POST \"https://${OKTA_DOMAIN}/api/v1/authorizationServers\" \\\n  -H \"Authorization: SSWS ${OKTA_API_TOKEN}\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"name\": \"Stats Agent API\",\n    \"description\": \"Authorization server for Statistics Agent\",\n    \"audiences\": [\"api://stats-agent\"]\n  }'\n</code></pre></p> </li> <li> <p>Define Scopes: <pre><code>{\n    \"scopes\": [\n        {\"name\": \"stats:read\", \"description\": \"Read statistics\"},\n        {\"name\": \"stats:search\", \"description\": \"Search for statistics\"},\n        {\"name\": \"stats:verify\", \"description\": \"Verify statistics\"},\n        {\"name\": \"admin:agents\", \"description\": \"Manage agent configuration\"}\n    ]\n}\n</code></pre></p> </li> <li> <p>Create Access Policies: <pre><code>{\n    \"name\": \"Stats Agent Default Policy\",\n    \"conditions\": {\n        \"clients\": {\"include\": [\"ALL_CLIENTS\"]}\n    },\n    \"rules\": [{\n        \"name\": \"Standard Access\",\n        \"conditions\": {\n            \"grantTypes\": {\"include\": [\"client_credentials\"]},\n            \"scopes\": {\"include\": [\"stats:read\", \"stats:search\"]}\n        },\n        \"actions\": {\n            \"token\": {\n                \"accessTokenLifetimeMinutes\": 60,\n                \"refreshTokenLifetimeMinutes\": 0\n            }\n        }\n    }]\n}\n</code></pre></p> </li> <li> <p>Go Middleware for JWT Validation: <pre><code>import (\n    \"github.com/okta/okta-jwt-verifier-golang\"\n)\n\nfunc OktaAuthMiddleware(next http.Handler) http.Handler {\n    verifier := jwtverifier.JwtVerifier{\n        Issuer:           \"https://your-okta-domain.okta.com/oauth2/default\",\n        ClaimsToValidate: map[string]string{\n            \"aud\": \"api://stats-agent\",\n        },\n    }\n\n    return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n        token := extractBearerToken(r)\n        if token == \"\" {\n            http.Error(w, \"Unauthorized\", http.StatusUnauthorized)\n            return\n        }\n\n        _, err := verifier.VerifyAccessToken(token)\n        if err != nil {\n            http.Error(w, \"Invalid token\", http.StatusUnauthorized)\n            return\n        }\n\n        next.ServeHTTP(w, r)\n    })\n}\n</code></pre></p> </li> </ol>"},{"location":"operations/security/#okta-identity-governance-oig-just-in-time-access","title":"Okta Identity Governance (OIG) / Just-in-Time Access","text":"<p>For sensitive operations, implement Just-in-Time (JIT) access using Okta Identity Governance:</p> <ol> <li> <p>Define Access Bundles: <pre><code># Access bundle for admin operations\nname: stats-agent-admin\ndescription: \"Admin access to Statistics Agent\"\nresources:\n  - type: api_scope\n    name: admin:agents\n  - type: api_scope\n    name: stats:verify\nmax_duration: 4h\napproval_required: true\napprovers:\n  - group: security-team\n</code></pre></p> </li> <li> <p>Request Access Flow: <pre><code>// Example: Request elevated access for admin operations\nfunc RequestElevatedAccess(ctx context.Context, userID string) error {\n    client := okta.NewClient(ctx, oktaConfig)\n\n    request := &amp;okta.AccessRequest{\n        ResourceSetID: \"stats-agent-admin\",\n        Justification: \"Need to modify agent configuration for maintenance\",\n        Duration:      \"4h\",\n    }\n\n    _, err := client.AccessRequests.Create(ctx, userID, request)\n    return err\n}\n</code></pre></p> </li> </ol>"},{"location":"operations/security/#cloud-deployment-security","title":"Cloud Deployment Security","text":""},{"location":"operations/security/#aws-security-configuration","title":"AWS Security Configuration","text":""},{"location":"operations/security/#vpc-architecture","title":"VPC Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                         VPC                                  \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502   Public Subnet     \u2502    \u2502     Private Subnet          \u2502 \u2502\n\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502    \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502 \u2502\n\u2502  \u2502  \u2502      ALB      \u2502  \u2502    \u2502  \u2502   ECS/EKS Cluster   \u2502   \u2502 \u2502\n\u2502  \u2502  \u2502  (HTTPS:443)  \u2502\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u253c\u2500&gt;\u2502   - Research Agent  \u2502   \u2502 \u2502\n\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502    \u2502  \u2502   - Synthesis Agent \u2502   \u2502 \u2502\n\u2502  \u2502                     \u2502    \u2502  \u2502   - Verification    \u2502   \u2502 \u2502\n\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502    \u2502  \u2502   - Orchestration   \u2502   \u2502 \u2502\n\u2502  \u2502  \u2502   NAT GW      \u2502&lt;\u2500\u253c\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2502                     \u2502   \u2502 \u2502\n\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502    \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502                             \u2502 \u2502\n\u2502                             \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502 \u2502\n\u2502                             \u2502  \u2502    VPC Endpoints    \u2502   \u2502 \u2502\n\u2502                             \u2502  \u2502  - Secrets Manager  \u2502   \u2502 \u2502\n\u2502                             \u2502  \u2502  - ECR              \u2502   \u2502 \u2502\n\u2502                             \u2502  \u2502  - CloudWatch       \u2502   \u2502 \u2502\n\u2502                             \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502 \u2502\n\u2502                             \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"operations/security/#terraform-configuration","title":"Terraform Configuration","text":"<pre><code># vpc.tf\nresource \"aws_vpc\" \"stats_agent\" {\n  cidr_block           = \"10.0.0.0/16\"\n  enable_dns_hostnames = true\n  enable_dns_support   = true\n\n  tags = {\n    Name = \"stats-agent-vpc\"\n  }\n}\n\n# Security Group for Agents\nresource \"aws_security_group\" \"agents\" {\n  name_prefix = \"stats-agent-\"\n  vpc_id      = aws_vpc.stats_agent.id\n\n  # Internal agent communication\n  ingress {\n    from_port = 8000\n    to_port   = 8005\n    protocol  = \"tcp\"\n    self      = true\n  }\n\n  # ALB health checks\n  ingress {\n    from_port       = 8000\n    to_port         = 8005\n    protocol        = \"tcp\"\n    security_groups = [aws_security_group.alb.id]\n  }\n\n  # Outbound for LLM/Search APIs\n  egress {\n    from_port   = 443\n    to_port     = 443\n    protocol    = \"tcp\"\n    cidr_blocks = [\"0.0.0.0/0\"]\n  }\n}\n\n# VPC Endpoint for Secrets Manager (avoid NAT costs, stay private)\nresource \"aws_vpc_endpoint\" \"secrets_manager\" {\n  vpc_id              = aws_vpc.stats_agent.id\n  service_name        = \"com.amazonaws.${var.region}.secretsmanager\"\n  vpc_endpoint_type   = \"Interface\"\n  subnet_ids          = aws_subnet.private[*].id\n  security_group_ids  = [aws_security_group.vpc_endpoints.id]\n  private_dns_enabled = true\n}\n</code></pre>"},{"location":"operations/security/#iam-roles-principle-of-least-privilege","title":"IAM Roles (Principle of Least Privilege)","text":"<pre><code># iam.tf\nresource \"aws_iam_role\" \"stats_agent_task\" {\n  name = \"stats-agent-task-role\"\n\n  assume_role_policy = jsonencode({\n    Version = \"2012-10-17\"\n    Statement = [{\n      Action = \"sts:AssumeRole\"\n      Effect = \"Allow\"\n      Principal = {\n        Service = \"ecs-tasks.amazonaws.com\"\n      }\n    }]\n  })\n}\n\n# Minimal permissions for Secrets Manager\nresource \"aws_iam_role_policy\" \"secrets_access\" {\n  name = \"secrets-access\"\n  role = aws_iam_role.stats_agent_task.id\n\n  policy = jsonencode({\n    Version = \"2012-10-17\"\n    Statement = [\n      {\n        Effect = \"Allow\"\n        Action = [\n          \"secretsmanager:GetSecretValue\"\n        ]\n        Resource = [\n          \"arn:aws:secretsmanager:${var.region}:${var.account_id}:secret:stats-agent/*\"\n        ]\n        Condition = {\n          StringEquals = {\n            \"secretsmanager:VersionStage\" = \"AWSCURRENT\"\n          }\n        }\n      }\n    ]\n  })\n}\n\n# CloudWatch Logs (required for debugging)\nresource \"aws_iam_role_policy\" \"cloudwatch_logs\" {\n  name = \"cloudwatch-logs\"\n  role = aws_iam_role.stats_agent_task.id\n\n  policy = jsonencode({\n    Version = \"2012-10-17\"\n    Statement = [{\n      Effect = \"Allow\"\n      Action = [\n        \"logs:CreateLogStream\",\n        \"logs:PutLogEvents\"\n      ]\n      Resource = \"arn:aws:logs:${var.region}:${var.account_id}:log-group:/ecs/stats-agent:*\"\n    }]\n  })\n}\n</code></pre>"},{"location":"operations/security/#azure-security-configuration","title":"Azure Security Configuration","text":""},{"location":"operations/security/#resource-architecture","title":"Resource Architecture","text":"<pre><code># Create resource group\naz group create --name stats-agent-rg --location eastus\n\n# Create virtual network\naz network vnet create \\\n    --resource-group stats-agent-rg \\\n    --name stats-agent-vnet \\\n    --address-prefix 10.0.0.0/16 \\\n    --subnet-name agents-subnet \\\n    --subnet-prefix 10.0.1.0/24\n\n# Create private endpoint for Key Vault\naz network private-endpoint create \\\n    --resource-group stats-agent-rg \\\n    --name stats-agent-keyvault-pe \\\n    --vnet-name stats-agent-vnet \\\n    --subnet agents-subnet \\\n    --private-connection-resource-id $(az keyvault show --name stats-agent-vault --query id -o tsv) \\\n    --group-id vault \\\n    --connection-name keyvault-connection\n</code></pre>"},{"location":"operations/security/#azure-container-apps-with-managed-identity","title":"Azure Container Apps with Managed Identity","text":"<pre><code>// main.bicep\nresource containerApp 'Microsoft.App/containerApps@2023-05-01' = {\n  name: 'stats-agent-eino'\n  location: resourceGroup().location\n  identity: {\n    type: 'SystemAssigned'\n  }\n  properties: {\n    configuration: {\n      ingress: {\n        external: true\n        targetPort: 8000\n        transport: 'http'\n      }\n      secrets: [\n        {\n          name: 'gemini-api-key'\n          keyVaultUrl: 'https://stats-agent-vault.vault.azure.net/secrets/gemini-api-key'\n          identity: 'system'\n        }\n      ]\n    }\n    template: {\n      containers: [\n        {\n          name: 'stats-agent'\n          image: 'your-registry.azurecr.io/stats-agent:latest'\n          env: [\n            {\n              name: 'GEMINI_API_KEY'\n              secretRef: 'gemini-api-key'\n            }\n          ]\n        }\n      ]\n    }\n  }\n}\n\n// Grant Key Vault access\nresource keyVaultAccessPolicy 'Microsoft.KeyVault/vaults/accessPolicies@2023-07-01' = {\n  name: 'add'\n  parent: keyVault\n  properties: {\n    accessPolicies: [\n      {\n        tenantId: subscription().tenantId\n        objectId: containerApp.identity.principalId\n        permissions: {\n          secrets: ['get', 'list']\n        }\n      }\n    ]\n  }\n}\n</code></pre>"},{"location":"operations/security/#local-development-security","title":"Local Development Security","text":""},{"location":"operations/security/#secure-local-development-setup","title":"Secure Local Development Setup","text":"<ol> <li> <p>Use a secrets manager even locally: <pre><code># Install 1Password CLI or similar\nbrew install 1password-cli\n\n# Load secrets into environment (ephemeral)\neval $(op signin)\nexport GEMINI_API_KEY=$(op read \"op://Development/Stats-Agent/gemini-key\")\nexport SERPER_API_KEY=$(op read \"op://Development/Stats-Agent/serper-key\")\n</code></pre></p> </li> <li> <p>Use direnv for project-specific environments: <pre><code># .envrc (gitignored)\nexport GEMINI_API_KEY=\"$(op read 'op://Development/Stats-Agent/gemini-key')\"\nexport SERPER_API_KEY=\"$(op read 'op://Development/Stats-Agent/serper-key')\"\n</code></pre></p> </li> <li> <p>Docker secrets for local compose: <pre><code># docker-compose.local.yml\nservices:\n  stats-agent-eino:\n    environment:\n      - GEMINI_API_KEY_FILE=/run/secrets/gemini_key\n    secrets:\n      - gemini_key\n\nsecrets:\n  gemini_key:\n    file: ./secrets/gemini_key.txt  # gitignored\n</code></pre></p> </li> </ol>"},{"location":"operations/security/#gitignore-security-entries","title":".gitignore Security Entries","text":"<pre><code># Secrets - NEVER commit\n.env\n.env.local\n.env.*.local\nsecrets/\n*.key\n*.pem\n*credentials*\n*secret*\n\n# IDE might cache secrets\n.idea/\n.vscode/settings.json\n\n# Shell history might contain secrets\n.bash_history\n.zsh_history\n</code></pre>"},{"location":"operations/security/#pre-commit-hooks-for-secret-detection","title":"Pre-commit Hooks for Secret Detection","text":"<pre><code># .pre-commit-config.yaml\nrepos:\n  - repo: https://github.com/gitleaks/gitleaks\n    rev: v8.18.0\n    hooks:\n      - id: gitleaks\n\n  - repo: https://github.com/trufflesecurity/trufflehog\n    rev: v3.63.0\n    hooks:\n      - id: trufflehog\n</code></pre> <p>Install and run: <pre><code>pip install pre-commit\npre-commit install\npre-commit run --all-files\n</code></pre></p>"},{"location":"operations/security/#network-security","title":"Network Security","text":""},{"location":"operations/security/#tls-configuration","title":"TLS Configuration","text":"<ol> <li>External Traffic: Always use TLS 1.2+ for external endpoints</li> <li>Inter-Agent Communication: Use mTLS with SPIFFE or service mesh</li> </ol> <pre><code># Istio service mesh example\napiVersion: security.istio.io/v1beta1\nkind: PeerAuthentication\nmetadata:\n  name: stats-agent-mtls\n  namespace: stats-agent\nspec:\n  mtls:\n    mode: STRICT\n\n---\napiVersion: security.istio.io/v1beta1\nkind: AuthorizationPolicy\nmetadata:\n  name: stats-agent-policy\n  namespace: stats-agent\nspec:\n  rules:\n  - from:\n    - source:\n        principals:\n        - \"cluster.local/ns/stats-agent/sa/orchestration-agent\"\n    to:\n    - operation:\n        methods: [\"POST\"]\n        paths: [\"/search\", \"/synthesize\", \"/verify\"]\n</code></pre>"},{"location":"operations/security/#network-policies-kubernetes","title":"Network Policies (Kubernetes)","text":"<pre><code># network-policy.yaml\napiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: stats-agent-policy\n  namespace: stats-agent\nspec:\n  podSelector:\n    matchLabels:\n      app: stats-agent\n  policyTypes:\n  - Ingress\n  - Egress\n  ingress:\n  # Only from ingress controller\n  - from:\n    - namespaceSelector:\n        matchLabels:\n          name: ingress-nginx\n    ports:\n    - port: 8000\n  # Inter-agent communication\n  - from:\n    - podSelector:\n        matchLabels:\n          app: stats-agent\n    ports:\n    - port: 8001\n    - port: 8002\n    - port: 8003\n    - port: 8004\n  egress:\n  # LLM APIs (HTTPS)\n  - to:\n    - ipBlock:\n        cidr: 0.0.0.0/0\n    ports:\n    - port: 443\n      protocol: TCP\n  # DNS\n  - to:\n    - namespaceSelector: {}\n    ports:\n    - port: 53\n      protocol: UDP\n</code></pre>"},{"location":"operations/security/#api-security","title":"API Security","text":""},{"location":"operations/security/#rate-limiting","title":"Rate Limiting","text":"<pre><code>import (\n    \"golang.org/x/time/rate\"\n    \"sync\"\n)\n\ntype RateLimiter struct {\n    limiters map[string]*rate.Limiter\n    mu       sync.RWMutex\n    rate     rate.Limit\n    burst    int\n}\n\nfunc NewRateLimiter(rps float64, burst int) *RateLimiter {\n    return &amp;RateLimiter{\n        limiters: make(map[string]*rate.Limiter),\n        rate:     rate.Limit(rps),\n        burst:    burst,\n    }\n}\n\nfunc (rl *RateLimiter) GetLimiter(key string) *rate.Limiter {\n    rl.mu.Lock()\n    defer rl.mu.Unlock()\n\n    limiter, exists := rl.limiters[key]\n    if !exists {\n        limiter = rate.NewLimiter(rl.rate, rl.burst)\n        rl.limiters[key] = limiter\n    }\n    return limiter\n}\n\nfunc RateLimitMiddleware(rl *RateLimiter) func(http.Handler) http.Handler {\n    return func(next http.Handler) http.Handler {\n        return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n            key := r.Header.Get(\"X-API-Key\")\n            if key == \"\" {\n                key = r.RemoteAddr\n            }\n\n            if !rl.GetLimiter(key).Allow() {\n                http.Error(w, \"Rate limit exceeded\", http.StatusTooManyRequests)\n                return\n            }\n            next.ServeHTTP(w, r)\n        })\n    }\n}\n</code></pre>"},{"location":"operations/security/#input-validation","title":"Input Validation","text":"<pre><code>import (\n    \"regexp\"\n    \"strings\"\n)\n\nconst (\n    MaxTopicLength = 500\n    MaxURLLength   = 2048\n)\n\nvar (\n    // Prevent injection attacks\n    dangerousPatterns = regexp.MustCompile(`(?i)(script|javascript|vbscript|data:)`)\n\n    // Allow only safe URL schemes\n    allowedSchemes = []string{\"http://\", \"https://\"}\n)\n\nfunc ValidateTopic(topic string) error {\n    if len(topic) &gt; MaxTopicLength {\n        return fmt.Errorf(\"topic exceeds maximum length of %d\", MaxTopicLength)\n    }\n\n    if dangerousPatterns.MatchString(topic) {\n        return fmt.Errorf(\"topic contains potentially dangerous content\")\n    }\n\n    return nil\n}\n\nfunc ValidateURL(urlStr string) error {\n    if len(urlStr) &gt; MaxURLLength {\n        return fmt.Errorf(\"URL exceeds maximum length\")\n    }\n\n    for _, scheme := range allowedSchemes {\n        if strings.HasPrefix(strings.ToLower(urlStr), scheme) {\n            return nil\n        }\n    }\n\n    return fmt.Errorf(\"URL must use http or https scheme\")\n}\n</code></pre>"},{"location":"operations/security/#ssrf-prevention","title":"SSRF Prevention","text":"<p>The verification agent fetches URLs, which creates SSRF risk. Mitigate with:</p> <pre><code>import (\n    \"net\"\n    \"net/url\"\n)\n\nvar (\n    privateIPBlocks []*net.IPNet\n)\n\nfunc init() {\n    for _, cidr := range []string{\n        \"127.0.0.0/8\",    // Loopback\n        \"10.0.0.0/8\",     // RFC1918\n        \"172.16.0.0/12\",  // RFC1918\n        \"192.168.0.0/16\", // RFC1918\n        \"169.254.0.0/16\", // Link-local\n        \"::1/128\",        // IPv6 loopback\n        \"fc00::/7\",       // IPv6 private\n        \"fe80::/10\",      // IPv6 link-local\n    } {\n        _, block, _ := net.ParseCIDR(cidr)\n        privateIPBlocks = append(privateIPBlocks, block)\n    }\n}\n\nfunc isPrivateIP(ip net.IP) bool {\n    for _, block := range privateIPBlocks {\n        if block.Contains(ip) {\n            return true\n        }\n    }\n    return false\n}\n\nfunc SafeFetch(urlStr string) (*http.Response, error) {\n    parsed, err := url.Parse(urlStr)\n    if err != nil {\n        return nil, err\n    }\n\n    // Resolve hostname\n    ips, err := net.LookupIP(parsed.Hostname())\n    if err != nil {\n        return nil, err\n    }\n\n    for _, ip := range ips {\n        if isPrivateIP(ip) {\n            return nil, fmt.Errorf(\"access to private IP addresses is not allowed\")\n        }\n    }\n\n    // Use a custom transport that doesn't follow redirects to private IPs\n    client := &amp;http.Client{\n        CheckRedirect: func(req *http.Request, via []*http.Request) error {\n            // Re-validate redirect target\n            ips, _ := net.LookupIP(req.URL.Hostname())\n            for _, ip := range ips {\n                if isPrivateIP(ip) {\n                    return fmt.Errorf(\"redirect to private IP not allowed\")\n                }\n            }\n            return nil\n        },\n        Timeout: 30 * time.Second,\n    }\n\n    return client.Get(urlStr)\n}\n</code></pre>"},{"location":"operations/security/#container-security","title":"Container Security","text":""},{"location":"operations/security/#dockerfile-best-practices","title":"Dockerfile Best Practices","text":"<pre><code># Dockerfile.secure\n# Build stage\nFROM golang:1.21-alpine AS builder\n\n# Security: Run as non-root during build\nRUN adduser -D -g '' appuser\nUSER appuser\n\nWORKDIR /app\nCOPY --chown=appuser:appuser go.mod go.sum ./\nRUN go mod download\n\nCOPY --chown=appuser:appuser . .\nRUN CGO_ENABLED=0 GOOS=linux go build -ldflags=\"-w -s\" -o /stats-agent ./main.go\n\n# Runtime stage\nFROM gcr.io/distroless/static-debian12:nonroot\n\n# Security: Use non-root user (65532 is nonroot in distroless)\nUSER nonroot:nonroot\n\nCOPY --from=builder /stats-agent /stats-agent\n\n# Security: Read-only filesystem\nENTRYPOINT [\"/stats-agent\"]\n</code></pre>"},{"location":"operations/security/#image-scanning","title":"Image Scanning","text":"<pre><code># Scan with Trivy\ntrivy image --severity HIGH,CRITICAL your-registry/stats-agent:latest\n\n# Scan with Grype\ngrype your-registry/stats-agent:latest\n</code></pre>"},{"location":"operations/security/#kubernetes-pod-security","title":"Kubernetes Pod Security","text":"<pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: stats-agent\nspec:\n  securityContext:\n    runAsNonRoot: true\n    runAsUser: 65532\n    fsGroup: 65532\n    seccompProfile:\n      type: RuntimeDefault\n  containers:\n  - name: stats-agent\n    image: your-registry/stats-agent:latest\n    securityContext:\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n      capabilities:\n        drop:\n        - ALL\n    resources:\n      limits:\n        cpu: \"1\"\n        memory: \"512Mi\"\n      requests:\n        cpu: \"100m\"\n        memory: \"128Mi\"\n</code></pre>"},{"location":"operations/security/#monitoring-and-auditing","title":"Monitoring and Auditing","text":""},{"location":"operations/security/#structured-logging-no-secrets","title":"Structured Logging (No Secrets)","text":"<pre><code>import (\n    \"log/slog\"\n)\n\nfunc NewSecureLogger() *slog.Logger {\n    return slog.New(slog.NewJSONHandler(os.Stdout, &amp;slog.HandlerOptions{\n        ReplaceAttr: func(groups []string, a slog.Attr) slog.Attr {\n            // Redact sensitive fields\n            sensitiveKeys := []string{\"api_key\", \"token\", \"password\", \"secret\", \"authorization\"}\n            for _, key := range sensitiveKeys {\n                if strings.Contains(strings.ToLower(a.Key), key) {\n                    return slog.Attr{Key: a.Key, Value: slog.StringValue(\"[REDACTED]\")}\n                }\n            }\n            return a\n        },\n    }))\n}\n\n// Usage\nlogger.Info(\"processing request\",\n    slog.String(\"topic\", req.Topic),\n    slog.String(\"api_key\", apiKey),  // Will be redacted\n    slog.Int(\"min_stats\", req.MinStats),\n)\n</code></pre>"},{"location":"operations/security/#audit-trail","title":"Audit Trail","text":"<pre><code>type AuditEvent struct {\n    Timestamp   time.Time `json:\"timestamp\"`\n    Action      string    `json:\"action\"`\n    UserID      string    `json:\"user_id,omitempty\"`\n    Resource    string    `json:\"resource\"`\n    Result      string    `json:\"result\"`\n    SourceIP    string    `json:\"source_ip\"`\n    RequestID   string    `json:\"request_id\"`\n    Details     any       `json:\"details,omitempty\"`\n}\n\nfunc LogAuditEvent(ctx context.Context, event AuditEvent) {\n    event.Timestamp = time.Now()\n    event.RequestID = GetRequestID(ctx)\n\n    // Send to audit log stream (CloudWatch, Azure Monitor, etc.)\n    auditLogger.Info(\"audit\",\n        slog.String(\"action\", event.Action),\n        slog.String(\"user_id\", event.UserID),\n        slog.String(\"resource\", event.Resource),\n        slog.String(\"result\", event.Result),\n        slog.String(\"source_ip\", event.SourceIP),\n        slog.String(\"request_id\", event.RequestID),\n    )\n}\n</code></pre>"},{"location":"operations/security/#metrics-for-security-monitoring","title":"Metrics for Security Monitoring","text":"<pre><code>import (\n    \"github.com/prometheus/client_golang/prometheus\"\n)\n\nvar (\n    authFailures = prometheus.NewCounterVec(\n        prometheus.CounterOpts{\n            Name: \"stats_agent_auth_failures_total\",\n            Help: \"Total authentication failures\",\n        },\n        []string{\"reason\", \"source_ip\"},\n    )\n\n    rateLimitHits = prometheus.NewCounterVec(\n        prometheus.CounterOpts{\n            Name: \"stats_agent_rate_limit_hits_total\",\n            Help: \"Rate limit violations\",\n        },\n        []string{\"client_id\"},\n    )\n\n    suspiciousRequests = prometheus.NewCounterVec(\n        prometheus.CounterOpts{\n            Name: \"stats_agent_suspicious_requests_total\",\n            Help: \"Requests flagged as suspicious\",\n        },\n        []string{\"reason\"},\n    )\n)\n\nfunc init() {\n    prometheus.MustRegister(authFailures, rateLimitHits, suspiciousRequests)\n}\n</code></pre>"},{"location":"operations/security/#incident-response","title":"Incident Response","text":""},{"location":"operations/security/#credential-rotation-procedure","title":"Credential Rotation Procedure","text":"<p>If a credential is compromised:</p> <ol> <li>Immediately rotate the compromised credential in the secrets manager</li> <li>Restart affected services to pick up new credentials</li> <li>Review audit logs for unauthorized access</li> <li>Assess impact - what data/services were accessible</li> <li>Notify affected parties if user data was accessed</li> </ol> <pre><code># AWS: Rotate secret\naws secretsmanager rotate-secret --secret-id stats-agent/llm-keys\n\n# Azure: Create new version\naz keyvault secret set \\\n    --vault-name stats-agent-vault \\\n    --name gemini-api-key \\\n    --value \"new-rotated-key\"\n\n# Restart services (ECS)\naws ecs update-service \\\n    --cluster stats-agent \\\n    --service stats-agent-eino \\\n    --force-new-deployment\n</code></pre>"},{"location":"operations/security/#security-contact","title":"Security Contact","text":"<p>For security issues with this project, contact the maintainers via GitHub Security Advisories.</p>"},{"location":"operations/security/#compliance-considerations","title":"Compliance Considerations","text":""},{"location":"operations/security/#soc-2-alignment","title":"SOC 2 Alignment","text":"Control Implementation CC6.1 - Logical Access Okta integration, IAM policies CC6.2 - System Access SPIFFE/SPIRE workload identity CC6.3 - Data Classification Secrets in dedicated managers CC6.6 - Encryption TLS for transit, KMS for rest CC7.2 - System Monitoring CloudWatch/Azure Monitor logs"},{"location":"operations/security/#gdpr-considerations","title":"GDPR Considerations","text":"<ul> <li>User queries may contain personal data</li> <li>Implement data retention policies</li> <li>Provide data export/deletion capabilities</li> <li>Log access to personal data</li> </ul>"},{"location":"operations/security/#pci-dss-if-handling-payment-data","title":"PCI-DSS (if handling payment data)","text":"<ul> <li>Network segmentation</li> <li>Encryption of cardholder data</li> <li>Access control measures</li> <li>Regular security testing</li> </ul>"},{"location":"operations/security/#summary-security-checklist","title":"Summary: Security Checklist","text":""},{"location":"operations/security/#before-deployment","title":"Before Deployment","text":"<ul> <li>[ ] Secrets stored in cloud secrets manager (not environment variables)</li> <li>[ ] IAM roles follow least privilege principle</li> <li>[ ] Container images scanned for vulnerabilities</li> <li>[ ] Network policies restrict inter-service communication</li> <li>[ ] TLS enabled for all external endpoints</li> <li>[ ] Pre-commit hooks detect secret leakage</li> <li>[ ] Input validation implemented</li> <li>[ ] SSRF protections in place</li> </ul>"},{"location":"operations/security/#ongoing-operations","title":"Ongoing Operations","text":"<ul> <li>[ ] Regular credential rotation (90 days max)</li> <li>[ ] Security monitoring alerts configured</li> <li>[ ] Audit logs reviewed periodically</li> <li>[ ] Dependency updates for security patches</li> <li>[ ] Penetration testing annually</li> <li>[ ] Incident response plan documented</li> </ul>"},{"location":"operations/security/#for-enterprise-deployments","title":"For Enterprise Deployments","text":"<ul> <li>[ ] Okta/IdP integration for user authentication</li> <li>[ ] SPIFFE/SPIRE for workload identity</li> <li>[ ] Service mesh (Istio/Linkerd) for mTLS</li> <li>[ ] Just-in-time access for admin operations</li> <li>[ ] SOC 2 controls documented</li> </ul>"},{"location":"operations/security/#references","title":"References","text":"<ul> <li>AWS Secrets Manager Best Practices</li> <li>Azure Key Vault Security</li> <li>SPIFFE/SPIRE Documentation</li> <li>Okta API Access Management</li> <li>OWASP API Security Top 10</li> <li>CIS Docker Benchmark</li> </ul>"},{"location":"reference/roadmap/","title":"Roadmap","text":"<p>This document outlines the planned features and enhancements for the Statistics Agent Team project.</p>"},{"location":"reference/roadmap/#orchestrator-comparison-adk-vs-eino","title":"Orchestrator Comparison (ADK vs Eino)","text":"<p>The project supports two orchestration approaches for comparison:</p> Orchestrator Protocol Routing Style Status ADK A2A (:900x) LLM-driven (Hybrid) \u2705 Implemented Eino HTTP (:800x) Code-driven (Graph) \u2705 Implemented"},{"location":"reference/roadmap/#planned-comparison-metrics","title":"Planned Comparison Metrics","text":"<ul> <li>\ud83d\udcca Response time - ADK vs Eino orchestrator latency</li> <li>\ud83d\udcca Cost per query - LLM calls for orchestration decisions</li> <li>\ud83d\udcca Verification rate - Does routing strategy affect accuracy?</li> <li>\ud83d\udcca Predictability - Variance in execution paths and timing</li> <li>\ud83d\udcca Error recovery - How each handles failures</li> </ul>"},{"location":"reference/roadmap/#why-both","title":"Why Both?","text":"<ul> <li>ADK (Hybrid): Code-defined agent structure, LLM-driven routing/delegation</li> <li>Eino (Code-driven): Deterministic graph, predictable execution, lower cost</li> </ul> <p>Current recommendation: Eino for production (faster, cheaper, reproducible)</p>"},{"location":"reference/roadmap/#refined-a2a-strategy-external-agent-services","title":"Refined A2A Strategy: External Agent Services","text":"<p>Key insight: A2A is most valuable for external interoperability, not internal communication.</p>"},{"location":"reference/roadmap/#agent-reusability-analysis","title":"Agent Reusability Analysis","text":"Agent Capability External Value Verification Validate excerpt exists in URL \u2705 High - Universal problem Research Search web for topic \u2705 Medium - Generic capability Synthesis Extract statistics from pages \u26a0\ufe0f Low - Specific to statistics Orchestrator Coordinate pipeline \u274c None - Internal only"},{"location":"reference/roadmap/#recommended-architecture","title":"Recommended Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  stats-agent-team (internal)                                \u2502\n\u2502                                                             \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                                        \u2502\n\u2502  \u2502 Eino Orchestrator\u2502\u2500\u2500HTTP\u2500\u2500\u2192 Research, Synthesis          \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518          (internal, simple)            \u2502\n\u2502           \u2502                                                 \u2502\n\u2502           \u2502 HTTP or A2A                                     \u2502\n\u2502           \u25bc                                                 \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                                        \u2502\n\u2502  \u2502 Verification    \u2502\u2190\u2500\u2500A2A\u2500\u2500\u2500\u2500\u2500 External A2A Clients        \u2502\n\u2502  \u2502 Agent           \u2502           (other agent systems)        \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                                        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"reference/roadmap/#verification-as-a-service","title":"Verification-as-a-Service","text":"<p>The Verification Agent solves a universal problem: LLMs hallucinate URLs and citations.</p> <p>Any agent system that generates sourced content needs verification: - Research assistants - Content generators - Fact-checking tools - RAG systems</p> <p>Proposed A2A Agent Card:</p> <pre><code>name: \"Verification Agent\"\ndescription: \"Verify that excerpts and statistics exist in source URLs\"\nskills:\n  - name: \"verify_excerpt\"\n    description: \"Check if text excerpt exists in URL\"\n    input: { url: string, excerpt: string }\n    output: { verified: boolean, reason: string }\n  - name: \"verify_statistic\"\n    description: \"Verify numerical statistic with context\"\n    input: { url: string, value: number, excerpt: string }\n    output: { verified: boolean, value_match: boolean, excerpt_match: boolean }\n</code></pre>"},{"location":"reference/roadmap/#protocol-strategy","title":"Protocol Strategy","text":"Component Protocol Rationale Eino \u2192 Internal agents HTTP Simple, no overhead Verification Agent HTTP + A2A A2A for external clients Research Agent HTTP + A2A Optional external exposure <p>Don't add A2A client to Eino unless there's a concrete need. HTTP is simpler for internal communication.</p>"},{"location":"reference/roadmap/#q1-2026","title":"Q1 2026","text":"<ul> <li>\u2728 Perplexity API integration - Built-in search without separate provider</li> <li>\u2728 Range statistics support - Add <code>value_max</code> field for ranges like \"79-96%\"</li> <li>\u2728 Response streaming - Faster perceived performance with streaming results</li> <li>\ud83d\udcca Orchestrator benchmarks - Publish ADK vs Eino comparison results</li> <li>\ud83c\udf10 Verification-as-a-Service - Document and promote Verification Agent as external A2A service</li> </ul>"},{"location":"reference/roadmap/#q2-2026","title":"Q2 2026","text":"<ul> <li>\u2728 Multi-language support - Spanish, French, German, Chinese sources</li> <li>\u2728 Caching layer - Reduce redundant searches and API costs</li> <li>\u2728 GraphQL API - Alternative query interface</li> <li>\ud83c\udf10 Research Agent external - Expose Research Agent via A2A if demand exists</li> </ul>"},{"location":"reference/roadmap/#q3-2026","title":"Q3 2026","text":"<ul> <li>\u2728 Browser extension - Real-time fact-checking while browsing</li> <li>\u2728 Notion/Confluence integrations - Embed verified statistics in docs</li> <li>\u2728 Advanced citation formats - APA, MLA, Chicago styles</li> </ul>"},{"location":"reference/roadmap/#future-considerations","title":"Future Considerations","text":"<ul> <li>\ud83d\udd2e Academic database integration (PubMed, arXiv, JSTOR)</li> <li>\ud83d\udd2e Paywall-aware fetching with institutional credentials</li> <li>\ud83d\udd2e Historical statistics tracking and trend analysis</li> <li>\ud83d\udd2e Confidence scoring based on source reputation</li> </ul>"},{"location":"reference/roadmap/#contributing","title":"Contributing","text":"<p>This roadmap is community-driven. Submit feature requests on GitHub Issues!</p> <p>To propose a new feature: 1. Check existing issues for duplicates 2. Open a new issue with the <code>enhancement</code> label 3. Describe the use case and proposed solution 4. Community feedback helps prioritize features</p>"},{"location":"releases/v0.1.0/","title":"Release Notes v0.1.0","text":"<p>Release Date: December 13, 2025</p> <p>This is the initial release of Statistics Agent Team, a multi-agent system for finding and verifying statistics from reputable web sources.</p>"},{"location":"releases/v0.1.0/#overview","title":"Overview","text":"<p>Statistics Agent Team is built with Google ADK (Agent Development Kit) and Eino, implementing a sophisticated multi-agent architecture that leverages LLMs and web search to find verifiable statistics from well-known and respected publishers.</p>"},{"location":"releases/v0.1.0/#features","title":"Features","text":""},{"location":"releases/v0.1.0/#3-agent-architecture","title":"3-Agent Architecture","text":"<p>The system implements three specialized agents:</p>"},{"location":"releases/v0.1.0/#research-agent-agentsresearch","title":"Research Agent (<code>agents/research/</code>)","text":"<ul> <li>Built with Google ADK and Gemini 2.0 Flash model</li> <li>Executes web searches for statistics on given topics</li> <li>Prioritizes reputable sources (academic, government, research organizations)</li> <li>Extracts candidate statistics with context</li> <li>Returns structured data for verification</li> <li>Port: 8001</li> </ul>"},{"location":"releases/v0.1.0/#verification-agent-agentsverification","title":"Verification Agent (<code>agents/verification/</code>)","text":"<ul> <li>Built with Google ADK and Gemini 2.0 Flash model</li> <li>Fetches actual source content from URLs</li> <li>Searches for verbatim excerpts in source</li> <li>Validates numerical values match exactly</li> <li>Flags hallucinations and discrepancies</li> <li>Returns verification results with reasons</li> <li>Port: 8002</li> </ul>"},{"location":"releases/v0.1.0/#orchestration-agents-two-options","title":"Orchestration Agents (Two Options)","text":"<p>ADK Orchestration (<code>agents/orchestration/</code>) - Built with Google ADK and Gemini 2.0 Flash model - LLM-based decision making for workflow coordination - Implements adaptive retry logic - Dynamic quality control - Port: 8000</p> <p>Eino Orchestration (<code>agents/orchestration-eino/</code>) - Recommended - Deterministic graph-based workflow - Type-safe orchestration with compile-time checks - Predictable, reproducible behavior - Faster and lower cost (no LLM for orchestration) - Port: 8003</p>"},{"location":"releases/v0.1.0/#mcp-server-integration","title":"MCP Server Integration","text":"<ul> <li>Full MCP (Model Context Protocol) server implementation</li> <li>Integration with Claude Code and other MCP clients</li> <li>Exposes Eino orchestration via MCP tools</li> <li><code>mcp/server/main.go</code> - Server implementation</li> <li><code>MCP_SERVER.md</code> - Integration documentation</li> </ul>"},{"location":"releases/v0.1.0/#multi-llm-provider-support","title":"Multi-LLM Provider Support","text":"<p>Configurable LLM providers with unified interface: - Gemini (default) - Google's Gemini 2.0 Flash - Claude - Anthropic Claude models - OpenAI - GPT-4 and GPT-3.5 - Ollama - Local LLM deployment</p> <p>Configuration via environment variables documented in <code>LLM_CONFIGURATION.md</code>.</p>"},{"location":"releases/v0.1.0/#structured-output","title":"Structured Output","text":"<p>Statistics returned in JSON format with complete metadata:</p> <pre><code>{\n  \"name\": \"Global temperature increase since pre-industrial times\",\n  \"value\": 1.1,\n  \"unit\": \"\u00b0C\",\n  \"source\": \"IPCC Sixth Assessment Report\",\n  \"source_url\": \"https://www.ipcc.ch/...\",\n  \"excerpt\": \"Global surface temperature has increased by approximately 1.1\u00b0C...\",\n  \"verified\": true,\n  \"date_found\": \"2025-12-13T10:30:00Z\"\n}\n</code></pre>"},{"location":"releases/v0.1.0/#core-capabilities","title":"Core Capabilities","text":"<ul> <li>Multi-agent orchestration with workflow coordination</li> <li>Google ADK integration for LLM-based agents</li> <li>Eino framework for deterministic graph orchestration</li> <li>Source verification to prevent hallucinations</li> <li>Reputable source prioritization</li> <li>HTTP APIs for all agents</li> <li>Retry logic for ensuring quality results</li> <li>Function tools for structured agent capabilities</li> </ul>"},{"location":"releases/v0.1.0/#project-structure","title":"Project Structure","text":"<pre><code>stats-agent-team/\n\u251c\u2500\u2500 agents/\n\u2502   \u251c\u2500\u2500 orchestration/       # ADK-based orchestration agent\n\u2502   \u251c\u2500\u2500 orchestration-eino/  # Eino-based orchestration agent\n\u2502   \u251c\u2500\u2500 research/            # Research agent\n\u2502   \u2514\u2500\u2500 verification/        # Verification agent\n\u251c\u2500\u2500 mcp/\n\u2502   \u2514\u2500\u2500 server/              # MCP server implementation\n\u251c\u2500\u2500 pkg/\n\u2502   \u251c\u2500\u2500 config/              # Configuration management\n\u2502   \u251c\u2500\u2500 httpclient/          # HTTP client utilities\n\u2502   \u251c\u2500\u2500 llm/                 # LLM factory and adapters\n\u2502   \u251c\u2500\u2500 models/              # Data models\n\u2502   \u2514\u2500\u2500 orchestration/       # Eino orchestration logic\n\u251c\u2500\u2500 main.go                  # CLI entry point\n\u2514\u2500\u2500 Makefile                 # Build and run targets\n</code></pre>"},{"location":"releases/v0.1.0/#documentation","title":"Documentation","text":"<ul> <li><code>README.md</code> - Project overview and quick start</li> <li><code>README_EINO.md</code> - Eino orchestrator details</li> <li><code>LLM_CONFIGURATION.md</code> - LLM provider setup</li> <li><code>MCP_SERVER.md</code> - MCP integration guide</li> </ul>"},{"location":"releases/v0.1.0/#requirements","title":"Requirements","text":"<ul> <li>Go 1.21 or higher</li> <li>LLM API key (Gemini, Claude, OpenAI, or Ollama)</li> </ul>"},{"location":"releases/v0.1.0/#quick-start","title":"Quick Start","text":"<pre><code># Install dependencies\nmake install\n\n# Set API key\nexport GOOGLE_API_KEY=\"your-api-key\"\n\n# Run with Eino orchestration (recommended)\nmake run-eino\n\n# Or run all agents\nmake run-all\n</code></pre>"},{"location":"releases/v0.1.0/#cicd","title":"CI/CD","text":"<ul> <li>GitHub Actions workflows for build and lint</li> <li>Dependabot configuration for dependency updates</li> <li>golangci-lint integration for code quality</li> </ul>"},{"location":"releases/v0.1.0/#contributors","title":"Contributors","text":"<ul> <li>John Wang (@grokify)</li> </ul> <p>Repository: https://github.com/grokify/stats-agent-team</p>"},{"location":"releases/v0.2.0/","title":"Release Notes v0.2.0","text":"<p>Release Date: December 14, 2025</p> <p>This is a major release that introduces the complete 4-agent architecture, Docker deployment, multi-LLM provider support, and real web search integration.</p>"},{"location":"releases/v0.2.0/#highlights","title":"Highlights","text":"<ul> <li>4-Agent Architecture - Complete multi-agent pipeline with Research, Synthesis, Verification, and Orchestration agents</li> <li>Docker Deployment - Full containerization with docker-compose support</li> <li>Multi-LLM Support - Unified interface for Gemini, Claude, OpenAI, xAI Grok, and Ollama</li> <li>Real Web Search - Serper/SerpAPI integration for live search results</li> </ul>"},{"location":"releases/v0.2.0/#new-features","title":"New Features","text":""},{"location":"releases/v0.2.0/#synthesis-agent-agentssynthesis","title":"Synthesis Agent (<code>agents/synthesis/</code>)","text":"<p>New LLM-powered agent for extracting statistics from web content:</p> <ul> <li>Fetches webpage content from URLs provided by Research agent</li> <li>Uses LLM analysis to extract numerical statistics</li> <li>Finds verbatim excerpts containing statistics</li> <li>Creates structured <code>CandidateStatistic</code> objects with metadata</li> <li>Runs on port 8004</li> </ul>"},{"location":"releases/v0.2.0/#4-agent-architecture-documentation","title":"4-Agent Architecture Documentation","text":"<p>Added comprehensive architecture documentation (<code>4_AGENT_ARCHITECTURE.md</code>) describing:</p> <ul> <li>Agent responsibilities and communication patterns</li> <li>Research \u2192 Synthesis \u2192 Verification pipeline</li> <li>Orchestration strategies (ADK and Eino)</li> <li>Port assignments and API contracts</li> </ul>"},{"location":"releases/v0.2.0/#docker-support","title":"Docker Support","text":"<p>Complete containerization for easy deployment:</p> <ul> <li><code>Dockerfile</code> - Multi-stage build for optimized images</li> <li><code>docker-compose.yml</code> - Full stack orchestration</li> <li><code>docker-entrypoint.sh</code> - Flexible agent startup script</li> <li><code>DOCKER.md</code> - Comprehensive Docker deployment guide</li> <li><code>.dockerignore</code> - Optimized build context</li> </ul>"},{"location":"releases/v0.2.0/#serperserpapi-integration","title":"Serper/SerpAPI Integration","text":"<p>Real web search capabilities via the <code>metasearch</code> library:</p> <ul> <li><code>pkg/search/service.go</code> - Unified search service</li> <li>Support for Serper and SerpAPI providers</li> <li>Configurable result limits and filtering</li> <li><code>SEARCH_INTEGRATION.md</code> - Search provider documentation</li> </ul>"},{"location":"releases/v0.2.0/#multi-llm-provider-support","title":"Multi-LLM Provider Support","text":"<p>Unified LLM interface supporting multiple providers:</p> <ul> <li>Gemini (Google) - Default provider</li> <li>Claude (Anthropic) - Via gollm adapter</li> <li>OpenAI - GPT-4 and GPT-3.5 support</li> <li>xAI Grok - xAI's Grok models</li> <li>Ollama - Local LLM deployment</li> </ul> <p>New files: - <code>pkg/llm/adapters/gollm_adapter.go</code> - Multi-provider adapter - <code>pkg/llm/factory.go</code> - Enhanced model factory - <code>MULTI_LLM_SUPPORT.md</code> - Provider configuration guide - <code>LLM_INTEGRATION.md</code> - LLM integration documentation</p>"},{"location":"releases/v0.2.0/#direct-llm-search-mode","title":"Direct LLM Search Mode","text":"<p>Alternative search mode using LLM memory (for quick results without web verification):</p> <ul> <li><code>pkg/direct/llm_search.go</code> - Direct search implementation</li> <li><code>--direct</code> CLI flag for direct mode</li> <li>Optional web verification of LLM-generated statistics</li> </ul>"},{"location":"releases/v0.2.0/#base-agent-package","title":"Base Agent Package","text":"<p>New shared agent utilities:</p> <ul> <li><code>pkg/agent/base.go</code> - Common agent functionality</li> <li>Standardized health checks and configuration</li> </ul>"},{"location":"releases/v0.2.0/#enhancements","title":"Enhancements","text":"<ul> <li>Orchestration agent improvements - Better coordination logic and error handling</li> <li>Research agent refactoring - Cleaner separation of concerns</li> <li>Eino orchestration updates - Improved graph-based workflow</li> <li>JSON extraction - Enhanced <code>extractJSONFromMarkdown()</code> function</li> </ul>"},{"location":"releases/v0.2.0/#documentation","title":"Documentation","text":"<ul> <li><code>4_AGENT_ARCHITECTURE.md</code> - Complete architecture documentation</li> <li><code>DOCKER.md</code> - Docker deployment guide</li> <li><code>LLM_INTEGRATION.md</code> - LLM provider integration</li> <li><code>MULTI_LLM_SUPPORT.md</code> - Multi-provider configuration</li> <li><code>SEARCH_INTEGRATION.md</code> - Search provider setup</li> <li>Updated <code>README.md</code> with new features and examples</li> </ul>"},{"location":"releases/v0.2.0/#dependencies","title":"Dependencies","text":"<ul> <li>Added <code>github.com/grokify/gollm</code> for multi-LLM support</li> <li>Added <code>github.com/grokify/metasearch</code> for web search</li> <li>Various go.mod updates for compatibility</li> </ul>"},{"location":"releases/v0.2.0/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>Fixed search functionality (<code>ad14475</code>)</li> <li>Fixed LLM support for synthesis and verification agents (<code>99c9447</code>)</li> <li>Various golangci-lint fixes</li> </ul>"},{"location":"releases/v0.2.0/#breaking-changes","title":"Breaking Changes","text":"<ul> <li>Removed pre-built binaries from <code>bin/</code> directory (now built from source)</li> <li>Research agent API changes for 4-agent architecture compatibility</li> </ul>"},{"location":"releases/v0.2.0/#migration-guide","title":"Migration Guide","text":""},{"location":"releases/v0.2.0/#from-v010","title":"From v0.1.0","text":"<ol> <li> <p>Update environment variables: <pre><code># Search provider (required for web search)\nexport SERPER_API_KEY=\"your-key\"\n# or\nexport SERPAPI_API_KEY=\"your-key\"\n</code></pre></p> </li> <li> <p>Docker deployment (recommended): <pre><code>docker-compose up -d\n</code></pre></p> </li> <li> <p>Local development: <pre><code>make install\nmake run-all-eino  # Recommended\n# or\nmake run-all       # ADK orchestration\n</code></pre></p> </li> </ol>"},{"location":"releases/v0.2.0/#llm-provider-configuration","title":"LLM Provider Configuration","text":"<pre><code># Gemini (default)\nexport GOOGLE_API_KEY=\"your-key\"\n\n# Claude\nexport LLM_PROVIDER=\"claude\"\nexport ANTHROPIC_API_KEY=\"your-key\"\n\n# OpenAI\nexport LLM_PROVIDER=\"openai\"\nexport OPENAI_API_KEY=\"your-key\"\n\n# xAI Grok\nexport LLM_PROVIDER=\"xai\"\nexport XAI_API_KEY=\"your-key\"\n\n# Ollama (local)\nexport LLM_PROVIDER=\"ollama\"\nexport OLLAMA_URL=\"http://localhost:11434\"\n</code></pre>"},{"location":"releases/v0.2.0/#contributors","title":"Contributors","text":"<ul> <li>John Wang (@grokify)</li> </ul> <p>Full Changelog: <code>v0.1.0...v0.2.0</code></p>"},{"location":"releases/v0.3.0/","title":"Release Notes v0.3.0","text":"<p>Release Date: December 21, 2025</p> <p>This release introduces major features for agent interoperability, observability, and security, along with performance improvements and comprehensive documentation updates.</p>"},{"location":"releases/v0.3.0/#highlights","title":"Highlights","text":"<ul> <li>A2A Protocol Support - Full inter-agent protocol implementation for agent interoperability</li> <li>LLM Observability - MetaObserve integration for tracing and monitoring LLM operations</li> <li>Security Documentation - Comprehensive security guide for production deployments</li> <li>Project Roadmap - Published feature roadmap for Q1-Q3 2026</li> </ul>"},{"location":"releases/v0.3.0/#new-features","title":"New Features","text":""},{"location":"releases/v0.3.0/#a2a-inter-agent-protocol-support","title":"A2A Inter-Agent Protocol Support","text":"<p>Added support for Google's Agent-to-Agent (A2A) protocol across all agents, enabling standardized inter-agent communication and interoperability:</p> <ul> <li><code>agents/orchestration/a2a.go</code> - A2A server for ADK orchestration agent</li> <li><code>agents/orchestration-eino/a2a.go</code> - A2A server for Eino orchestration agent</li> <li><code>agents/research/a2a.go</code> - A2A server for research agent</li> <li><code>agents/synthesis/a2a.go</code> - A2A server for synthesis agent</li> <li><code>agents/verification/a2a.go</code> - A2A server for verification agent</li> </ul> <p>Uses the <code>a2aproject/a2a-go</code> library with Google ADK's <code>adka2a</code> integration.</p>"},{"location":"releases/v0.3.0/#llm-observability-via-metaobserve","title":"LLM Observability via MetaObserve","text":"<p>Added integrated observability for LLM operations with support for multiple backends:</p> <ul> <li>Opik - Comet ML's LLM observability platform</li> <li>Langfuse - Open-source LLM observability</li> <li>Phoenix - Arize AI's open-source observability</li> </ul> <p>Configuration via environment variables: - <code>OBSERVABILITY_ENABLED=true</code> - <code>OBSERVABILITY_PROVIDER=opik|langfuse|phoenix</code> - <code>OBSERVABILITY_PROJECT=your-project-name</code></p>"},{"location":"releases/v0.3.0/#llm-adapter-refactoring","title":"LLM Adapter Refactoring","text":"<p>Replaced the gollm adapter with the new MetaLLM adapter (<code>pkg/llm/adapters/metallm_adapter.go</code>) for improved multi-LLM provider support with built-in observability hooks.</p>"},{"location":"releases/v0.3.0/#documentation","title":"Documentation","text":""},{"location":"releases/v0.3.0/#security-guide-readme_securitymd","title":"Security Guide (<code>README_SECURITY.md</code>)","text":"<p>Comprehensive security documentation covering: - Threat modeling for multi-agent systems - Credential management best practices - Cloud deployment security (AWS/Azure) - SPIFFE/SPIRE workload identity - Network and API security - Container security hardening - Incident response procedures - Compliance considerations</p>"},{"location":"releases/v0.3.0/#project-roadmap-roadmapmd","title":"Project Roadmap (<code>ROADMAP.md</code>)","text":"<p>Published feature roadmap including: - Q1 2026: Perplexity API, range statistics, response streaming - Q2 2026: Multi-language support, caching layer, GraphQL API - Q3 2026: Browser extension, Notion/Confluence integrations, citation formats</p>"},{"location":"releases/v0.3.0/#presentation-materials","title":"Presentation Materials","text":"<p>Added <code>presentation.md</code> with comprehensive project overview for conferences and demos.</p>"},{"location":"releases/v0.3.0/#enhancements","title":"Enhancements","text":"<ul> <li>Performance improvement - Enhanced team stats finding via <code>make run-all-eino</code></li> <li>Updated README - Revised architecture diagram and feature documentation</li> <li>Interactive documentation - Added <code>docs/index.html</code> for browsable documentation</li> </ul>"},{"location":"releases/v0.3.0/#dependencies","title":"Dependencies","text":"<ul> <li>Updated <code>github.com/cloudwego/eino</code> from 0.7.8 to 0.7.10</li> <li>Added <code>github.com/a2aproject/a2a-go</code> for A2A protocol support</li> <li>Added <code>github.com/grokify/metallm</code> for unified LLM interface</li> <li>Added <code>github.com/grokify/metaobserve</code> for observability integration</li> <li>Various go.mod dependency updates</li> </ul>"},{"location":"releases/v0.3.0/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>Fixed various linting issues identified by golangci-lint</li> </ul>"},{"location":"releases/v0.3.0/#breaking-changes","title":"Breaking Changes","text":"<p>None.</p>"},{"location":"releases/v0.3.0/#migration-guide","title":"Migration Guide","text":""},{"location":"releases/v0.3.0/#enabling-observability-optional","title":"Enabling Observability (Optional)","text":"<p>To enable LLM observability, set the following environment variables:</p> <pre><code>export OBSERVABILITY_ENABLED=true\nexport OBSERVABILITY_PROVIDER=opik  # or langfuse, phoenix\nexport OBSERVABILITY_PROJECT=stats-agent\nexport OBSERVABILITY_API_KEY=your-api-key  # if required by provider\n</code></pre>"},{"location":"releases/v0.3.0/#a2a-protocol","title":"A2A Protocol","text":"<p>A2A servers run alongside existing HTTP servers. No configuration changes required - A2A support is automatically available when agents start.</p>"},{"location":"releases/v0.3.0/#contributors","title":"Contributors","text":"<ul> <li>John Wang (@grokify)</li> </ul> <p>Full Changelog: <code>v0.2.0...v0.3.0</code></p>"},{"location":"releases/v0.4.0/","title":"Release Notes v0.4.0","text":"<p>Release Date: December 27, 2025</p> <p>This release introduces a major organization transition, comprehensive Helm chart deployment, parameterized Docker builds, and a robust CI/CD pipeline with security scanning and validation.</p>"},{"location":"releases/v0.4.0/#highlights","title":"Highlights","text":"<ul> <li>Organization Migration - Module moved from <code>grokify</code> to <code>agentplexus</code> organization</li> <li>Dependency Rebranding - Meta libraries renamed to Omni libraries</li> <li>Helm Chart - Production-ready Kubernetes deployment with Minikube and EKS support</li> <li>Parameterized Dockerfile - Single Dockerfile for building all agent images</li> <li>CI/CD Pipeline - Comprehensive security scanning, validation, and testing</li> <li>MkDocs Documentation Site - Full documentation site with Material theme</li> </ul>"},{"location":"releases/v0.4.0/#breaking-changes","title":"Breaking Changes","text":""},{"location":"releases/v0.4.0/#module-path-change","title":"Module Path Change","text":"<p>The Go module path has changed:</p> <pre><code>github.com/grokify/stats-agent-team \u2192 github.com/agentplexus/stats-agent-team\n</code></pre> <p>Update your imports accordingly if you depend on this module.</p>"},{"location":"releases/v0.4.0/#dependency-library-renames","title":"Dependency Library Renames","text":"<p>The following dependencies have been renamed and updated:</p> Old Package New Package Version <code>github.com/grokify/metallm</code> <code>github.com/agentplexus/omnillm</code> v0.9.0 <code>github.com/grokify/metaobserve</code> <code>github.com/agentplexus/omniobserve</code> v0.4.0 <code>github.com/grokify/metaserp</code> <code>github.com/agentplexus/omniserp</code> v0.6.0"},{"location":"releases/v0.4.0/#new-features","title":"New Features","text":""},{"location":"releases/v0.4.0/#helm-chart-helmstats-agent-team","title":"Helm Chart (<code>helm/stats-agent-team/</code>)","text":"<p>Production-ready Helm chart for Kubernetes deployment:</p> <p>Templates: - Deployments for all 5 agents (research, synthesis, verification, orchestration, direct) - Services with HTTP and A2A protocol ports - ConfigMaps and Secrets for configuration - Horizontal Pod Autoscaler (HPA) for auto-scaling - Pod Disruption Budget (PDB) for high availability - Ingress for external access - ServiceAccount with configurable annotations</p> <p>Values Files: - <code>values.yaml</code> - Default configuration - <code>values-minikube.yaml</code> - Local development with Minikube - <code>values-eks.yaml</code> - AWS EKS production deployment</p> <p>Makefile Commands: <pre><code>make k8s-minikube-setup    # Setup Minikube\nmake k8s-minikube-build    # Build images in Minikube\nmake k8s-minikube-deploy   # Deploy to Minikube\nmake k8s-eks-deploy        # Deploy to AWS EKS\nmake helm-lint             # Lint Helm chart\nmake helm-template         # Render templates locally\n</code></pre></p>"},{"location":"releases/v0.4.0/#parameterized-dockerfile-dockerfileagent","title":"Parameterized Dockerfile (<code>Dockerfile.agent</code>)","text":"<p>Single multi-stage Dockerfile for building all agent images:</p> <pre><code># Build individual agents\ndocker build --build-arg AGENT=research -t stats-agent-research .\ndocker build --build-arg AGENT=synthesis -t stats-agent-synthesis .\ndocker build --build-arg AGENT=verification -t stats-agent-verification .\ndocker build --build-arg AGENT=orchestration-eino -t stats-agent-orchestration-eino .\ndocker build --build-arg AGENT=direct -t stats-agent-direct .\n</code></pre> <p>Features: - Multi-stage build for minimal image size - Non-root user for security - Health check configuration - OCI labels for container metadata</p>"},{"location":"releases/v0.4.0/#cicd-pipeline-githubworkflows","title":"CI/CD Pipeline (<code>.github/workflows/</code>)","text":""},{"location":"releases/v0.4.0/#helm-chart-ci-helmyaml","title":"Helm Chart CI (<code>helm.yaml</code>)","text":"<p>Comprehensive Helm chart validation pipeline:</p> Job Description Gitleaks Secret detection in repository Trivy Config Configuration security scan Trivy Secret Filesystem secret scan Trivy Image Container vulnerability scan with SBOM Lint Helm chart linting (default, Minikube, EKS) Unit Tests helm-unittest test suites Kubeconform Kubernetes schema validation (v1.29.0) Polaris Security &amp; best practices audit Go Validation Go struct validation tests Integration Kind cluster deployment test Chart Testing Official Helm chart-testing (ct)"},{"location":"releases/v0.4.0/#release-workflow-releaseyaml","title":"Release Workflow (<code>release.yaml</code>)","text":"<p>Automated container image publishing: - Triggers on GitHub releases (minor/major only) - Builds all 5 agent images in parallel - Pushes to GitHub Container Registry (ghcr.io) - Semantic versioning tags (v1.0.0, v1.0, v1, latest) - Docker layer caching for faster builds</p>"},{"location":"releases/v0.4.0/#go-struct-validation-pkghelm","title":"Go Struct Validation (<code>pkg/helm/</code>)","text":"<p>Type-safe Go structs mirroring Helm values with validation:</p> <pre><code>// Load and validate Helm values\nvalues, errs := helm.LoadAndValidate(\"values.yaml\")\n\n// Merge base with overlay and validate\nvalues, errs := helm.LoadMergeAndValidate(\"values.yaml\", \"values-eks.yaml\")\n</code></pre> <p>Validation features: - Struct tag validation (required, oneof, min, max) - Custom Kubernetes resource quantity validation (<code>100m</code>, <code>256Mi</code>) - Business rule validation (agent dependencies, port conflicts) - LLM provider configuration checks</p>"},{"location":"releases/v0.4.0/#helm-chart-unit-tests-helmstats-agent-teamtests","title":"Helm Chart Unit Tests (<code>helm/stats-agent-team/tests/</code>)","text":"<p>helm-unittest test suites: - <code>deployment_test.yaml</code> - Deployment configuration tests - <code>service_test.yaml</code> - Service configuration tests - <code>hpa_test.yaml</code> - HorizontalPodAutoscaler tests - <code>pdb_test.yaml</code> - PodDisruptionBudget tests - <code>ingress_test.yaml</code> - Ingress configuration tests</p> <p>Run tests: <pre><code>make helm-unittest    # Run unit tests\nmake helm-test        # Lint + unit tests\nmake helm-test-all    # All tests including kubeconform\n</code></pre></p>"},{"location":"releases/v0.4.0/#security-configuration","title":"Security Configuration","text":"<p>Gitleaks Configuration (<code>.gitleaks.toml</code>): - Extends default gitleaks rules - Allowlists for go.mod, go.sum - Ignores example values in documentation</p> <p>Trivy Configuration (<code>.trivyignore</code>): - CVE ignore list for false positives - Secret detection rule exceptions</p> <p>Chart Testing Configuration (<code>ct.yaml</code>): - Helm chart-testing configuration - Target branch and chart directories</p>"},{"location":"releases/v0.4.0/#mkdocs-documentation-site","title":"MkDocs Documentation Site","text":"<p>Full documentation site built with MkDocs and Material theme:</p> <ul> <li>Source files: <code>docsrc/</code> directory</li> <li>Generated output: <code>docs/</code> directory (auto-generated)</li> <li>Theme: Material for MkDocs with dark/light mode toggle</li> </ul> <p>Documentation structure: - Getting Started (Installation, Quick Start, Configuration) - Architecture (Overview, 4-Agent Architecture, Eino Orchestration) - Guides (Docker, Kubernetes, MCP Server, LLM Configuration) - Operations (Security, Scaling, Chart Testing) - Development (Lint Fixes) - Reference (Roadmap) - Release Notes</p> <p>Commands: <pre><code>make docs        # Build documentation\nmake docs-serve  # Serve documentation locally\nmake docs-clean  # Clean generated docs\n</code></pre></p>"},{"location":"releases/v0.4.0/#enhancements","title":"Enhancements","text":""},{"location":"releases/v0.4.0/#helm-validation-error-handling","title":"Helm Validation Error Handling","text":"<p>Improved error handling in <code>pkg/helm/values.go</code> for validation registration. Programming errors during validation setup now panic with descriptive messages instead of silently ignoring errors.</p>"},{"location":"releases/v0.4.0/#documentation-updates","title":"Documentation Updates","text":"<ul> <li>All documentation updated to reference new <code>agentplexus</code> organization</li> <li>Updated badge URLs in README</li> <li>Updated Go package documentation links</li> <li>Updated Helm chart metadata</li> </ul>"},{"location":"releases/v0.4.0/#dependencies","title":"Dependencies","text":"<ul> <li><code>github.com/agentplexus/omnillm</code> v0.9.0 (replaces metallm)</li> <li><code>github.com/agentplexus/omniobserve</code> v0.4.0 (replaces metaobserve)</li> <li><code>github.com/agentplexus/omniserp</code> v0.6.0 (replaces metaserp)</li> <li><code>github.com/cloudwego/eino</code> v0.7.14</li> <li><code>github.com/go-playground/validator/v10</code> (for Helm values validation)</li> </ul>"},{"location":"releases/v0.4.0/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>Fixed unchecked error return value in Helm validation registration (<code>pkg/helm/values.go:228</code>)</li> </ul>"},{"location":"releases/v0.4.0/#migration-guide","title":"Migration Guide","text":""},{"location":"releases/v0.4.0/#updating-import-paths","title":"Updating Import Paths","text":"<p>If you import this module, update your imports:</p> <pre><code>// Before\nimport \"github.com/grokify/stats-agent-team/pkg/...\"\n\n// After\nimport \"github.com/agentplexus/stats-agent-team/pkg/...\"\n</code></pre>"},{"location":"releases/v0.4.0/#cloning-the-repository","title":"Cloning the Repository","text":"<p>The repository URL has changed:</p> <pre><code># New URL\ngit clone https://github.com/agentplexus/stats-agent-team.git\n</code></pre>"},{"location":"releases/v0.4.0/#deploying-to-kubernetes","title":"Deploying to Kubernetes","text":""},{"location":"releases/v0.4.0/#minikube-local-development","title":"Minikube (Local Development)","text":"<pre><code># Setup and build\nmake k8s-minikube-setup\nmake k8s-minikube-build\n\n# Deploy\nmake k8s-minikube-deploy\n\n# Access\nkubectl port-forward -n stats-agent svc/stats-agent-orchestration 8000:8000\n</code></pre>"},{"location":"releases/v0.4.0/#aws-eks-production","title":"AWS EKS (Production)","text":"<pre><code># Build and push images to ECR\nmake k8s-build-images\nmake k8s-eks-push REGISTRY=123456789.dkr.ecr.us-west-2.amazonaws.com\n\n# Deploy\nmake k8s-eks-deploy REGISTRY=123456789.dkr.ecr.us-west-2.amazonaws.com\n</code></pre>"},{"location":"releases/v0.4.0/#building-documentation","title":"Building Documentation","text":"<p>To build and serve the documentation locally:</p> <pre><code># Install dependencies\npip install mkdocs mkdocs-material pymdown-extensions\n\n# Serve locally\nmake docs-serve\n\n# Build static site\nmake docs\n</code></pre>"},{"location":"releases/v0.4.0/#contributors","title":"Contributors","text":"<ul> <li>John Wang (@grokify)</li> </ul> <p>Full Changelog: <code>v0.3.0...v0.4.0</code></p>"}]}