# LLM Provider Configuration
# Choose one: gemini, claude, openai, xai, ollama
LLM_PROVIDER=gemini

# LLM Model (optional - defaults set per provider)
# Gemini: gemini-2.0-flash-exp
# Claude: claude-3-5-sonnet-20241022
# OpenAI: gpt-4
# xAI: grok-3
# Ollama: llama3.2
# LLM_MODEL=

# Provider-Specific API Keys
# For Gemini (default provider)
GOOGLE_API_KEY=your-google-api-key-here
# GEMINI_API_KEY=your-google-api-key-here

# For Claude
# ANTHROPIC_API_KEY=your-anthropic-api-key-here
# CLAUDE_API_KEY=your-anthropic-api-key-here

# For OpenAI
# OPENAI_API_KEY=your-openai-api-key-here

# For xAI (Grok)
# XAI_API_KEY=your-xai-api-key-here

# For Ollama (local)
# OLLAMA_URL=http://localhost:11434

# Generic LLM API Key (overrides provider-specific keys)
# LLM_API_KEY=

# Custom LLM Base URL (for custom endpoints)
# LLM_BASE_URL=

# Search Provider Configuration
# Choose one: serper, serpapi
SEARCH_PROVIDER=serper

# Serper API Key (https://serper.dev)
# Get your key at: https://serper.dev/api-key
SERPER_API_KEY=your-serper-api-key-here

# SerpAPI Key (https://serpapi.com)
# Alternative search provider
# SERPAPI_API_KEY=your-serpapi-key-here

# Agent URLs (defaults shown - customize if needed)
# RESEARCH_AGENT_URL=http://localhost:8001
# VERIFICATION_AGENT_URL=http://localhost:8002
# ORCHESTRATOR_URL=http://localhost:8000
# ORCHESTRATOR_EINO_URL=http://localhost:8003

# A2A Protocol Configuration
# A2A_ENABLED=true
# A2A_AUTH_TYPE=apikey
# A2A_AUTH_TOKEN=

# =============================================================================
# LLM Observability Configuration (via OmniObserve)
# =============================================================================
# Choose one provider: opik, langfuse, phoenix
# OBSERVABILITY_ENABLED=false
# OBSERVABILITY_PROVIDER=opik

# -----------------------------------------------------------------------------
# Opik Configuration (https://github.com/comet-ml/opik)
# Open-source LLM observability with tracing, evaluation, and prompt management
# -----------------------------------------------------------------------------
# Get your API key at: https://www.comet.com/opik
# OPIK_API_KEY=your-opik-api-key-here

# For self-hosted Opik (optional)
# OPIK_ENDPOINT=https://opik.example.com

# Workspace name (optional, for Comet cloud)
# OPIK_WORKSPACE=your-workspace

# Default project name for traces
# OPIK_PROJECT=stats-agent-team

# -----------------------------------------------------------------------------
# Langfuse Configuration (https://langfuse.com)
# Open-source LLM observability and analytics
# -----------------------------------------------------------------------------
# Get your keys at: https://cloud.langfuse.com (Settings > API Keys)
# LANGFUSE_PUBLIC_KEY=pk-lf-your-public-key-here
# LANGFUSE_SECRET_KEY=sk-lf-your-secret-key-here

# For self-hosted Langfuse (optional)
# LANGFUSE_ENDPOINT=https://langfuse.example.com

# -----------------------------------------------------------------------------
# Phoenix Configuration (https://phoenix.arize.com)
# Open-source LLM observability with OpenTelemetry support
# -----------------------------------------------------------------------------
# Local Phoenix server (default: http://localhost:6006)
# PHOENIX_ENDPOINT=http://localhost:6006

# For Arize cloud (optional)
# PHOENIX_API_KEY=your-phoenix-api-key-here

# Project/dataset name
# PHOENIX_PROJECT=stats-agent-team
